{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTie3+ElCwiYDCNH+gb3N4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e73205db7d1490d8a890a92e6fee68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624ccb8e07f844adbf662104666ec228",
              "IPY_MODEL_80479d9bc5594ff1838e020f7f94a598",
              "IPY_MODEL_8348cc697c5947f5af0e4c1cdc98bd6c"
            ],
            "layout": "IPY_MODEL_6e7f69632a744179aa419601d06b4278"
          }
        },
        "624ccb8e07f844adbf662104666ec228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd91eadf0da4d148f7048167b7b16e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ca479a7ebbfb4e79b8fe77e741d462df",
            "value": "100%"
          }
        },
        "80479d9bc5594ff1838e020f7f94a598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952e050b2e2c41d7a25647fd2ed18b2c",
            "max": 208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5021b77fe45445e1b1e873ca17714687",
            "value": 208
          }
        },
        "8348cc697c5947f5af0e4c1cdc98bd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03886693f3194001afb4cd6d037e71be",
            "placeholder": "​",
            "style": "IPY_MODEL_ae93d10750f945cf94e95c9319c7ddc4",
            "value": " 208/208 [05:07&lt;00:00,  1.54s/it]"
          }
        },
        "6e7f69632a744179aa419601d06b4278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd91eadf0da4d148f7048167b7b16e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca479a7ebbfb4e79b8fe77e741d462df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "952e050b2e2c41d7a25647fd2ed18b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5021b77fe45445e1b1e873ca17714687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03886693f3194001afb4cd6d037e71be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae93d10750f945cf94e95c9319c7ddc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravadhani/NLP/blob/main/SimilarityOfDocuments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czJpkWB1fns8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "You want to give readers of an online portal a better reading experience by recomminding articles to the reader on the basis of current article the reader is reading.\n",
        "\n",
        "***This is a case study for finding similar documents.***"
      ],
      "metadata": {
        "id": "AfHjzB9jfznp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries to display dataframe and images\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "#matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "#inbuild library to work with textual data\n",
        "import string\n",
        "#setting up NLTK for preprocessing text data\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('treebank')\n",
        "\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytA34E-1gcJ3",
        "outputId": "0e52dda9-a083-4d98-a090-28892782c193"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYsJISsTis88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link for dataset: https://drive.google.com/file/d/1MyOEKk_z78P8JL0mTYSerRiPLVflkVK6/view"
      ],
      "metadata": {
        "id": "e9ntXz-sjIzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1MyOEKk_z78P8JL0mTYSerRiPLVflkVK6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE5ffvfNis_T",
        "outputId": "c5333c95-993e-4a89-c21c-3adaaa305901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MyOEKk_z78P8JL0mTYSerRiPLVflkVK6\n",
            "To: /content/medium_articles_v3.csv\n",
            "\r  0% 0.00/3.13M [00:00<?, ?B/s]\r100% 3.13M/3.13M [00:00<00:00, 198MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "#reading data file\n",
        "df = pd.read_csv(\"/content/medium_articles_v3.csv\")\n",
        "display(df.head())\n",
        "print(\"\\nShape of the dataframe: {}\".format(df.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "XIgc8NzRitDq",
        "outputId": "d480ffa1-b5c2-4003-ce98-3d6b6e4b19f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                link  \\\n",
              "0  https://towardsdatascience.com/ensemble-method...   \n",
              "1  https://towardsdatascience.com/understanding-a...   \n",
              "2  https://towardsdatascience.com/how-to-work-wit...   \n",
              "3  https://towardsdatascience.com/11-dimensionali...   \n",
              "4  https://towardsdatascience.com/the-time-series...   \n",
              "\n",
              "                                               title  \\\n",
              "0   Ensemble methods: bagging, boosting and stacking   \n",
              "1                      Understanding AUC - ROC Curve   \n",
              "2  How to work with object detection datasets in ...   \n",
              "3  11 Dimensionality reduction techniques you sho...   \n",
              "4                        The Time Series Transformer   \n",
              "\n",
              "                                           sub_title               author  \\\n",
              "0  Understanding the key concepts of ensemble lea...         Joseph Rocca   \n",
              "1  In Machine Learning, performance measurement i...      Sarang Narkhede   \n",
              "2  A comprehensive guide to defining, loading, ex...       Eric Hofesmann   \n",
              "3  Reduce the size of your dataset while keeping ...   Rukshan Pramoditha   \n",
              "4  Attention Is All You Need they said. Is it a m...  Theodoros Ntakouris   \n",
              "\n",
              "   reading_time                                               text  id  \n",
              "0            20  This post was co-written with Baptiste Rocca.\\...   1  \n",
              "1             5  In Machine Learning, performance measurement i...   2  \n",
              "2            10  Microsoft's Common Objects in Context dataset ...   3  \n",
              "3            16  In both Statistics and Machine Learning, the n...   4  \n",
              "4             6  Attention Is All You Need they said. Is it a m...   5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d980bc0-4bae-47b1-8a79-84d0054de9b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>title</th>\n",
              "      <th>sub_title</th>\n",
              "      <th>author</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "      <td>Understanding the key concepts of ensemble lea...</td>\n",
              "      <td>Joseph Rocca</td>\n",
              "      <td>20</td>\n",
              "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
              "      <td>Understanding AUC - ROC Curve</td>\n",
              "      <td>In Machine Learning, performance measurement i...</td>\n",
              "      <td>Sarang Narkhede</td>\n",
              "      <td>5</td>\n",
              "      <td>In Machine Learning, performance measurement i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
              "      <td>How to work with object detection datasets in ...</td>\n",
              "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
              "      <td>Eric Hofesmann</td>\n",
              "      <td>10</td>\n",
              "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
              "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
              "      <td>Reduce the size of your dataset while keeping ...</td>\n",
              "      <td>Rukshan Pramoditha</td>\n",
              "      <td>16</td>\n",
              "      <td>In both Statistics and Machine Learning, the n...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
              "      <td>The Time Series Transformer</td>\n",
              "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
              "      <td>Theodoros Ntakouris</td>\n",
              "      <td>6</td>\n",
              "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d980bc0-4bae-47b1-8a79-84d0054de9b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d980bc0-4bae-47b1-8a79-84d0054de9b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d980bc0-4bae-47b1-8a79-84d0054de9b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a5cffa1-af41-4d40-803b-cd3ae6b69e68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a5cffa1-af41-4d40-803b-cd3ae6b69e68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a5cffa1-af41-4d40-803b-cd3ae6b69e68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nShape of the dataframe: {}\\\"\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5?source=tag_archive---------1-----------------------\",\n          \"https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3?source=tag_archive---------4-----------------------\",\n          \"https://towardsdatascience.com/how-to-work-with-object-detection-datasets-in-coco-format-9bf4fb5848a4?source=tag_archive---------7-----------------------\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Understanding AUC - ROC Curve\",\n          \"The Time Series Transformer\",\n          \"How to work with object detection datasets in COCO format\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sub_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"In Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC - ROC Curve. When we need to check or visualize the performance...\",\n          \"Attention Is All You Need they said. Is it a more robust convolution? Is it just a hack to squeeze more learning capacity out of fewer parameters? Is it supposed to be sparse? How did the original...\",\n          \"A comprehensive guide to defining, loading, exploring, and evaluating object detection datasets in COCO format using FiftyOne\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sarang Narkhede\",\n          \"Theodoros Ntakouris\",\n          \"Eric Hofesmann\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reading_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 5,\n        \"max\": 20,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          6,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"In Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC - ROC Curve. When we need to check or visualize the performance of the multi-class classification problem, we use the AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification model's performance. It is also written as AUROC (Area Under the Receiver Operating Characteristics)\\nNote: For better understanding, I suggest you read my article about Confusion Matrix.\\nThis blog aims to answer the following questions:\\n1. What is the AUC - ROC Curve?\\n2. Defining terms used in AUC and ROC Curve.\\n3. How to speculate the performance of the model?\\n4. Relation between Sensitivity, Specificity, FPR, and Threshold.\\n5. How to use AUC - ROC curve for the multiclass model?\\nAUC - ROC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1. By analogy, the Higher the AUC, the better the model is at distinguishing between patients with the disease and no disease.\\nThe ROC curve is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis.\\nAn excellent model has AUC near to the 1 which means it has a good measure of separability. A poor model has an AUC near 0 which means it has the worst measure of separability. In fact, it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means the model has no class separation capacity whatsoever.\\nLet's interpret the above statements.\\nAs we know, ROC is a curve of probability. So let's plot the distributions of those probabilities:\\nNote: Red distribution curve is of the positive class (patients with disease) and the green distribution curve is of the negative class(patients with no disease).\\nThis is an ideal situation. When two curves don't overlap at all means model has an ideal measure of separability. It is perfectly able to distinguish between positive class and negative class.\\nWhen two distributions overlap, we introduce type 1 and type 2 errors. Depending upon the threshold, we can minimize or maximize them. When AUC is 0.7, it means there is a 70% chance that the model will be able to distinguish between positive class and negative class.\\nThis is the worst situation. When AUC is approximately 0.5, the model has no discrimination capacity to distinguish between positive class and negative class.\\nWhen AUC is approximately 0, the model is actually reciprocating the classes. It means the model is predicting a negative class as a positive class and vice versa.\\nSensitivity and Specificity are inversely proportional to each other. So when we increase Sensitivity, Specificity decreases, and vice versa.\\nSensitivity, Specificity and Sensitivity, Specificity\\nWhen we decrease the threshold, we get more positive values thus it increases the sensitivity and decreasing the specificity.\\nSimilarly, when we increase the threshold, we get more negative values thus we get higher specificity and lower sensitivity.\\nAs we know FPR is 1 - specificity. So when we increase TPR, FPR also increases and vice versa.\\nTPR, FPR and TPR, FPR\\nIn a multi-class model, we can plot the N number of AUC ROC Curves for N number classes using the One vs ALL methodology. So for example, If you have three classes named X, Y, and Z, you will have one ROC for X classified against Y and Z, another ROC for Y classified against X and Z, and the third one of Z classified against Y and X.\\nThanks for Reading.\\nI hope I've given you some understanding of what exactly is the AUC - ROC Curve. If you like this post, a tad of extra motivation will be helpful by giving this post some claps . I am always open to your questions and suggestions. You can share this on Facebook, Twitter, Linkedin, so someone in need might stumble upon this.\\nYou can reach me at:\\nLinkedIn: https://www.linkedin.com/in/narkhedesarang/\\nTwitter: https://twitter.com/narkhede_sarang\\nGithub: https://github.com/TheSarang\\n\",\n          \"Attention Is All You Need they said. Is it a more robust convolution? Is it just a hack to squeeze more learning capacity out of fewer parameters? Is it supposed to be sparse? How did the original authors come up with this architecture?\\nIt is pretty easy to switch from an existing RNN model to the Attention architecture. Inputs are of the same shape!\\nUsing Transformers for Time Series Tasks is different than using them for NLP or Computer Vision. We neither tokenize data, nor cut them into 16x16 image chunks. Instead, we follow a more classic / old school way of preparing data for training.\\nOne thing that is definitely true is that we have to feed data in the same value range as input, to eliminate bias. This is typically on the [0, 1] or [-1, 1] range. In general, it is recommended to apply the same kind of preprocessing pipeline on all of your input features to eliminate this bias. Individual use cases may be exempt from this, different models and data are unique! Think about the origin of your data for a moment.\\nAgain, preprocessing decisions are tightly coupled to the problem and data at hand, but this is a nice list to get your started.\\nIf your time series can become stationary by doing preprocessing such as seasonal decomposition, you could get good quality predictions by using smaller models (that also get trained way faster and require less code and effort), such as NeuralProphet or Tensorflow Probability.\\nDeep Neural Networks can learn linear and periodic components on their own, during training (we will use Time 2 Vec later). That said, I would advise against seasonal decomposition as a preprocessing step.\\nOther decisions such as calculating aggregates and pairwise differences, depend on the nature of your data, and what you want to predict.\\nTreating sequence length as a hyper parameter, this leads us to an input tensor shape that is similar to RNNs: (batch size, sequence length, features) .\\nHere is a drawing for all the dimensions set to 3.\\nFor Attention to work, you need to attach the meaning of time to your input features. In the original NLP model, a collection of superimposed sinusoidal functions were added to each input embedding. We need a different representation now that our inputs are scalar values and not distinct words/tokens.\\nThe Time 2 Vec paper comes in handy. It's a learnable and complementary, model-agnostic represetation of time. If you've studied Fourier Transforms in the past, this should be easy to understand.\\nJust break down each input feature to a linear component ( a line ) and as many periodic (sinusoidal) components you wish. By defining the decomposition as a function, we can make the weights learnable through back propagation.\\nFor each input feature, we apply the same layer in a time-independent (time-distributed layer) manner. This learnable embedding does not depend on time! Finally, concatenate the original inputs.\\nHere is a an illustration of the learned time embeddings, which are different, for each input feature category (1 learned linear component and 1 learned periodic component per feature).\\nThis does not mean that each time  step will carry the same embedding value, because the computation of the time2vec embeddings depend on the input values!\\nAnd, in the end, we concatenate these all together to form the input for the attention blocks.\\nWe are going to use Multi-Head Self-Attention (setting Q, K and V to depend on the input through different dense layers/matrices). The next part is optional and depends on the scale of your model and data, but we are also going to ditch the decoder part completely. This means, that we are only going to use one or more attention block layers.\\nIn the last part, we are going to use a few (one or more) Dense layers to predict whatever we want to predict.\\nEach Attention Block consists of Self Attention, Layer Normalizations and a Feed  Forward Block. The input dimensions of each block are equal to it's output dimensions.\\nOptionally, before the head part, you can apply some sort of pooling (Global Average 1D for example).\\nThings to consider when using Transformers and Attention, to get the most out of your model.\\nDon't go crazy with hyperparameters. Start with a single, humble attention layer, a couple of heads and a low dimension. Observe results and adjust hyper parameters accordingly  don't overfit! Scale your model along with your data. Nevertheless, nothing is stopping you from scheduling a huge hyperparameter search job :).\\nA crucial part of the attention mechanism that leads to greater stability is learning-rate warmup. Start with a small learnign rate and gradually increase it till you reach the base one, then decrease again. You can go crazy with exponential  decaying schedules and sophisticated formulas, but I will just give you a simple example that you should be able to understand just by reading the following code out loud:\\nNon-accelerated gradient descent optimization methods do not work well with Transformers. Adam is a good initial optimizer choice to train with. Keep an eye out for newer (and possibly better) optimization techniques like AdamW or NovoGrad!\\nThanks for reading all the way to the end!\\n[1] Attention Is All You Need, Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin, 2017\\n[2] Time2Vec: Learning a Vector Representation of Time, Seyed Mehran Kazemi and Rishab Goel and Sepehr Eghbali and Janahan Ramanan and Jaspreet Sahota and Sanjay Thakur and Stella Wu and Cathal Smyth and Pascal Poupart and Marcus Brubaker, 2019\\n\",\n          \"Microsoft's Common Objects in Context dataset (COCO) is the most popular object detection dataset at the moment. It is widely used to benchmark the performance of computer vision methods.\\nDue to the popularity of the dataset, the format that COCO uses to store annotations is often the go-to format when creating a new custom object detection dataset. While the COCO dataset also supports annotations for other tasks like segmentation, I will leave that to a future blog post. For now, we will focus only on object detection data.\\nThe \\\"COCO format\\\" is a specific JSON structure dictating how labels and metadata are saved for an image dataset.\\nMany blog posts exist that describe the basic format of COCO, but they often lack detailed examples of loading and working with your COCO formatted data. This post will walk you through:\\nIn order to do all of this, I'll be using the open-source machine learning developer tool, FiftyOne, that I have been working on. It's designed to let researchers and engineers easily work with and visualize image and video datasets with annotations and model predictions stored in various formats.\\nYou can easily install FiftyOne through pip:\\nAs of 06/29/2021: With support from the COCO team, COCO has been integrated into FiftyOne to make it easy to download and evaluate on the dataset. You can now specify and download the exact subset of the dataset that you want, load your own COCO-formatted data into FiftyOne, and evaluate your models with COCO-style evaluation enhanced by the visualization capabilities of FiftyOne.\\nSee this post or this documentation for more details!\\nIf you are new to the object detection space and are tasked with creating a new object detection dataset, then following the COCO format is a good choice due to its relative simplicity and widespread usage. This section will explain what the file and folder structure of a COCO formatted object detection dataset actually looks like.\\nAt a high level, the COCO format defines exactly how your annotations (bounding boxes, object classes, etc) and image metadata (like height, width, image sources, etc) are stored on disk.\\nThe folder structure of a COCO dataset looks like this:\\nThe dataset is stored in a directory containing your raw image data and a single json file that contains all of the annotations, metadata, categories, and other information that you could possibly want to store about your dataset. If you have multiple splits of data, they would be stored in different directories with different json files.\\nIf you were to download the COCO dataset from their website, this would be the instances_train2017.json and instances_val2017.json files. (Note: The official test set annotations are unavailable to the public)\\nThis section will outline how to take your raw or annotated dataset and convert it to the COCO format depending on what data you currently have and the format it is in.\\nIn this case, you already have a dataset with images and annotations but want to convert it to the COCO format.\\nIf your dataset happens to follow a different common format that is supported by FiftyOne, like CVAT, YOLO, KITTI, Pascal VOC, TF Object detection, or others, then you can load and convert it to COCO format in a single command.\\nIf your data is not stored in a supported format, then it is still easy to load it into FiftyOne using Python and export it in COCO format. The idea is to load each image and associated labels as a FiftyOne Sample and add them to a FiftyOne Dataset:\\nYou can then export this dataset in COCO format with one line:\\nAnd there you have it! /path/to/coco-detection-dataset now contains your images and labels in COCO format. Check out the next section to see how to easily load it back into Python.\\nIf you only have unlabeled images, then you will first need to generate object labels. You can generate either ground truth labels with an annotation tool or provider (like CVAT, Labelbox, MTurk, or one of many others) or predicted labels with an existing pretrained model.\\nIf, for example, you used CVAT to annotate your raw data, then you can now convert it to COCO format using the FiftyOne command just like in the above section:\\nAlternatively, if you want to use a model to generate predictions, you can load your unlabeled data into FiftyOne and generate predictions with the FiftyOne Model Zoo, then save your dataset in COCO format.\\nThis section assumes that you have gathered images and annotated them, storing your dataset in the COCO format, either following the previous section or manually building the labels JSON through custom scripting.\\nIn order to load your COCO formatted dataset, you could write a parser for the JSON labels file, but really you should just use one of the various tools out there that will load it for you. Two of the best tools for this are the official COCO APIs and FiftyOne.\\nThere are official COCO APIs for Python, Lua, and Matlab. These APIs are commonly used and provide basic functionality to load and compute dataset-wide evaluation on your dataset.\\nIf you are using Python, I would recommend trying out FiftyOne, since it provides similar functionality to the cocoapi, along with a powerful API and GUI designed specifically to make it as easy as possible for you to explore, analyze, and work with your data.\\nIf your dataset correctly follows the COCO format outlined in the previous sections, you can load it into a FiftyOne Dataset in Python with a single command:\\nNow that your dataset is in Python, you can use the FiftyOne API to easily access all of the different information and labels associated with your data and visualize it in the App.\\nTo visualize your dataset, launch the FiftyOne App:\\nWith the API, you can use aggregations to get statistics about your dataset, like the number of detections for each category:\\nThe primary way of interacting with your dataset is through views. Every query you make will give you a different view into your dataset, like sorting by samples with the most number of objects:\\nYou can also make a view that filters a label field based on a more complex value like small bounding box area:\\nThe FiftyOne Brain contains various methods that allow you to analyze the quality of your ground truth data. For example, you can find the most unique samples in your dataset which can help you get a better idea of what kind of additional data you should add:\\nOther Brain methods can help you find possible annotation mistakes and identify hard samples you may want to train on. All of these will assist you in training better models since better models generally stem from better data.\\nThe main reason that you want to create a COCO formatted dataset is to use it to train and test models.\\nMost models these days rely on your data being loaded into Python. Especially if you are using TensorFlow or PyTorch since these libraries are primarily Python-based. Using the COCO API or FiftyOne to get your dataset into Python makes it much easier to write up a PyTorch dataloader, for example, than if you had to parse the labels JSON yourself. Actually training a model on your data is out of the scope of this post but there are plenty of examples for both PyTorch object detection training and even a TensorFlow Object Detection API to help you along.\\nIf you are just starting and want to see how some pretrained models would behave on your dataset, the easiest way to generate some predictions is with the FiftyOne Model Zoo. It contains over 70 models, many of which are object detection models.\\nNote: If you're tired of configuring TensorFlow/PyTorch models to use your GPU, check out my blog post on Conda.\\nSince your data is stored in COCO format, it can be loaded into FiftyOne, model predictions can be generated on it, and then visualized in the App:\\nThe primary evaluation metric for object detection models is mean average precision (mAP). This is a fairly complex metric that is explained in more detail in other posts. In summary, it is computed by:\\nThe COCO evaluation protocol introduces one additional step: mAPs are averaged across a range of 10 IoU thresholds. Additionally, COCO object detection evaluation also includes calculating the mAP for things like small, medium, and large bounding boxes, and varying thresholds of detections per image.\\nNote: When evaluating an object detection model, the categories of the predictions must match those of the dataset. This means you must either follow the labels of the COCO dataset to use an out-of-the-box model trained on COCO, or you must fine-tune a model on your dataset so it will predict your custom categories.\\nThis COCO mAP value can be computed with either the COCO API or with FiftyOne. Assuming you have a dataset in COCO format with model predictions stored in the predictions field of the dataset, the following will compute the COCO mAP in FiftyOne:\\nEven though mAP is the most popular single value to compare model performances, this metric does have drawbacks. If you really want to know how well your model is performing, you need to dig into your data and look at model predictions on individual samples.\\nThe best way to build intuition about how your model performs is by looking at predictions that it was confident about but got wrong. With FiftyOne, this is easy. For example, let's create a view into our dataset looking at the samples with the most false positives:\\nThe example above is in this view and shows a crowd of objects with the false positives not annotated in the ground truth! In the COCO format, ground truth objects can have an iscrowd attribute that specifies that the bounding box is drawn around a crowd of objects. This is one of many examples where this iscrowd box is either missing or incorrectly labeled resulting in false positives.\\nThis is something that would have been impossible to find just by looking at the mAP of the model and shows the importance of sample-level analysis to understand dataset quality.\\nHigh-quality, intentionally-curated data is critical to training great computer vision models. At Voxel51, we have over 25 years of CV/ML experience and care deeply about enabling the community to bring their AI solutions to life. That's why we developed FiftyOne, an open-source tool that helps engineers and scientists to build high-quality datasets and models.\\nWant to learn more? Check us out at fiftyone.ai.\\nMachine learning engineer at Voxel51, Masters in Computer Science from the University of Michigan. https://www.linkedin.com/in/eric-hofesmann/\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the dataframe: (208, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nShape of the dataframe: \" + format(df.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkJiPuyskA5M",
        "outputId": "6f003051-6a01-4f63-9911-3846ca65ad1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the dataframe: (208, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(df.iloc[1].to_dict(), compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVxa-f1KlvAv",
        "outputId": "6a26699a-aadb-4044-b78c-493e81ec7994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'author': 'Sarang Narkhede',\n",
            " 'id': 2,\n",
            " 'link': 'https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5?source=tag_archive---------1-----------------------',\n",
            " 'reading_time': 5,\n",
            " 'sub_title': 'In Machine Learning, performance measurement is an essential '\n",
            "              'task. So when it comes to a classification problem, we can '\n",
            "              'count on an AUC - ROC Curve. When we need to check or visualize '\n",
            "              'the performance...',\n",
            " 'text': 'In Machine Learning, performance measurement is an essential task. '\n",
            "         'So when it comes to a classification problem, we can count on an AUC '\n",
            "         '- ROC Curve. When we need to check or visualize the performance of '\n",
            "         'the multi-class classification problem, we use the AUC (Area Under '\n",
            "         'The Curve) ROC (Receiver Operating Characteristics) curve. It is one '\n",
            "         'of the most important evaluation metrics for checking any '\n",
            "         \"classification model's performance. It is also written as AUROC \"\n",
            "         '(Area Under the Receiver Operating Characteristics)\\n'\n",
            "         'Note: For better understanding, I suggest you read my article about '\n",
            "         'Confusion Matrix.\\n'\n",
            "         'This blog aims to answer the following questions:\\n'\n",
            "         '1. What is the AUC - ROC Curve?\\n'\n",
            "         '2. Defining terms used in AUC and ROC Curve.\\n'\n",
            "         '3. How to speculate the performance of the model?\\n'\n",
            "         '4. Relation between Sensitivity, Specificity, FPR, and Threshold.\\n'\n",
            "         '5. How to use AUC - ROC curve for the multiclass model?\\n'\n",
            "         'AUC - ROC curve is a performance measurement for the classification '\n",
            "         'problems at various threshold settings. ROC is a probability curve '\n",
            "         'and AUC represents the degree or measure of separability. It tells '\n",
            "         'how much the model is capable of distinguishing between classes. '\n",
            "         'Higher the AUC, the better the model is at predicting 0 classes as 0 '\n",
            "         'and 1 classes as 1. By analogy, the Higher the AUC, the better the '\n",
            "         'model is at distinguishing between patients with the disease and no '\n",
            "         'disease.\\n'\n",
            "         'The ROC curve is plotted with TPR against the FPR where TPR is on '\n",
            "         'the y-axis and FPR is on the x-axis.\\n'\n",
            "         'An excellent model has AUC near to the 1 which means it has a good '\n",
            "         'measure of separability. A poor model has an AUC near 0 which means '\n",
            "         'it has the worst measure of separability. In fact, it means it is '\n",
            "         'reciprocating the result. It is predicting 0s as 1s and 1s as 0s. '\n",
            "         'And when AUC is 0.5, it means the model has no class separation '\n",
            "         'capacity whatsoever.\\n'\n",
            "         \"Let's interpret the above statements.\\n\"\n",
            "         \"As we know, ROC is a curve of probability. So let's plot the \"\n",
            "         'distributions of those probabilities:\\n'\n",
            "         'Note: Red distribution curve is of the positive class (patients with '\n",
            "         'disease) and the green distribution curve is of the negative '\n",
            "         'class(patients with no disease).\\n'\n",
            "         \"This is an ideal situation. When two curves don't overlap at all \"\n",
            "         'means model has an ideal measure of separability. It is perfectly '\n",
            "         'able to distinguish between positive class and negative class.\\n'\n",
            "         'When two distributions overlap, we introduce type 1 and type 2 '\n",
            "         'errors. Depending upon the threshold, we can minimize or maximize '\n",
            "         'them. When AUC is 0.7, it means there is a 70% chance that the model '\n",
            "         'will be able to distinguish between positive class and negative '\n",
            "         'class.\\n'\n",
            "         'This is the worst situation. When AUC is approximately 0.5, the '\n",
            "         'model has no discrimination capacity to distinguish between positive '\n",
            "         'class and negative class.\\n'\n",
            "         'When AUC is approximately 0, the model is actually reciprocating the '\n",
            "         'classes. It means the model is predicting a negative class as a '\n",
            "         'positive class and vice versa.\\n'\n",
            "         'Sensitivity and Specificity are inversely proportional to each '\n",
            "         'other. So when we increase Sensitivity, Specificity decreases, and '\n",
            "         'vice versa.\\n'\n",
            "         'Sensitivity, Specificity and Sensitivity, Specificity\\n'\n",
            "         'When we decrease the threshold, we get more positive values thus it '\n",
            "         'increases the sensitivity and decreasing the specificity.\\n'\n",
            "         'Similarly, when we increase the threshold, we get more negative '\n",
            "         'values thus we get higher specificity and lower sensitivity.\\n'\n",
            "         'As we know FPR is 1 - specificity. So when we increase TPR, FPR also '\n",
            "         'increases and vice versa.\\n'\n",
            "         'TPR, FPR and TPR, FPR\\n'\n",
            "         'In a multi-class model, we can plot the N number of AUC ROC Curves '\n",
            "         'for N number classes using the One vs ALL methodology. So for '\n",
            "         'example, If you have three classes named X, Y, and Z, you will have '\n",
            "         'one ROC for X classified against Y and Z, another ROC for Y '\n",
            "         'classified against X and Z, and the third one of Z classified '\n",
            "         'against Y and X.\\n'\n",
            "         'Thanks for Reading.\\n'\n",
            "         \"I hope I've given you some understanding of what exactly is the AUC \"\n",
            "         '- ROC Curve. If you like this post, a tad of extra motivation will '\n",
            "         'be helpful by giving this post some claps . I am always open to your '\n",
            "         'questions and suggestions. You can share this on Facebook, Twitter, '\n",
            "         'Linkedin, so someone in need might stumble upon this.\\n'\n",
            "         'You can reach me at:\\n'\n",
            "         'LinkedIn: https://www.linkedin.com/in/narkhedesarang/\\n'\n",
            "         'Twitter: https://twitter.com/narkhede_sarang\\n'\n",
            "         'Github: https://github.com/TheSarang\\n',\n",
            " 'title': 'Understanding AUC - ROC Curve'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistical summary of the dataframe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "TAV_KuoNlvDK",
        "outputId": "dd957b63-475e-44c0-aa46-3fe22b51fea5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     link  \\\n",
              "count                                                 208   \n",
              "unique                                                208   \n",
              "top     https://towardsdatascience.com/ensemble-method...   \n",
              "freq                                                    1   \n",
              "mean                                                  NaN   \n",
              "std                                                   NaN   \n",
              "min                                                   NaN   \n",
              "25%                                                   NaN   \n",
              "50%                                                   NaN   \n",
              "75%                                                   NaN   \n",
              "max                                                   NaN   \n",
              "\n",
              "                                                   title  \\\n",
              "count                                                208   \n",
              "unique                                               208   \n",
              "top     Ensemble methods: bagging, boosting and stacking   \n",
              "freq                                                   1   \n",
              "mean                                                 NaN   \n",
              "std                                                  NaN   \n",
              "min                                                  NaN   \n",
              "25%                                                  NaN   \n",
              "50%                                                  NaN   \n",
              "75%                                                  NaN   \n",
              "max                                                  NaN   \n",
              "\n",
              "                                                sub_title        author  \\\n",
              "count                                                 208           208   \n",
              "unique                                                204           179   \n",
              "top     Update: This article is part of a series. Chec...  Adam Geitgey   \n",
              "freq                                                    4             5   \n",
              "mean                                                  NaN           NaN   \n",
              "std                                                   NaN           NaN   \n",
              "min                                                   NaN           NaN   \n",
              "25%                                                   NaN           NaN   \n",
              "50%                                                   NaN           NaN   \n",
              "75%                                                   NaN           NaN   \n",
              "max                                                   NaN           NaN   \n",
              "\n",
              "        reading_time                                               text  \\\n",
              "count     208.000000                                                208   \n",
              "unique           NaN                                                208   \n",
              "top              NaN  This post was co-written with Baptiste Rocca.\\...   \n",
              "freq             NaN                                                  1   \n",
              "mean       12.375000                                                NaN   \n",
              "std        13.880224                                                NaN   \n",
              "min         2.000000                                                NaN   \n",
              "25%         6.000000                                                NaN   \n",
              "50%         9.000000                                                NaN   \n",
              "75%        13.000000                                                NaN   \n",
              "max       149.000000                                                NaN   \n",
              "\n",
              "                id  \n",
              "count   208.000000  \n",
              "unique         NaN  \n",
              "top            NaN  \n",
              "freq           NaN  \n",
              "mean    107.091346  \n",
              "std      62.575453  \n",
              "min       1.000000  \n",
              "25%      52.750000  \n",
              "50%     107.500000  \n",
              "75%     162.250000  \n",
              "max     214.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-073bef8a-169d-49ef-87eb-b0602fba7b12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>title</th>\n",
              "      <th>sub_title</th>\n",
              "      <th>author</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208</td>\n",
              "      <td>208.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>204</td>\n",
              "      <td>179</td>\n",
              "      <td>NaN</td>\n",
              "      <td>208</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "      <td>Update: This article is part of a series. Chec...</td>\n",
              "      <td>Adam Geitgey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.375000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.091346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.880224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.575453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>162.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>214.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-073bef8a-169d-49ef-87eb-b0602fba7b12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-073bef8a-169d-49ef-87eb-b0602fba7b12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-073bef8a-169d-49ef-87eb-b0602fba7b12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94dc45d3-90bb-418e-a786-2ad5db93074b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94dc45d3-90bb-418e-a786-2ad5db93074b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94dc45d3-90bb-418e-a786-2ad5db93074b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"208\",\n          \"https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205?source=tag_archive---------5-----------------------\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"208\",\n          \"Ensemble methods: bagging, boosting and stacking\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sub_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          204,\n          \"4\",\n          \"208\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          179,\n          \"5\",\n          \"208\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reading_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79.95830716817348,\n        \"min\": 2.0,\n        \"max\": 208.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.375,\n          9.0,\n          208.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"208\",\n          \"This post was co-written with Baptiste Rocca.\\n\\\"Unity is strength\\\". This old saying expresses pretty well the underlying idea that rules the very powerful \\\"ensemble methods\\\" in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle's competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model.\\nThe purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, boosting, stacking and many others that are the basis of ensemble learning. In order to make the link between all these methods as clear as possible, we will try to present them in a much broader and logical framework that, we hope, will be easier to understand and remember.\\nIn the first section of this post we will present the notions of weak and strong learners and we will introduce three main ensemble learning methods: bagging, boosting and stacking. Then, in the second section we will be focused on bagging and we will discuss notions such that bootstrapping, bagging and random forests. In the third section, we will present boosting and, in particular, its two most popular variants: adaptative boosting (adaboost) and gradient boosting. Finally in the fourth section we will give an overview of stacking.\\nEnsemble learning is a machine learning paradigm where multiple models (often called \\\"weak learners\\\") are trained to solve the same problem and combined to get better results. The main hypothesis is that when weak models are correctly combined we can obtain more accurate and/or robust models.\\nIn machine learning, no matter if we are facing a classification or a regression problem, the choice of the model is extremely important to have any chance to obtain good results. This choice can depend on many variables of the problem: quantity of data, dimensionality of the space, distribution hypothesis...\\nA low bias and a low variance, although they most often vary in opposite directions, are the two most fundamental features expected for a model. Indeed, to be able to \\\"solve\\\" a problem, we want our model to have enough degrees of freedom to resolve the underlying complexity of the data we are working with, but we also want it to have not too much degrees of freedom to avoid high variance and be more robust. This is the well known bias-variance tradeoff.\\nIn ensemble learning theory, we call weak learners (or base models) models that can be used as building blocks for designing more complex models by combining several of them. Most of the time, these basics models perform not so well by themselves either because they have a high bias (low degree of freedom models, for example) or because they have too much variance to be robust (high degree of freedom models, for example). Then, the idea of ensemble methods is to try reducing bias and/or variance of such weak learners by combining several of them together in order to create a strong learner (or ensemble model) that achieves better performances.\\nIn order to set up an ensemble learning method, we first need to select our base models to be aggregated. Most of the time (including in the well known bagging and boosting methods) a single base learning algorithm is used so that we have homogeneous weak learners that are trained in different ways. The ensemble model we obtain is then said to be \\\"homogeneous\\\". However, there also exist some methods that use different type of base learning algorithms: some heterogeneous weak learners are then combined into an \\\"heterogeneous ensembles model\\\".\\nOne important point is that our choice of weak learners should be coherent with the way we aggregate these models. If we choose base models with low bias but high variance, it should be with an aggregating method that tends to reduce variance whereas if we choose base models with low variance but high bias, it should be with an aggregating method that tends to reduce bias.\\nThis brings us to the question of how to combine these models. We can mention three major kinds of meta-algorithms that aims at combining weak learners:\\nVery roughly, we can say that bagging will mainly focus at getting an ensemble model with less variance than its components whereas boosting and stacking will mainly try to produce strong models less biased than their components (even if variance can also be reduced).\\nIn the following sections, we will present in details bagging and boosting (that are a bit more widely used than stacking and will allow us to discuss some key notions of ensemble learning) before giving a brief overview of stacking.\\nIn parallel methods we fit the different considered learners independently from each others and, so, it is possible to train them concurrently. The most famous such approach is \\\"bagging\\\" (standing for \\\"bootstrap aggregating\\\") that aims at producing an ensemble model that is more robust than the individual models composing it.\\nLet's begin by defining bootstrapping. This statistical technique consists in generating samples of size B (called bootstrap samples) from an initial dataset of size N by randomly drawing with replacement B observations.\\nUnder some assumptions, these samples have pretty good statistical properties: in first approximation, they can be seen as being drawn both directly from the true underlying (and often unknown) data distribution and independently from each others. So, they can be considered as representative and independent samples of the true data distribution (almost i.i.d. samples). The hypothesis that have to be verified to make this approximation valid are twofold. First, the size N of the initial dataset should be large enough to capture most of the complexity of the underlying distribution so that sampling from the dataset is a good approximation of sampling from the real distribution (representativity). Second, the size N of the dataset should be large enough compared to the size B of the bootstrap samples so that samples are not too much correlated (independence). Notice that in the following, we will sometimes make reference to these properties (representativity and independence) of bootstrap samples: the reader should always keep in mind that this is only an approximation.\\nBootstrap samples are often used, for example, to evaluate variance or confidence intervals of a statistical estimators. By definition, a statistical estimator is a function of some observations and, so, a random variable with variance coming from these observations. In order to estimate the variance of such an estimator, we need to evaluate it on several independent samples drawn from the distribution of interest. In most of the cases, considering truly independent samples would require too much data compared to the amount really available. We can then use bootstrapping to generate several bootstrap samples that can be considered as being \\\"almost-representative\\\" and \\\"almost-independent\\\" (almost i.i.d. samples). These bootstrap samples will allow us to approximate the variance of the estimator, by evaluating its value for each of them.\\nWhen training a model, no matter if we are dealing with a classification or a regression problem, we obtain a function that takes an input, returns an output and that is defined with respect to the training dataset. Due to the theoretical variance of the training dataset (we remind that a dataset is an observed sample coming from a true unknown underlying distribution), the fitted model is also subject to variability: if another dataset had been observed, we would have obtained a different model.\\nThe idea of bagging is then simple: we want to fit several independent models and \\\"average\\\" their predictions in order to obtain a model with a lower variance. However, we can't, in practice, fit fully independent models because it would require too much data. So, we rely on the good \\\"approximate properties\\\" of bootstrap samples (representativity and independence) to fit models that are almost independent.\\nFirst, we create multiple bootstrap samples so that each new bootstrap sample will act as another (almost) independent dataset drawn from true distribution. Then, we can fit a weak learner for each of these samples and finally aggregate them such that we kind of \\\"average\\\" their outputs and, so, obtain an ensemble model with less variance that its components. Roughly speaking, as the bootstrap samples are approximatively independent and identically distributed (i.i.d.), so are the learned base models. Then, \\\"averaging\\\" weak learners outputs do not change the expected answer but reduce its variance (just like averaging i.i.d. random variables preserve expected value but reduce variance).\\nSo, assuming that we have L bootstrap samples (approximations of L independent datasets) of size B denoted\\nwe can fit L almost independent weak learners (one on each dataset)\\nand then aggregate them into some kind of averaging process in order to get an ensemble model with a lower variance. For example, we can define our strong model such that\\nThere are several possible ways to aggregate the multiple models fitted in parallel. For a regression problem, the outputs of individual models can literally be averaged to obtain the output of the ensemble model. For classification problem the class outputted by each model can be seen as a vote and the class that receives the majority of the votes is returned by the ensemble model (this is called hard-voting). Still for a classification problem, we can also consider the probabilities of each classes returned by all the models, average these probabilities and keep the class with the highest average probability (this is called soft-voting). Averages or votes can either be simple or weighted if any relevant weights can be used.\\nFinally, we can mention that one of the big advantages of bagging is that it can be parallelised. As the different models are fitted independently from each others, intensive parallelisation techniques can be used if required.\\nLearning trees are very popular base models for ensemble methods. Strong learners composed of multiple trees can be called \\\"forests\\\". Trees that compose a forest can be chosen to be either shallow (few depths) or deep (lot of depths, if not fully grown). Shallow trees have less variance but higher bias and then will be better choice for sequential methods that we will described thereafter. Deep trees, on the other side, have low bias but high variance and, so, are relevant choices for bagging method that is mainly focused at reducing variance.\\nThe random forest approach is a bagging method where deep trees, fitted on bootstrap samples, are combined to produce an output with lower variance. However, random forests also use another trick to make the multiple fitted trees a bit less correlated with each others: when growing each tree, instead of only sampling over the observations in the dataset to generate a bootstrap sample, we also sample over features and keep only a random subset of them to build the tree.\\nSampling over features has indeed the effect that all trees do not look at the exact same information to make their decisions and, so, it reduces the correlation between the different returned outputs. Another advantage of sampling over the features is that it makes the decision making process more robust to missing data: observations (from the training dataset or not) with missing data can still be regressed or classified based on the trees that take into account only features where data are not missing. Thus, random forest algorithm combines the concepts of bagging and random feature subspace selection to create more robust models.\\nIn sequential methods the different combined weak models are no longer fitted independently from each others. The idea is to fit models iteratively such that the training of model at a given step depends on the models fitted at the previous steps. \\\"Boosting\\\" is the most famous of these approaches and it produces an ensemble model that is in general less biased than the weak learners that compose it.\\nBoosting methods work in the same spirit as bagging methods: we build a family of models that are aggregated to obtain a strong learner that performs better. However, unlike bagging that mainly aims at reducing variance, boosting is a technique that consists in fitting sequentially multiple weak learners in a very adaptative way: each model in the sequence is fitted giving more importance to observations in the dataset that were badly handled by the previous models in the sequence. Intuitively, each new model focus its efforts on the most difficult observations to fit up to now, so that we obtain, at the end of the process, a strong learner with lower bias (even if we can notice that boosting can also have the effect of reducing variance). Boosting, like bagging, can be used for regression as well as for classification problems.\\nBeing mainly focused at reducing bias, the base models that are often considered for boosting are models with low variance but high bias. For example, if we want to use trees as our base models, we will choose most of the time shallow decision trees with only a few depths. Another important reason that motivates the use of low variance but high bias models as weak learners for boosting is that these models are in general less computationally expensive to fit (few degrees of freedom when parametrised). Indeed, as computations to fit the different models can't be done in parallel (unlike bagging), it could become too expensive to fit sequentially several complex models.\\nOnce the weak learners have been chosen, we still need to define how they will be sequentially fitted (what information from previous models do we take into account when fitting current model?) and how they will be aggregated (how do we aggregate the current model to the previous ones?). We will discuss these questions in the two following subsections, describing more especially two important boosting algorithms: adaboost and gradient boosting.\\nIn a nutshell, these two meta-algorithms differ on how they create and aggregate the weak learners during the sequential process. Adaptive boosting updates the weights attached to each of the training dataset observations whereas gradient boosting updates the value of these observations. This main difference comes from the way both methods try to solve the optimisation problem of finding the best model that can be written as a weighted sum of weak learners.\\nIn adaptative boosting (often called \\\"adaboost\\\"), we try to define our ensemble model as a weighted sum of L weak learners\\nFinding the best ensemble model with this form is a difficult optimisation problem. Then, instead of trying to solve it in one single shot (finding all the coefficients and weak learners that give the best overall additive model), we make use of an iterative optimisation process that is much more tractable, even if it can lead to a sub-optimal solution. More especially, we add the weak learners one by one, looking at each iteration for the best possible pair (coefficient, weak learner) to add to the current ensemble model. In other words, we define recurrently the (s_l)'s such that\\nwhere c_l and w_l are chosen such that s_l is the model that fit the best the training data and, so, that is the best possible improvement over s_(l-1). We can then denote\\nwhere E(.) is the fitting error of the given model and e(.,.) is the loss/error function. Thus, instead of optimising \\\"globally\\\" over all the L models in the sum, we approximate the optimum by optimising \\\"locally\\\" building and adding the weak learners to the strong model one by one.\\nMore especially, when considering a binary classification, we can show that the adaboost algorithm can be re-written into a process that proceeds as follow. First, it updates the observations weights in the dataset and train a new weak learner with a special focus given to the observations misclassified by the current ensemble model. Second, it adds the weak learner to the weighted sum according to an update coefficient that expresse the performances of this weak model: the better a weak learner performs, the more it contributes to the strong learner.\\nSo, assume that we are facing a binary classification problem, with N observations in our dataset and we want to use adaboost algorithm with a given family of weak models. At the very beginning of the algorithm (first model of the sequence), all the observations have the same weights 1/N. Then, we repeat L times (for the L learners in the sequence) the following steps:\\nRepeating these steps, we have then build sequentially our L models and aggregate them into a simple linear combination weighted by coefficients expressing the performance of each learner. Notice that there exists variants of the initial adaboost algorithm such that LogitBoost (classification) or L2Boost (regression) that mainly differ by their choice of loss function.\\nIn gradient boosting, the ensemble model we try to build is also a weighted sum of weak learners\\nJust as we mentioned for adaboost, finding the optimal model under this form is too difficult and an iterative approach is required. The main difference with adaptative boosting is in the definition of the sequential optimisation process. Indeed, gradient boosting casts the problem into a gradient descent one: at each iteration we fit a weak learner to the opposite of the gradient of the current fitting error with respect to the current ensemble model. Let's try to clarify this last point. First, theoretical gradient descent process over the ensemble model can be written\\nwhere E(.) is the fitting error of the given model, c_l is a coefficient corresponding to the step size and\\nis the opposite of the gradient of the fitting error with respect to the ensemble model at step l-1. This (pretty abstract) opposite of the gradient is a function that can, in practice, only be evaluated for observations in the training dataset (for which we know inputs and outputs): these evaluations are called pseudo-residuals attached to each observations. Moreover, even if we know for the observations the values of these pseudo-residuals, we don't want to add to our ensemble model any kind of function: we only want to add a new instance of weak model. So, the natural thing to do is to fit a weak learner to the pseudo-residuals computed for each observation. Finally, the coefficient c_l is computed following a one dimensional optimisation process (line-search to obtain the best step size c_l).\\nSo, assume that we want to use gradient boosting technique with a given family of weak models. At the very beginning of the algorithm (first model of the sequence), the pseudo-residuals are set equal to the observation values. Then, we repeat L times (for the L models of the sequence) the following steps:\\nRepeating these steps, we have then build sequentially our L models and aggregate them following a gradient descent approach. Notice that, while adaptative boosting tries to solve at each iteration exactly the \\\"local\\\" optimisation problem (find the best weak learner and its coefficient to add to the strong model), gradient boosting uses instead a gradient descent approach and can more easily be adapted to large number of loss functions. Thus, gradient boosting can be considered as a generalization of adaboost to arbitrary differentiable loss functions.\\nStacking mainly differ from bagging and boosting on two points. First stacking often considers heterogeneous weak learners (different learning algorithms are combined) whereas bagging and boosting consider mainly homogeneous weak learners. Second, stacking learns to combine the base models using a meta-model whereas bagging and boosting combine weak learners following deterministic algorithms.\\nAs we already mentioned, the idea of stacking is to learn several different weak learners and combine them by training a meta-model to output predictions based on the multiple predictions returned by these weak models. So, we need to define two things in order to build our stacking model: the L learners we want to fit and the meta-model that combines them.\\nFor example, for a classification problem, we can choose as weak learners a KNN classifier, a logistic regression and a SVM, and decide to learn a neural network as meta-model. Then, the neural network will take as inputs the outputs of our three weak learners and will learn to return final predictions based on it.\\nSo, assume that we want to fit a stacking ensemble composed of L weak learners. Then we have to follow the steps thereafter:\\nIn the previous steps, we split the dataset in two folds because predictions on data that have been used for the training of the weak learners are not relevant for the training of the meta-model. Thus, an obvious drawback of this split of our dataset in two parts is that we only have half of the data to train the base models and half of the data to train the meta-model. In order to overcome this limitation, we can however follow some kind of \\\"k-fold cross-training\\\" approach (similar to what is done in k-fold cross-validation) such that all the observations can be used to train the meta-model: for any observation, the prediction of the weak learners are done with instances of these weak learners trained on the k-1 folds that do not contain the considered observation. In other words, it consists in training on k-1 fold in order to make predictions on the remaining fold and that iteratively so that to obtain predictions for observations in any folds. Doing so, we can produce relevant predictions for each observation of our dataset and then train our meta-model on all these predictions.\\nA possible extension of stacking is multi-level stacking. It consists in doing stacking with multiple layers. As an example, let's consider a 3-levels stacking. In the first level (layer), we fit the L weak learners that have been chosen. Then, in the second level, instead of fitting a single meta-model on the weak models predictions (as it was described in the previous subsection) we fit M such meta-models. Finally, in the third level we fit a last meta-model that takes as inputs the predictions returned by the M meta-models of the previous level.\\nFrom a practical point of view, notice that for each meta-model of the different levels of a multi-levels stacking ensemble model, we have to choose a learning algorithm that can be almost whatever we want (even algorithms already used at lower levels). We can also mention that adding levels can either be data expensive (if k-folds like technique is not used and, then, more data are needed) or time expensive (if k-folds like technique is used and, then, lot of models need to be fitted).\\nThe main takeaways of this post are the following:\\nIn this post we have given a basic overview of ensemble learning and, more especially, of some of the main notions of this field: bootstrapping, bagging, random forest, boosting (adaboost, gradient boosting) and stacking. Among the notions that were left aside we can mention for example the Out-Of-Bag evaluation technique for bagging or also the very popular \\\"XGBoost\\\" (that stands for eXtrem Gradient Boosting) that is a library that implements Gradient Boosting methods along with a great number of additional tricks that make learning much more efficient (and tractable for big dataset).\\nFinally, we would like to conclude by reminding that ensemble learning is about combining some base models in order to obtain an ensemble model with better performances/properties. Thus, even if bagging, boosting and stacking are the most commonly used ensemble methods, variants are possible and can be designed to better adapt to some specific problems. This mainly requires two things: fully understand the problem we are facing... and be creative!\\nThanks for reading!\\nOur last articles with Baptiste Rocca:\\ntowardsdatascience.com\\ntowardsdatascience.com\\n\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75.98668586080221,\n        \"min\": 1.0,\n        \"max\": 214.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          107.09134615384616,\n          107.5,\n          208.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of reading times in our corpus\n",
        "fig, axes = plt.subplots(figsize = (8, 6))\n",
        "#creating histograms\n",
        "sns.histplot(df['reading_time'], kde=True, ax = axes)\n",
        "#Computing percentile of the reading_time data\n",
        "first_q = np.percentile(df['reading_time'], 25)\n",
        "second_q = np.percentile(df['reading_time'], 50)\n",
        "third_q = np.percentile(df['reading_time'], 75)\n",
        "#green lines for 25th and 75th percentile\n",
        "plt.axvline(first_q, color=\"green\")\n",
        "plt.axvline(third_q, color=\"green\")\n",
        "#red line for median reading_time\n",
        "plt.axvline(second_q, color=\"red\")\n",
        "#plot title\n",
        "plt.suptitle(\"Distribution of reading time across articles\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "-DY4LVxHl9VD",
        "outputId": "fb12cd87-36ff-4cc1-da33-500541548830"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAJSCAYAAAAoH7bLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5HUlEQVR4nO3dd3wUdf7H8ffsppdNqAESuiZ0A1IFURHxKIpdzhM9G1iwoHcKnqjYvZ8dlBMsB3qW85TTE8QTRDwVAVFEikgndAjpPbvz+yPskk02ZcMmu9m8no+Hspn57sxnP9kk70y+M2OYpmkKAAAACBIWfxcAAAAA+BIBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcBb+LEiUpJSfHb/qdNm6aUlBTt3bvXtWzv3r1KSUnRtGnT/FaX5P/e+MquXbt02223aejQoUpJSVH//v39XdJJWbVqlVJSUjRr1iy35Y3x8zVr1iylpKRo1apV/i4FjcxHH32klJQUffTRR3XexogRIzRixAgfVoWmgoCLBpGSkuL2X69evTR48GBdfPHF+stf/qIVK1bIbrfXy74b8zdIT+E62Njtdt12221asWKFzj77bE2ZMkWTJk3yd1lNhi9CCJqmqn6RAwJBiL8LQNMyZcoUSWWhJicnR1u3btXHH3+sf/3rX+rVq5eeeeYZde7c2e05Tz/9tAoKCvxRriTp7rvv1k033aSEhAS/1VAVf/fGF/bu3att27bpiiuu0KOPPurvcupVY/x8/eEPf9CYMWPUrl07f5eCRua8887TaaedptatW/u7FDRBBFw0qNtvv73SsqNHj+rRRx/VkiVLdN111+nDDz9UixYtXOv9/YO1devWAfsN2t+98YXDhw9LUsD22Jca4+erefPmat68ub/LQCMUGxur2NhYf5eBJoopCvC7li1b6vnnn9fAgQN14MAB/e1vf3Nb72neommaWrhwoSZMmKDBgwerd+/eOuuss3TDDTdo8eLFkk78+Wzfvn3at2+f2xSJ8nNnU1JSNHHiRB05ckR/+ctfdOaZZ6p79+6uP9nWNE1g+/btuvXWWzVw4EClpqbq97//vb755ptK46qby+hpTm9KSooWLlwoSTr33HNdtZefblHVnE6Hw6F3331Xl156qfr27avU1FRdeumleuedd+RwOCqNd/bg2LFjmjFjhoYNG6ZevXpp7Nix+vDDDz2+7ups2LBBt99+u4YMGaJevXrpnHPO0cMPP+wKs+X3e/XVV0uSZs+e7XqNNf3Js3y/du7cqbvuuktDhgxRt27d3Pr7v//9TzfddJMGDRqkXr16aeTIkXr66aeVnZ1daZvff/+9ZsyYoTFjxqhfv37q06ePxo0bp9mzZ6uoqMhjHUePHtX999+vM844Q3369NH48eNdnzNPPH2+yv+Zd/PmzZo0aZL69++v0047TVdffbV+/PFHj9s6fPiwpk+friFDhrjt25s/G0+cOFHTp0+XJE2fPt3ta8T5fq/qfet8zxw9elTTp0/XGWecodTUVE2YMEE//PCDJCk/P19PP/20zjnnHNf76bPPPquynk8//VQTJ05U//791bt3b40ePVqvvPKKiouLa3wtTjt37tQzzzyjSy65RIMHD3a9/2bMmKGDBw9W+bxvvvlGN998s+s9e9ZZZ+mWW27Rd9995xpTvrfr16/XpEmTNHDgQLd+FRcXa+7cubrgggt02mmnqV+/frrqqqtc35cqWrZsma699lrX19ywYcN09dVX6x//+IfbuLS0NM2YMUPnnXee+vTpo4EDB+qCCy7Qgw8+qIyMjFr1ZunSpfrTn/6k888/X6mpqUpNTdUll1yiBQsWePy+4Pzel5aWprfeeksXXHCB+vTpo4kTJ2ratGm65pprJLl/7ZZ/r1Q3/eXgwYN67LHHNGrUKNfrueyyy/Tyyy/X6rVI3r1ffvjhB918880aPny4evXqpaFDh+qKK67Q7Nmza70/NC4cwUVAsFgsuvXWW7V69WotWrRI999/vwzDqHL8888/r1dffVVJSUkaPXq0YmNjdeTIEf3yyy9asmSJxowZo8TERE2ZMkXz58+XJF177bWu53fv3t1te5mZmbryyisVFRWlUaNGyTAMt6PIVdm7d68mTJig5ORkXXnllTpy5IgWL16sm266Sc8++6zGjBlTx46UTedYunSpfv31V11zzTWy2WySVKsjIn/+85/16aefqm3btrrssstkGIaWLl2qmTNnau3atXr22WcrPSc7O1u///3vFRYWpvPPP1/FxcVasmSJ7r//flksFl188cW1qnv58uWuI/Xnn3++2rVrp40bN+rdd9/VsmXL9M4776h9+/au17hv3z4tXLhQAwcO1MCBAyXJ9W9N9uzZoyuuuEKdOnXSBRdcoMLCQsXExEgq+6E7a9YsxcfH6+yzz1bz5s3122+/6Y033tDXX3+t999/3zVWkubNm6edO3eqb9++Ouuss1RcXKwff/xRs2bN0qpVq/T3v/9dVqvVNf7YsWOaMGGC0tLSdPrpp+v000/XkSNH9NBDD2no0KG1qr+8DRs26LXXXlNqaqouv/xy7d+/X//973/1xz/+Uf/+97/VpUsX19j09HRNmDBB+/bt04ABA9S3b18dPXpUM2fO9GrfF198sWJjY7Vs2TKde+65bl8XzvdbdZzvmejoaI0dO1ZZWVlavHixbrjhBr3//vt68MEHlZWVpbPPPlulpaX69NNPNXXqVLVt21apqalu25o+fbo++ugjtWnTRqNGjZLNZtO6dev04osvauXKlXrzzTcVElLzj6wvvvhC7733ngYNGqR+/fopNDRUW7du1QcffKDly5frww8/rDTd6KWXXtLLL7+sqKgojRw5Um3bttXhw4f1008/6ZNPPtEZZ5zhNn7dunV69dVXdfrpp+vSSy9VRkaGQkNDVVxcrBtuuEGrV69Wly5ddNVVV6mwsFCff/65pk6dql9//VV33323azvOHrVq1UrnnHOOmjVrpvT0dG3ZskUfffSR/vCHP0gq+2XmsssuU25uroYPH65Ro0apqKhIe/fu1SeffKKrr75azZo1q7E3zzzzjCwWi/r06aOEhATl5OTo+++/1+OPP65ffvlF//d//+fxeY8//rh++OEHnXXWWTrrrLNktVrVu3dvSar0tStJiYmJ1dbxyy+/6MYbb1RmZqYGDBig8847T4WFhdq2bZtmz56t2267rcbX4s375euvv9bkyZMVExOjESNGKCEhQZmZmdqxY4feeecd19Q5BBkTaADJyclmcnJytWOKiorMHj16mMnJyeaePXtcy6+++upKzx04cKB55plnmvn5+ZW2k56e7vbxOeecY55zzjk11vbnP//ZLCkpqbT+vvvuM5OTk820tDTXsrS0NNfznnrqKbfx69evN3v06GH279/fzMnJcS1/6aWXzOTkZPP777+vtA/n9u67774a912ep9785z//MZOTk82LLrrIzM3NdS3Py8szL774YjM5Odn85JNPPPbg/vvvN0tLS13Lt27danbv3t0cPXq0x/1XlJubaw4cONDs1q2buWbNGrd1r776qpmcnGxed911bsu///57Mzk52XzppZdqtQ/TdO//s88+W2n9ypUrzeTkZPPKK680s7Ky3NZ9+OGHZnJysvn444+7Ld+zZ4/pcDgqbev55583k5OTzUWLFrktf+CBBzxux/n59/SaPH2+nK8/OTnZ/PDDD93Wvfvuu2ZycrL50EMPuS2fPn26mZycbP71r391W75582azZ8+eXvXT2Y+K+3aq6n3rrHnGjBmm3W53LV+4cKGZnJxsDhgwwJw8ebJZWFjoWrdmzRozOTnZvPXWWz3WcNttt5kFBQUe9//3v/+9Vq/n4MGDZlFRUaXl//vf/8xu3bqZDz74YKXlycnJ5ogRI8yDBw9Wet6BAwdcj8t/rt59991KY//2t7+ZycnJ5o033uj2veTo0aPmOeecYyYnJ5tr1651Lb/44ovNnj17mkePHq20rfLfxxYsWFBlD/Ly8ir1rCq7d++utMxut5v33nuvmZycbK5bt85tnfP7z7Bhw9y+JzvV9LXr6b1VVFTk6kXF70Om6d5v0/T8/dvb98uUKVPM5ORkc/PmzZX2V/HnBYIHUxQQMMLCwhQfHy9JtfqTW0hIiNsRNae6zBcMDQ3VfffdV6sjROXFxsZWOtrQu3dvXXDBBcrOztYXX3zhdS0nyzml4J577lF0dLRreVRUlP785z9Lkj744INKz4uMjNT06dPdenrKKaeoX79+2r59u/Ly8mrc97Jly5SZmakxY8ZUutTX9ddfr8TERH377bfav39/nV5bRS1btvR49OWtt96SJD366KOVjkRecskl6t69u/7zn/+4LW/fvr3Hvxr88Y9/lFQ23cGppKRE//nPfxQdHV1pXrnz8++tfv366ZJLLnFbdumllyokJETr1693LSsuLtaiRYsUGxurW265xW18t27ddNFFF3m977qKjIzUvffeK4vlxI+SCy64QCEhIcrKytJf/vIXhYeHu9b1799fiYmJ2rx5s9t2FixYoJCQED3xxBOKiIhwW3frrbcqPj6+0uerKgkJCQoLC6u0fNiwYTrllFMqTR96++23JZX9Od7TiaRt2rSptKx79+6aMGFCpeUffvihDMPQtGnT3L6XtGjRwvW5qvi1FxIS4vH7jqfvYxV7I5V9XXta7kmHDh0qLbNYLK6pBuXf4+XdeOONrr+6nKzly5dr3759GjFihMevE0/9rqiu75fy70Un5pcHL6YoIKCYplmrcRdccIHeeustjRkzRqNHj3b9mbauJzQkJibWakpCRT169HD7M7fTwIEDtXDhQm3atKnWf9r3lU2bNslisXj8M/+AAQNktVorBQxJ6tixo8fX4vyBk52d7RaYq9q3JA0ePLjSupCQEA0YMED79u3Tpk2bfHLCVbdu3TyGmXXr1ik0NFRLlizRkiVLKq0vKSnRsWPHlJGR4frTbn5+vhYsWKAvvvhCu3btUl5entv7sfz84R07dqigoED9+/f3+J5zfv690atXr0rLQkND1aJFC7c5wzt37lRhYaF69erl8fN1+umne/wFpj506tSpUg1Wq1UtWrRQQUGBx1CUkJDgFtgLCgr066+/qlmzZq7pRBWFhYVp+/bttarJNE198sknWrhwoX799VdlZ2e7XYIwNDTUbfy6detkGIbOPPPMWm1fkvr06VNpWW5urnbv3q2EhAR17dq10nrn10T5r70LLrhATz31lMaOHasxY8Zo4MCB6tevX6XQNWLECD333HN65JFH9M0332jYsGHq16+fTjnllGqnclWUkZGh119/XStWrNDevXuVn5/vtr7iHPnqXm9drVu3TpI0fPjwOj2/Lu+XCy64QP/97391xRVXaPTo0Ro8eLD69etXqzCNxouAi4BRVFSkrKwsSTX/Vj19+nQlJSXpo48+0ty5czV37lyFhIRo+PDhmjZtmjp27OjVvlu1alWnmlu2bFnt8tzc3Dpt92Tk5OQoLi7OY/ALCQlxzfOrqKo5l86jS7W5TnFOTo6kqvvpXO4cd7Kq6n9mZqZKS0trPIEkPz9fzZo1U0lJia699lqtX79eycnJGjNmjJo3b+567bNnz3Y7ccVZf1W/FFVVV3Wq63/5E4Bq2nddflGrq6p+oQwJCal2XWlpqevj7OxsmaapY8eO+eSEnyeffFLz589Xq1atNGzYMCUkJLiO8i1cuFD79u1zG+/8eqntUVDJ8+fX+bVe1XvfeZWQ8r+sXHfddWrWrJneeecdvfXWW5o/f74Mw9CAAQN07733uua5JiYm6l//+pdmzZql//3vf/rvf/8rSWrbtq2uv/561xHY6mRnZ+uyyy7T3r17XSclxsXFKSQkRNnZ2VqwYEGVJ/PV5f1cFef7t66XXazL+2XUqFF69dVX9cYbb+ijjz7S+++/L0nq2bOn7rnnnjrNmUfgI+AiYKxdu1alpaVq2bKlkpKSqh1rtVr1xz/+UX/84x+Vnp6utWvXatGiRVqyZIm2bdumRYsWeQx4VfHmKEh5R48erXZ5+aNbzn14Coq+CnxSWejIyspSSUlJpaNVpaWlysjI8Hjkz1f7lqQjR454XO9c7qtLB1X1eYuJiZFpmlq9enWttrNs2TKtX79el1xyiZ588km3dYcPH670g9RZv6dfFKSq3xe+4PzcVbXvqpYHKufr6dGjh9dHvStKT0/XW2+9peTkZL377ruV3ueffvpppefExsYqMzNThYWFtQ65nt53zn1V9bl3Hh2t+N6/6KKLdNFFFyk7O1s//fSTvvjiC3344Ye68cYb9dlnn7l+2e/atateeOEFlZaW6tdff9V3332nt99+W48//rgiIyN1+eWXV1vzBx98oL1792rKlCmVptX89NNPWrBggVevt66cr//QoUN1en5d3y9nn322zj77bOXn5+vnn3/WV199pXfffVeTJ0/Wv//9b51yyil1qgeBizm4CAgOh0Nz5syRJI0bN86r57Zo0UKjRo3Siy++qMGDB2vPnj367bffXOstFku93SVt06ZNHo/SOoNVjx49XMvi4uIkSQcOHKg0fsOGDR6375zb6OkSPlXp3r27HA6H61JN5a1Zs0Z2u92tLl9ynoXvKViWlpa6aqqv/TulpqYqKytLW7durdX4PXv2SCq7MH1Fa9asqbSsS5cuioyM1ObNmz3+clLbYF0XXbp0UUREhLZs2eLxvbd27Vqvtud8j9XX10hNoqOjdeqpp2rr1q3KzMw8qW2lpaXJ4XBo6NChlcLtwYMHPV7qLzU1VaZpVjn/tLZiYmLUoUMHHTp0SLt27aq03nnprKre+zabTWeddZYee+wxXXzxxcrMzPT43gsJCVGvXr00adIkPffcc5LKfkGrye7duyWVHc2syNN+asM5X9+b947z6hlff/11nfZ5su+XqKgoDRkyRNOnT9fkyZNVUlJS51oQ2Ai48Lv09HRNnTpVq1evVrt27TR58uRqxxcXF3v8IV5SUuKa4hAZGelaHh8fr2PHjqmwsNC3havsyGvF6zb+8ssv+s9//qPY2Fi3wOScx/bRRx+5/Yn2wIEDVV770XnSnTcnZV166aWSpGeffdbtrlkFBQWuy4Nddtlltd6eN0aOHKn4+HgtWrTINdfOaf78+dq7d6/OOOOMer/hgfPEsBkzZng8UpSfn+9Wn/OyRhWDaVpamp555plKzw8NDdUFF1ygvLy8StebdX7+60tYWJjGjBmjnJwc1y+FTr/++qv+/e9/e7U95xxkT794NZQ//vGPKikp0f333+/xGsVZWVnauHFjjdtxfh7Xrl3rFrry8vL0wAMPuH3dOTmvw/zUU095fK94c6Tx0ksvlWma+utf/+q2/2PHjumVV15xjXH6/vvvPZ53cOzYMUknTirbsGGDx1+knEeLa3Pk2flXsYrv8U2bNunVV1+t8fmeOL8/efPeOeecc5SYmKgvv/zS4xH16q5V7OTt+2XNmjUeP/fOv3Z4Mz0FjQdTFNCgnGHA4XC4btW7du1alZSUqE+fPnrmmWdqnH9bWFioq666Sh07dlTPnj3Vrl07FRUV6bvvvtP27ds1YsQIt5M8hgwZ4rruYv/+/RUWFqZu3bq53TChrgYMGKB//etfWr9+vfr16+e6Dq7D4dAjjzzidhTptNNO04ABA7RmzRpdfvnlGjx4sI4eParly5dr2LBhHn9IDBkyRK+//rpmzJihUaNGKTo6WjabzfVD2ZMLLrhAy5Yt02effaaxY8dq5MiRruvg7t27V2PGjNGFF1540q/dk+joaD3++OO66667dPXVV+t3v/ud6zq433zzjVq1aqVHHnmkXvZd3pAhQ3TPPffoueee0/nnn6/hw4crKSlJ+fn52r9/v9asWaN+/frp9ddfl1T2Q7djx45688039dtvv6l79+46cOCAli9frrPPPtvjLxhTp07VypUrNX/+fG3YsMF1HdzFixdr+PDh+vLLL+vt9d1zzz36/vvv9dprr2n9+vXq27evjhw5os8++0xnnXWWli5dWus/K6empioyMlLz589XZmama77lxIkTG+wuVJdddpk2btyod955R+edd56GDRumtm3bKisrS3v37tWaNWt0ySWX1PjeadWqlcaOHatFixbpoosu0tChQ5WTk6PvvvtOYWFh6t69e6UTLIcNG6ZbbrlFc+bM0ejRo13XwT169KjWrl2r1NRUPfXUU7V6Hddff72+/vprLVu2TOPHj9fw4cNVWFioJUuWKD093fU9yGnKlCmKiopSamqqEhMTZZqmfvjhB/3yyy/q2bOn6/q7H3/8sd5//32dfvrpat++veLi4rRnzx4tX75cYWFhbtf4rsr48eP1+uuv64knntCqVavUsWNH7d69W1999ZXOO++8Km9EUZ3OnTsrISFBixYtUkhIiNq1ayfDMDR+/Pgqr4UbFhamF198UTfccIPuuecevf/++zrttNNUVFSkHTt2aOXKla6TVavi7fvlscce06FDh9SvXz8lJiYqNDRUGzdu1Pfff6/ExESNHTvW69eOwEfARYNyzmUMDQ1VdHS0EhMTddFFF2nUqFEaNmyY2+WGqhIZGak//elPWrVqlX766SctXbpU0dHR6tChgx5++GG3IySSdMsttyg7O1vLly/Xjz/+KLvdrosvvtgnATcpKUkzZ87UM888o/fee0/FxcXq0aOHbrvtNo9nZb/yyiv661//qmXLlumtt95Sp06d9Oc//1lDhw71eIenM888U9OmTdM///lPzZ8/XyUlJUpMTKw24ErSc889pwEDBujDDz90nVDRtWtXXX/99fr9739/0q+7OiNHjtQ777yjV199Vd98841yc3PVsmVLTZgwQbfeemudTy7x1qRJk9SvXz+99dZbWrt2rb788kvFxMQoISFBV1xxhdtUmKioKM2fP1/PPPOMVq9erR9++EHt27fXrbfequuuu87jD//mzZvr3Xff1XPPPafly5drw4YN6ty5sx5++GHXEar60rJlS7333nt67rnntGLFCv3888/q3LmzHnroIUVGRmrp0qW1nmcdFxfnutHBwoULXWfWX3jhhQ16m9WHHnpIw4cP13vvvafvvvvOdfJX27ZtdcMNN9T6l7LHH39c7du31+LFi/WPf/xDzZs314gRI3THHXfojjvu8Picu+66S3379tWCBQv01VdfKT8/Xy1atFCvXr00fvz4Wr+GsLAwvfnmm3rzzTf16aef6u2335bValW3bt10//33V5p+dc899+ibb77Rxo0btWLFCoWHh6tdu3b605/+pN///veuOfTjxo1TcXGxfvrpJ23cuFGFhYVKSEjQ2LFjdd111yk5ObnG2hISEvSPf/xDzzzzjNauXatvvvlGXbp00UMPPaQhQ4bUKeBarVbNnj1bzz77rJYsWeK68sjpp59e7c0eevfurX//+9+aO3euvv76a/3000+u7+FVfY4q8ub9MnnyZC1dulQbNmzQypUrZRiG2rVrp5tvvlnXXnuta/oYgoth1va6TACAgPf888/rb3/7m1577TWvLn0FAMGEObgA0Ah5mhu6ZcsWLViwQPHx8bW+3TEABCOmKABAI3TppZeqY8eOOvXUUxUZGandu3drxYoVrvnfnu7aBABNBVMUAKARmj17tpYuXap9+/YpLy9PsbGxSk1N1fXXX69Bgwb5uzwA8CsCLgAAAIIKc3ABAAAQVAi4AAAACCoEXAAAAAQVAi4AAACCCgEXAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFQIuAAAAAgqBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCoEHABAAAQVAi4AAAACCoEXAAAAAQVAi4AAACCCgEXAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFQIuAAAAAgqBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKiE+LuAQGGaphwO06fbtFgMn2/TYTqUlrNHktQ+toMsRjW/ozgcsqaVjbW37yBZav/7jFf78ZH66Fewo2feo2feoV/eo2feo2feaar9slgMGYZRq7EE3OMcDlPHjuX5bHshIRY1axat7Ox8lZY6fLbdvJI8dZ3XVZK086YDig6NrmZwnlp1LRt7bOcBKbqasSezHx+or34FM3rmPXrmHfrlPXrmPXrmnabcr+bNo2W11i7gMkUBAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFQIuAAAAAgqBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCohPi7ADQMW1ykFB1Z5XqHw1RuTmEDVgQAAFA/CLhNxDufbVZpRNUB95pxPRuwGgAAgPrDFAUAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKtzooZGLiY2QxWJ4XhniaNhiAAAAAgABt5GzWAwt+HSjx3UhhQW6roHrAQAA8DemKAAAACCoEHABAAAQVAi4AAAACCoBG3Dz8vI0fPhwpaSk6JdffnFb98EHH+j8889X7969deGFF2r58uV+qhIAAACBJmAD7iuvvCK73V5p+aJFizRjxgyNHj1a8+bNU2pqqqZMmaJ169Y1fJEAAAAIOAEZcLdv36533nlHt99+e6V1L730ksaOHau77rpLgwcP1iOPPKLevXvr5Zdf9kOlAAAACDQBGXAfe+wxTZgwQZ07d3ZbnpaWpl27dmn06NFuy8eMGaOVK1equLi4IcsEAABAAAq4gLtkyRL99ttvuu222yqt27FjhyRVCr5du3ZVSUmJ0tLSGqRGAAAABK6AutFDQUGBnnrqKU2dOlUxMTGV1mdlZUmSbDab23Lnx871dRUS4ru8b7Va3P71lRDzxPZCQiwyDKPKO5lZLO6Pq7zjmSTDMNxef8X9+LI3ntRXv4IZPfMePfMO/fIePfMePfMO/aqdgAq4c+bMUYsWLXTppZc2+L4tFkPNmkX7fLs2W6RPtxdWbhZGs/hoGYYUGRnmcazVKHU9jogMkz3C8zhJMgy5vf6K+4kO831vPPF1v5oCeuY9euYd+uU9euY9euYd+lW9gAm4+/bt0xtvvKGXX35ZOTk5kqT8/HzXv3l5eYqLi5Mk5eTkqFWrVq7nZmdnS5JrfV04HKays/Pr/PyKrFaLbLZIZWcXyG53+Gy7eSV5rscZmXlq3SxCBQWe5x6HFJ5YXlhQrFKz6k+3aUoZGSe2XXE/xaEnU3XN6qtfwYyeeY+eeYd+eY+eeY+eeacp98tmi6z1keuACbh79+5VSUmJJk2aVGndNddco9NOO03PPvuspLK5uF26dHGt37Fjh0JDQ9W+ffuTqqG01PdvFLvd4dPtlt9WaalDpmnK4TA9jnU43B9XNU6STNOstO3yj0uNhvki8nW/mgJ65j165h365T165j165h36Vb2ACbjdu3fXggUL3JZt3rxZTz75pGbOnKnevXurffv26tSpk5YsWaKRI0e6xi1evFhDhgxRWFjVf4IHAABA0xAwAddms2nQoEEe1/Xs2VM9e/aUJN1+++3605/+pA4dOmjQoEFavHix1q9fr7fffrshywUAAECACpiAW1vjxo1TQUGB5s2bp7lz56pz586aPXu2+vbt6+/SAAAAEAACOuAOGjRIW7ZsqbT88ssv1+WXX+6HigAAABDouIgaAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCoEHABAAAQVAi4AAAACCoEXAAAAAQVAi4AAACCCgEXAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFQIuAAAAAgqBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoBLi7wJQtZjYCFkshtsya7HD9dhmi5RhGBWfBgAA0KQRcAOYxWJowacb3ZYVOQpcj99ZslmTxg9o6LIAAAACGlMUAAAAEFQIuAAAAAgqATVFYcWKFZo3b562bdum3NxcJSQkaOTIkZoyZYpiY2MlSdOmTdPChQsrPXfevHkaPnx4Q5cMAACAABNQATczM1N9+vTRxIkTFR8fr61bt2rWrFnaunWr3njjDde49u3b65lnnnF7bteuXRu6XAAAAASggAq448ePd/t40KBBCgsL04wZM3To0CElJCRIkiIiIpSamuqHCgEAABDoAn4Obnx8vCSppKTEv4UAAACgUQjIgGu321VUVKSNGzfq5Zdf1ogRI5SUlORav3v3bp1++unq1auXLrnkEi1dutSP1QIAACCQBNQUBadzzjlHhw4dkiSdeeaZevbZZ13runfvrt69e+uUU05RTk6O3n33Xd1222168cUX9bvf/e6k9hsS4ru8b7Va3P6tC8MwKt3owWKWe3x8VcUxrvUW98dVjXPuq/zrDzHLPQ6x+LQ3nviiX00NPfMePfMO/fIePfMePfMO/aqdgAy4c+fOVUFBgbZt26Y5c+bo5ptv1ptvvimr1aprr73WbeyIESM0YcIEvfTSSycVcC0WQ82aRZ9s6ZXYbJF1fm5JqV2RkWFuywx7qetxRGSYDEOVxjhZDfex9gjP4yTJMOT2+sOKT6xrFh+t6DDf98aTk+lXU0XPvEfPvEO/vEfPvEfPvEO/qheQAbdbt26SpL59+6p3794aP368vvjiC48B1mKxaNSoUfq///s/FRYWKiIiok77dDhMZWfnn1Td5VmtFtlskcrOLpDd7qj5CR5Ex0SooKDYbVmR/cTHhQXFMk1VGuMUUug+ttSs+tNtmlJGRp7r47ySE48zMvNUHOp1+V7xRb+aGnrmPXrmHfrlPXrmPXrmnabcL5ststZHrgMy4JaXkpKi0NBQ7dmzp973VVrq+zeK3e6o83ZN05TDYbotK/+h83HFMa71DvfHVY1z7qt8nRUflxoN80V0Mv1qquiZ9+iZd+iX9+iZ9+iZd+hX9QJ+AsfPP/+skpISt5PMynM4HFqyZIlOPfXUOh+9BQAAQPAIqCO4U6ZMUa9evZSSkqKIiAj9+uuvev3115WSkqKRI0dq3759mjZtmsaOHauOHTsqKytL7777rjZs2KBZs2b5u3wAAAAEgIAKuH369NHixYs1d+5cmaapxMREXX755brhhhsUFham6OhoxcTEaM6cOUpPT1doaKh69eqlefPm6cwzz/R3+QAAAAgAARVwJ02apEmTJlW5Pj4+XnPmzGnAigAAANDYBPwcXAAAAMAbBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCoEHABAAAQVAi4AAAACCoEXAAAAAQVAi4AAACCCgEXAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFQIuAAAAAgqBFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCoEHABAAAQVAIq4K5YsUJXX321Bg8erF69euncc8/Vk08+qZycHLdxX375pS688EL17t1b559/vj788EM/VQwAAIBAE+LvAsrLzMxUnz59NHHiRMXHx2vr1q2aNWuWtm7dqjfeeEOS9MMPP2jKlCm67LLLdP/99+v777/XX/7yF0VHR+t3v/udn18BAAAA/C2gAu748ePdPh40aJDCwsI0Y8YMHTp0SAkJCZozZ4769OmjRx55RJI0ePBgpaWl6aWXXiLgAgAAILCmKHgSHx8vSSopKVFxcbFWrVpVKciOGTNG27dv1969e/1QIQAAAAJJQAZcu92uoqIibdy4US+//LJGjBihpKQk7dmzRyUlJerSpYvb+K5du0qSduzY4Y9yAQAAEEACaoqC0znnnKNDhw5Jks4880w9++yzkqSsrCxJks1mcxvv/Ni5vq5CQnyX961Wi9u/dWEYhiwWw22ZxSz3+PiqimNc6y3uj6sa59xX+dcfYpZ7HGLxaW888UW/mhp65j165h365T165j165h36VTsBGXDnzp2rgoICbdu2TXPmzNHNN9+sN998s173abEYatYs2ufbtdki6/zcklK7IiPD3JYZ9lLX44jIMBmGKo1xshruY+0RnsdJkmHI7fWHFZ9Y1yw+WtFhvu+NJyfTr6aKnnmPnnmHfnmPnnmPnnmHflUvIANut27dJEl9+/ZV7969NX78eH3xxRc65ZRTJKnSZcOys7MlSXFxcXXep8NhKjs7v87Pr8hqtchmi1R2doHsdkedthEdE6GCgmK3ZUX2Ex8XFhTLNFVpjFNIofvYUrPqT7dpShkZea6P80pOPM7IzFNxqNfle8UX/Wpq6Jn36Jl36Jf36Jn36Jl3mnK/bLbIWh+5DsiAW15KSopCQ0O1Z88ejRgxQqGhodqxY4fOPPNM1xjn3NuKc3O9VVrq+zeK3e6o83ZN05TDYbotK/+h83HFMa71DvfHVY1z7qt8nRUflxoN80V0Mv1qquiZ9+iZd+iX9+iZ9+iZd+hX9QJ+AsfPP/+skpISJSUlKSwsTIMGDdLnn3/uNmbx4sXq2rWrkpKS/FQlAAAAAkVAHcGdMmWKevXqpZSUFEVEROjXX3/V66+/rpSUFI0cOVKSdMstt+iaa67Rww8/rNGjR2vVqlX69NNP9fzzz/u5egAAAASCgAq4ffr00eLFizV37lyZpqnExERdfvnluuGGGxQWVnaCVP/+/TVr1iy98MIL+te//qV27drpscce0+jRo/1cPQAAAAJBQAXcSZMmadKkSTWOO/fcc3Xuuec2QEUAAABobAJ+Di4AAADgDQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAABBhYALAACAoELABQAAQFAh4AIAACCoEHABAAAQVAi4AAAACCoE3CBjmqZM0/R3GQAAAH4T4u8C4Du5BSVatemQJKl7p2ZqH2X4uSIAAICGR8ANEll5xVq58aCKSxySpB9+PaL9kdL1fq4LAACgoTFFIQgcyynUd7+Uhdu46DCdmhQniyGlZxf6uzQAAIAGxxHcRq7U7tAPvx5Rid2h5rHhGtSjtUJDrOqYEKPVP+z0d3kAAAANjoDbyK3ZdFCFxXaFh1o1uGeCQqxlB+WjIkLVpZ3NNc7h4MQzAADQNDBFoZH7fNUeSVKHhBhXuHXqkBDrerzvaG6D1gUAAOAvBNxGLLegRL9sOypJ6pgQU2l9+cC7fV+2HFw+DAAANAEE3EYs7XCOJKl1s0hFRYRWOzavqFT7juQ1RFkAAAB+RcBtxPYeLgusncpNRajO7kM59VkOAABAQCDgNmLFpQ41t0WodfPIWo0/ll2k4hJ7PVcFAADgXwTcRu68gR1kMWq+Y1lsZNkUhkMZBfVdEgAAgF8RcBu5wb3b1mpcQrOyo7yHjuXXZzkAAAB+R8BtxMJCLWrfuvLVEzxJaB4lSTqcWcA1cQEAQFAj4DZiLWLDZdRieoIkxUWHKTzUolK7yS18AQBAUCPgNmIt4iJqPdYwDCU0KzuKe5BpCgAAIIgRcBsZu8PhetzCVrurJzglNHfOwy2QyU0fAABAkCLgNjKZ2UWux9GRIV49t1V8pCyGlF9Uqpz8El+XBgAAEBAIuI1M+fmztZ1/6xRitahl/PGjuFwuDAAABCkCbiNzNKeo5kHVaHV83u4xTjQDAABBioDbiJTaHco8yYDb3FYWcDNyipiHCwAAghIBtxE5llOkk82kcdFhshhlt/nNKyj1TWEAAAABhIDbiKRnnfy0AovFUHxsuCTpWA7TFAAAQPDx7jT8evbZZ5/pk08+0caNG5Wdna2OHTtq4sSJuvTSS10nVE2cOFGrV6+u9NzFixera9euDV1yg8rMPbnpCU7NY8N1LLtIx3KK1CEh1ifbBAAACBQBFXD//ve/KzExUdOmTVOzZs303XffacaMGTp48KCmTJniGtevXz/dd999bs9NSkpq6HIblGmaysor9sm2msVGSMpWRrZvAjMAAEAgCaiAO2fOHDVv3tz18ZAhQ5SZmak333xTt956qyyWshkVNptNqampfqrSP4qK7SoucdQ8sBaa28qmKOQUlKi41K6wEKtPtgsAABAIAmoObvlw69S9e3fl5uYqP79p317WefQ2NjL0pLcVHmpVdETZ7zYZJ3lVBgAAgEATUAHXk7Vr1yohIUExMTGuZatXr1Zqaqp69+6tq6++WmvWrPFjhQ3DFXCjTj7gSieO4jJNAQAABJuAmqJQ0Q8//KDFixe7zbcdMGCAxo8fr06dOunw4cN6/fXXdd111+mtt95S3759T2p/ISG+y/tWq8Xt37owDEMWS9nJddnHA25cbLh0rGz98VWuMRVZLO6Py49rYYtQ2uE8HcspksViyDAMt9cfYpZ7HGLxaW888UW/mhp65j165h365T165j165h36VTsBG3APHjyoqVOnatCgQbrmmmtcy++44w63cWeffbbGjRunV155RfPmzavz/iwWQ82aRdf5+VWx2SLr/NySUrsiI8MkSdn5JZKkVs2iXAE3IjJMhiHXmIqsxonr3EZEhskecWJc21axWrctXZm5RQoPD5VhyO31h5U7n61ZfLSiw3zfG09Opl9NFT3zHj3zDv3yHj3zHj3zDv2qXkAG3OzsbN10002Kj4/XrFmzXCeXeRIVFaWzzjpLn3/++Unt0+EwlZ3tu3m+VqtFNluksrMLZLfX7eSw6JgIFRQUq6TUodyCsoAbGXqiF4UFxTJNqaDA89UVQgqL3caWmic+3WFWKcRqqNRu6lB6rkxTysjIc63PKznxOCMzT8W+mRlRJV/0q6mhZ96jZ96hX96jZ96jZ95pyv2y2SJrfeQ64AJuYWGhJk+erJycHL3//vuKjW2467SWlvr+jWK3O+q8XdM05XCYrtvzRoZZFVLuE+s4flczh8Pz7c0cDvfHFcc1iw3XkcxCHcsqlGmabnVWfFxqNMwX0cn0q6miZ96jZ96hX96jZ96jZ96hX9ULqAkcpaWluuuuu7Rjxw699tprSkhIqPE5+fn5+uqrr9S7d+8GqNA/nCeY2aI9T0Woq7jj2/PV9XUBAAACQUAdwZ05c6aWL1+uadOmKTc3V+vWrXOt69Gjh9avX6/XXntN5513nhITE3X48GG9+eabOnLkiF588UX/FV7PnAE0LoaACwAAUJOACrjffvutJOmpp56qtG7ZsmVq1aqVSkpK9PzzzyszM1ORkZHq27evZs6cqT59+jR0uQ3GFXB9fgS37FJh2fklTW4eDwAACF4BFXC//PLLGse8/vrrDVBJ4HA4TOXklw+4pdU/wQvRkSGyWgzZHab2H81TXERAvR0AAADqJKDm4KKynPyyKyWEWi2KDPdtADUMwzWvd9eBbJ9uGwAAwF8IuAGu/AlmhuH5hg4nwzntYed+Ai4AAAgOdQ6411xzjVauXFnl+u+//97tBg2om5zj17+1RdfPhWjjOIILAACCTJ0D7urVq3X06NEq1x87dkxr1qyp6+ZxXO7xO5jFRNZvwN25P0um6fl6ugAAAI3JSU1RqO5P5rt371Z0dMPc3jWYOe9gVl8BNzY6VIaknPwSZRy/oQQAAEBj5tVZSwsXLtTChQtdH8+ZM0f//Oc/K43LycnRli1bNHz48JOvsAkrKbUrv7Dsqgmx9RRwrRaLYqJClZNfoj2HctXcFlEv+wEAAGgoXgXcgoICZWRkuD7Oy8uTxVL5IHBUVJQmTJig22677eQrbMIOpufLlBRiNRQeZq23/cRFh5UF3MM5Sj21Zb3tBwAAoCF4FXCvuuoqXXXVVZKkESNG6C9/+YvOPffceikM0r4juZLKpifUxxUUnOKiw7T3SJ72HMqtt30AAAA0lDpfWLU2N2XAydl3JE9S/c2/dXKeaLbnUE697gcAAKAhnPSdA3Jzc7V//35lZ2d7PAt/wIABJ7uLJqv8Edz6ZIspC7hHswqVV1ii6Ij63R8AAEB9qnPAPXbsmB577DH997//ld1ur7TeNE0ZhqHNmzefVIFN2b7DxwNuVP0GzrAQq1rGR+poZoH2HclTcvv4et0fAABAfapzwH3wwQe1fPlyTZw4Uf3795fNZvNlXU2eaZquI7j1dQWF8jokxBwPuLkEXAAA0KjVOeB+++23uvbaa3Xvvff6sh4cl5lbrMJiuwypQaYMtE+I1Y9bjmjf0bx63xcAAEB9qvONHiIiIpSYmOjLWlDOgfSyoBkVESKLpf6uoODUPiFW0okT2wAAABqrOgfcCy+8UEuXLvVlLU1KTGyEbHGRVf6XcfwWvbH1PP/WqYMz4B7N45a9AACgUavzFIXzzz9fa9as0Q033KArr7xSbdq0kdVa+WYEPXv2PKkCg5XFYmjBpxurXP/LjnRJ9X8FBafEVjEyVHZr4Oz8EoWENchuAQAAfK7OAdd5wwdJ+u677yqt5yoKJyfn+BHchgq44WFWtWoWqcMZBdp/JFcdEsMbZL8AAAC+VueA++STT/qyDlSQW9CwAVeSEltG63BGgfYezSPgAgCARqvOAffiiy/2ZR0op7TUocLismsLN2jAbRWtn7Ye1f6jeZKaN9h+AQAAfKnOJ5mh/jiP3sbFhCkstPK85vqS2DJGEldSAAAAjVudj+BOnz69xjGGYeiJJ56o6y6arLzCsoDb7njgbCiJLaMlcSUFAADQuNU54K5atarSMofDoSNHjshut6t58+aKjIw8qeKaqrzCUklSQvOoBt1vmxZRsloMFRSVKjO3qEH3DQAA4Ct1Drhffvmlx+UlJSV6//33NX/+fL3xxht1Lqwpcwbcti2ilZffcEEzxGpR62aROpCer/1H8xtsvwAAAL7k8zm4oaGhuvrqqzV06FA9+uijvt58k+CcopDQomGP4Epl18OVpAPcshcAADRS9XaSWbdu3bRmzZr62nxQyysoO4Lbxh8B9/g83P3pBFwAANA41VvA/e6775iDWweldoeKSsouEdamRXSD798ZcA8QcAEAQCNV5zm4s2fP9rg8JydHa9as0aZNmzRp0qQ6F9ZU5R+ffxtqtSg2quHvl5vYynkEN1/i9xMAANAI+TzgxsXFqX379po5c6auuOKKOhfWVDnn30ZH1vlTc1JaN4uU1WKoqMRBwAUAAI1SnVPUr7/+6ss6cJzzCgpREf4JuFaLRQnNo7TnaIFf9g8AAHCyuJNZgHEG3OiIhrtFb0Vt/XByGwAAgK+c9GHC1atX66uvvtL+/fslSe3atdPZZ5+tgQMHnnRxTVG+c4qCn47gSmXX3wUAAGis6pyiiouLdc8992jp0qUyTVM2m02SlJ2drTfffFPnnXeenn32WYWG+u9IZGPkvESYP4/gtuMILgAAaMTqPEXh5Zdf1hdffKHrrrtO33zzjVavXq3Vq1fr22+/1fXXX6///ve/evnll31Za9BzOEwVFDkDLkdwAQAA6qLOAfc///mPLr74Yt17771q2bKla3mLFi305z//WRdddJE++eQTnxTZVOQXlcqUZLUYCg+z+q2ONi2iZPht7wAAACenzgH3yJEj6tOnT5Xr+/TpoyNHjtR1802Sc/5tVESIDMN/ETM81Krmtgi/7R8AAOBk1DngtmnTRqtXr65y/Zo1a9SmTZu6br5JOnEFBf9NT3Dyx22CAQAAfKHOAfeiiy7SZ599pgcffFA7duyQ3W6Xw+HQjh079NBDD2nJkiW6+OKLfVlr0HOeYBblxxPMnNo0J+ACAIDGqc6HCm+++WalpaXpn//8pz744ANZLGVZ2eFwyDRNXXzxxbr55pt9VmhTkBcAlwhzatsiStrq7yoAAAC8V+ckZbVa9dRTT+mPf/yjvv76a+3bt0+SlJiYqOHDh6tbt24+K7KpyA+Amzw4cQQXAAA0Vl4F3KKiIj3++OM69dRTNXHiRElSt27dKoXZBQsW6L333tNf/vIXr66D+9lnn+mTTz7Rxo0blZ2drY4dO2rixIm69NJL3U66+uCDD/Taa69p//796ty5s6ZOnapzzjnHm5cScEzTDKgjuOUDblFxqaL9n7kBAABqxas5uO+//74WLlyos88+u9pxZ599tj788EN98MEHXhXz97//XZGRkZo2bZrmzJmj4cOHa8aMGW7X0120aJFmzJih0aNHa968eUpNTdWUKVO0bt06r/YVaAqL7XKYkiEpMtz/ATc68kSiPXiswI+VAAAAeMerJPXZZ59p1KhRat++fbXjOnTooN/97ndatGiRrrrqqlpvf86cOWrevLnr4yFDhigzM1Nvvvmmbr31VlksFr300ksaO3as7rrrLknS4MGD9dtvv+nll1/WvHnzvHk5ASX/+A0eIsNDZLEE1lVoDx7LU4/qP+UAAAABw6sjuL/99ptOP/30Wo3t27evtmzZ4lUx5cOtU/fu3ZWbm6v8/HylpaVp165dGj16tNuYMWPGaOXKlSouLvZqf4GkoPBEwA00HMEFAACNiVcBt6SkpNZzakNDQ30SONeuXauEhATFxMRox44dkqTOnTu7jenatatKSkqUlpZ20vvzF+cR3KgAmH9b0YH0PH+XAAAAUGtepanWrVtr69baXTtq69atat26dZ2Kcvrhhx+0ePFi3XfffZKkrKwsSZLNZnMb5/zYub6uQkLqfFngSqxWi9u/FRmG4TYVoaDoxE0eyi+vOF3BYpZ7bHgec+K57o+rm/pgGIbb6w8xTzw+dCzfp73xpKZ+oTJ65j165h365T165j165h36VTteBdwzzjhDH3/8sSZPnqwWLVpUOS49PV0ff/yxzj///DoXdvDgQU2dOlWDBg3SNddcU+ft1JbFYqhZs2ifb9dmi/S4vKTUrsjIMNfHhSUOSVK8LcK13DDkNkaSDHup63FEZJjHMU5Ww32sPcLzOOe+yr/+sHIH3w9nFiomNlKh9Rxypar7harRM+/RM+/QL+/RM+/RM+/Qr+p5FXBvuukmffLJJ7r22mv1+OOP67TTTqs05ueff9YDDzygoqIi3XjjjXUqKjs7WzfddJPi4+M1a9Ys100k4uLiJEk5OTlq1aqV2/jy6+vC4TCVnZ1f5+dXZLVaZLNFKju7QHa7o9L66JgIFRScSJG5+WWPQyxyLTdNuY2RpCL7iY8LC4o9jnEKKXQfW2pW/ek2TSkj48RUhLySE48dDlNbdhxRYquYKp9/smrqFyqjZ96jZ96hX96jZ96jZ95pyv2y2SJrfeTaq4Dbvn17vfDCC7r77rs1YcIEtW/fXsnJyYqOjlZeXp62bt2qPXv2KCIiQs8995w6dOjgdfGFhYWaPHmycnJy9P777ys2Nta1rkuXLpKkHTt2uB47Pw4NDa3x6g41KS31/RvFbnd43K5pmnI4TNdj11UUwkJcyyW5PZak8h86H1ccc+K57o+rGuesoXydFWtOO5SrhGb1f/OHqvqFqtEz79Ez79Av79Ez79Ez79Cv6nl9RtPZZ5+tTz75RPPmzdNXX32lpUuXuta1bt1al19+uW666aY6hc3S0lLddddd2rFjh/7xj38oISHBbX379u3VqVMnLVmyRCNHjnQtX7x4sYYMGaKwsKr/BB/ICovtMs2yaQIRYVZ/l+MRJ5oBAIDGok6n7CclJWnmzJmSpNzcXOXl5Sk6OloxMSf3J+yZM2dq+fLlmjZtmnJzc91u3tCjRw+FhYXp9ttv15/+9Cd16NBBgwYN0uLFi7V+/Xq9/fbbJ7Vvf8ovd4mw8ndsCyQH0n03fQMAAKA+nfQ1qWJiYk462Dp9++23kqSnnnqq0rply5YpKSlJ48aNU0FBgebNm6e5c+eqc+fOmj17tvr27euTGvzBdYmwALwGrtN+juACAIBGIqAS1ZdfflmrcZdffrkuv/zyeq6m4TSGgHswPV8O05QlQI8wAwAAOHERtQDgnKIQiDd5kKQQq6HiUoeOZRX6uxQAAIAaEXADgPMmD4F4m15Jah1fdq29/czDBQAAjQABNwAE+hHcNs3LLg/GlRQAAEBjQMD1M4dpqqA4sOfgtmlRdoczAi4AAGgMCLh+1hiugdumBVMUAABA40HA9TPX9IQAvgZu2+bHj+AezZNpVn03NAAAgEBAwPWz/AA/wUySEppFypCUV1iqnPwSf5cDAABQLQKunxUE+AlmkhQaalWLuAhJzMMFAACBj4DrZ43hJg+S1K5l2TQF5uECAIBAR8D1s/zCsj/5B/IRXElq2+L4pcKOcgQXAAAENgKunzWWI7htuVQYAABoJAi4fuQwTRUW2SUFfsBt14IpCgAAoHEg4PpRYVGpTEkWQwoP0GvgOrVtWTZFISOnyHVrYQAAgEBEwPWj8pcIC9Rr4DpFR4TKFh0mSTp4jKO4AAAgcBFw/Si/EVwirLx2x08028+JZgAAIIARcP2osZxg5nTiRDOO4AIAgMBFwPWjxnYE13WpMK6kAAAAAhgB148KGtsRXG72AAAAGgECrh85j+BGNpIjuM5LhR3JKFCp3eHnagAAADwj4PpJSalDBcWN4xq4TvExYYoIs8phmjrElRQAAECAIuD6ybHsQkmSxWIoPDSwr4HrZBgGJ5oBAICAR8D1k8MZZQExqhFcA7c816XCONEMAAAEKAKunxzOKJDUeKYnODlPNOMILgAACFQEXD85fHwOa2M5wczJdakwbvYAAAACFAHXT4400iO4zispHDyWL4dp+rkaAACAygi4fnI488Qc3MakZXyEQqyGiksdSs8q9Hc5AAAAlRBw/cR1BLeRTVGwWixKaM4dzQAAQOAi4PpBqd3hukxYYzuCK8l1qbD9RznRDAAABB4Crh+kZxfKNCWrxVBYaOP7FDgvFcYRXAAAEIgaX7oKAkePz12NbGTXwHXiZg8AACCQEXD9wHlyVmObf+vUttwRXJMrKQAAgABDwPWDo1mN8xJhTm2aR8mQlFdYquz8En+XAwAA4IaA6wdHMxvvCWaSFBZqVcv4CEnc8AEAAAQeAq4fOOfdxsWE+bmSujsxD5eACwAAAgsB1w+uHpWsmTcNVsu4CH+XUmfOebj7OdEMAAAEmMb5N/JGLjI8RD1bx2rtpoP+LsXFMAzZ4iJdH1uLHa7HNlukosMi5XCYys0pm17BEVwAABCoCLhwWfDpRtfjIkeB6/E7SzYr3BKpa8b1dC1rx6XCAABAgGKKAuqkbcuyKQoZOUUqKCr1czUAAAAnEHBRJ9ERobJFl50kd/AYR3EBAEDgIOCizpy37N3PpcIAAEAACag5uLt379brr7+un3/+WVu3blWXLl306aefuo2ZOHGiVq9eXem5ixcvVteuXRuqVKjsRLNf92QyDxcAAASUgAq4W7du1YoVK3TaaafJ4XBUeRvYfv366b777nNblpSU1BAlopzyt+wFAAAIFAEVcEeMGKGRI0dKkqZNm6YNGzZ4HGez2ZSamtqAlcGTti3LrqTAtXABAEAgCag5uBZLQJWDGjgvFXYko0CldkcNowEAABpGo0yUq1evVmpqqnr37q2rr75aa9as8XdJTVJ8TJgiwqxymKYOcSUFAAAQIAJqikJtDBgwQOPHj1enTp10+PBhvf7667ruuuv01ltvqW/fvie17ZAQ3+V9q9Xi9m9FhmHIYjFq3E7FMZZy05Kdq6raTvkD4hZL1eM87avifiwWQ4ZhVOpRYqtobd+XrUMZBerY1lbt9qtTU79QGT3zHj3zDv3yHj3zHj3zDv2qnUYXcO+44w63j88++2yNGzdOr7zyiubNm1fn7Voshpo1iz7Z8iqx2SI9Li8ptSsyMqza5xqGKo0x7CduqhARGeZxjJPVcB9rj6h6fxW3U3E/EdayfVXsUZfEeG3fl60jOUU+6V9V/ULV6Jn36Jl36Jf36Jn36Jl36Ff1Gl3ArSgqKkpnnXWWPv/885PajsNhKjvbd39mt1otstkilZ1dILuH+anRMREqKCiudhumqUpjiuwnPi4sKPY4ximk0H1sqVn1p7vidirtxxoi05QyMtyvmNAqLkKStG1PRqV13qipX6iMnnmPnnmHfnmPnnmPnnmnKffLZous9ZHrRh9wfam01PdvFLvd4XG7pmnK4fB8GbTyKo4p/6HzcVXbcTjcH9e0v/LrK+7H4TBlmmal1+K82UPa4Vyf9K+qfqFq9Mx79Mw79Mt79Mx79Mw79Kt6jX4CR35+vr766iv17t3b36U0SUmtYiSVXUmhqNju52oAAAAC7AhuQUGBVqxYIUnat2+fcnNztWTJEknSwIEDtWPHDr322ms677zzlJiYqMOHD+vNN9/UkSNH9OKLL/qz9CbLFh0mW1SosvNLtD89T51P4kQzAAAAXwiogJuenq4777zTbZnz4wULFqhNmzYqKSnR888/r8zMTEVGRqpv376aOXOm+vTp44+SISmxVYyyd2do7+FcAi4AAPC7gAq4SUlJ2rJlS7VjXn/99QaqBrWV1CpGm3dnaO8RbtkLAAD8r9HPwYX/JbUquzzY3iO5fq4EAACAgAsfSGpddqLZPgIuAAAIAARcnLR2LaNlSMrOL1F2XvXX9gUAAKhvBFyctPBQq1o1K7ujCtMUAACAvxFw4RPO6+FyohkAAPA3Ai58ghPNAABAoCDgwiecR3A50QwAAPgbARc+kXj8CO6+o3lymKafqwEAAE0ZARc+kdAsSqEhFhWXOHQks8Df5QAAgCaMgAufsFgMJbYsO4qbdohpCgAAwH8IuPCZDgmxkqTdh3L8XAkAAGjKCLjwmY4JZSea7eEILgAA8CMCLnzGeQR3D0dwAQCAHxFw4TNJrWJkSMrKK1ZWbpG/ywEAAE0UARc+Ex5mVZsWUZKk3UxTAAAAfkLAhU8xTQEAAPgbARc+1cF1ohkBFwAA+AcBFz7lOoJ7mCkKAADAPwi48KmOxwPu4YwCFRSV+rkaAADQFBFw4VMxkaFqbguXJKVxFBcAAPgBARc+16E1dzQDAAD+Q8CFz3GiGQAA8CcCLnzuxKXCmKIAAAAaHgEXPuc8grv/aJ5KSu1+rgYAADQ1BFz4XAtbhGKjQmV3mFwuDAAANDgCLnzOMAx1bmuTJO3cn+3nagAAQFNDwEW96OIMuAcIuAAAoGERcFEvOrcrC7g7DnAlBQAA0LAIuKgXzikKh47lK6+wxM/VAACApoSAi3oRExmq1vGRkqRdHMUFAAANiICLetOpbdn1cJmHCwAAGhIBF/WGE80AAIA/EHBRb1wnmu3Plmmafq4GAAA0FQRc1JsOCbGyGIay8oqVkVPk73IAAEATQcBFvQkPtSqpVbQkpikAAICGE+LvAtB4GIYhW1xktWMcDlO5OYWujzu3s2nP4VztOJCt01Na13eJAAAABFx4Z8GnG6tdf824nm4fd25r04p1+7llLwAAaDBMUUC96uq6o1m2Su0OP1cDAACaAgIu6lXbltGKjghRcYlDaYdz/V0OAABoAgIq4O7evVsPPvigxo8frx49emjcuHEex33wwQc6//zz1bt3b1144YVavnx5A1eK2rIYhk5Nipck/ZaW6ddaAABA0xBQAXfr1q1asWKFOnbsqK5du3ocs2jRIs2YMUOjR4/WvHnzlJqaqilTpmjdunUNWyxq7dSkOEnS1r1Zfq4EAAA0BQF1ktmIESM0cuRISdK0adO0YcOGSmNeeukljR07VnfddZckafDgwfrtt9/08ssva968eQ1ZLmrp1PbxkqStezNlmqYMw/BvQQAAIKgF1BFci6X6ctLS0rRr1y6NHj3abfmYMWO0cuVKFRcX12d5qKNObWIVGmJRTn6JDh7L93c5AAAgyAVUwK3Jjh07JEmdO3d2W961a1eVlJQoLS3NH2WhBiFWi7q0LbuaAtMUAABAfQuoKQo1ycoqC0c2m81tufNj5/q6CgnxXd63Wi1u/1ZkGIYslpr/VF9xjMUs99jwPObEc90f17S/8usr7se5rqZtGIbhsY8pHeK1JS1T2/ZlacTpSZXW19QvVEbPvEfPvEO/vEfPvEfPvEO/aqdRBdz6ZLEYatYs2ufbtdk83/mrpNSuyMiwap9rGKo0xrCXuh5HRIZ5HONkNdzH2iOq3l/F7VTcT4S1+n2V346nPp7eo60++XaXtu3LqrbPVfULVaNn3qNn3qFf3qNn3qNn3qFf1WtUATcuruxs/JycHLVq1cq1PDs72219XTgcprKzfTc/1Gq1yGaLVHZ2gewebnAQHROhgoLq5wybpiqNKbKf+LiwoNjjGKeQQvexpWbVn+6K26m0H2tItfsqv52MjLxKy9vEh8swpIPp+dqx55iaxYa7ra+pX6iMnnmPnnmHfnmPnnmPnnmnKffLZous9ZHrRhVwu3TpIqlsLq7zsfPj0NBQtW/f/qS2X1rq+zeK3e7wuF3TNOVwmB6e4a7imPIfOh9XtR2Hw/1xTfsrv77ifpzratqGaZoeX2+o1aL2rWO051CuNu86poHdEzw+v6p+oWr0zHv0zDv0y3v0zHv0zDv0q3qNagJH+/bt1alTJy1ZssRt+eLFizVkyBCFhVX/53P4l/OGD1vTONEMAADUn4A6gltQUKAVK1ZIkvbt26fc3FxXmB04cKCaN2+u22+/XX/605/UoUMHDRo0SIsXL9b69ev19ttv+7N01EJK+3gtW7tXm/dk+LsUAAAQxAIq4Kanp+vOO+90W+b8eMGCBRo0aJDGjRungoICzZs3T3PnzlXnzp01e/Zs9e3b1x8lwwvdOjaTIWn/0Txl5BRVmocLAADgCwEVcJOSkrRly5Yax11++eW6/PLLG6Ai+FJMZKg6tY3VzgM52rTrmIb2buvvkgAAQBBqVHNw0fj16NRckrRpF9MUAABA/SDgokH16NhMkrRp9zGZZs1XkQAAAPAWARcN6pSkOIWFWJSVW6z9RytfLxcAAOBkEXDRoEJDrDq1fbwkaSPTFAAAQD0g4KLB9XTNwz3m50oAAEAwIuCiwfXoVDYPd8ueTJU2sdsMAgCA+kfARYNLah2j2KhQFZXYtWN/tr/LAQAAQYaAiwZnMQx1P341hV92pPu5GgAAEGwIuPCL07q2lCT9vO2onysBAADBhoALv+jdtYUshqG9R/J0JLPA3+UAAIAgQsCFX8REhurUpDhJ0jqO4gIAAB8i4MJvUk8tm6awbisBFwAA+A4BF36TekpZwP0tLVN5hSV+rgYAAAQLAi78JqF5lNq2iJLdYeqX7VxNAQAA+AYBF37V99RWkqQffzvi50oAAECwIODCr5zzcNdvS+euZgAAwCcIuPCrLm1tskWFKr+oVBu2c7IZAAA4eQRc+JXFYij1+DSFr3/a5+dqAABAMCDgwu8G90iQJH33ywGVlDJNAQAAnBwCLvwuuX28msWGK6+gROuZpgAAAE4SARd+Z7EYGnT8KO73Gw/5uRoAANDYEXAREAb3bCNJ+um3IyosLvVzNQAAoDEj4CIgdG4bq3Yto1Vc6tBP3LoXAACcBAIuAoJhGBreN0mStGoT0xQAAEDdEXARMIb3TZQkbdx5TNn5xX6uBgAANFYh/i4AwcUwDNniImsaJJlmpefFGFLXpDht35ultVuP6pzT2tVjpQAAIFgRcOFzCz7dWO36ay/opfkVxlgshiIjwxQbUfaWXLYmTWf3aSvDMOqtTgAAEJyYooCAktgqRlaLof1H87RlT6a/ywEAAI0QARcBJTTEoqRW0ZKkFT/v93M1AACgMSLgIuB0bBMrSVq75bByONkMAAB4iYCLgBMfE64uiXEqtZv69peD/i4HAAA0MgRcBKTzBnaQJK1Yt0+OCldcAAAAqA4BFwFp2GntFBlu1aGMAq3flu7vcgAAQCNCwEVAigwP0VmpZTd+WLJqt5+rAQAAjQkBFwHrvP7tZbUY+m1vlrbvz/J3OQAAoJEg4CJgNYsN1+AeCZKkz1ftqbQ+JjZCtrjIav+LiY1o6LIBAICfcSczBLTzB3XQtxsOau1vR3Q4I1+tm0W51lksRo13TbtmXM/6LhEAAAQYjuAioCW1ilGfri1kmtLnq9P8XQ4AAGgECLgIeKMHlV0y7H/r9ys9q9DP1QAAgEBHwEXAS24fr24d4lVqN/Wf73b6uxwAABDgGl3A/eijj5SSklLpv2eeecbfpaGeGIahS4Z3lSR9s/6gDh3L93NFAAAgkDXak8xee+01xcbGuj5OSEjwYzWob6ckxalP1xZavz1dH3+zU5Mu5OQxAADgWaMNuD179lTz5s39XQYa0MVndtH67elatemQxgzpqB5xkf4uCQAABKBGN0UBTVfHNrHqn9JKpqR/fbXd3+UAAIAA1WgD7rhx49S9e3ede+65evXVV2W32/1dEhrAJWd1ldViaP32dK399ZC/ywEAAAGo0U1RaNWqlW6//XaddtppMgxDX375pV544QUdOnRIDz744EltOyTEd3nfarW4/VuRYRiyWIwat1NxjMUs99jwPObEc90f17S/8usr7se5ri4112ZMxe0bhuHx85HUOkbnD+qgxSt3681PN2lAt9ayVrO/qrYTDGp6j6EyeuYd+uU9euY9euYd+lU7jS7gnnnmmTrzzDNdHw8bNkzh4eGaP3++br75ZrVu3bpO27VYDDVrFu2rMl1sNs/zREtK7YqMDKv2uYahSmMMe6nrcURkmMcxTlbDfaw9our9VdxOxf1EWKvfV3U1ezMmPDzUNaaqz8e143pq5YaDOpierz2Hc9Wjc4tq91Ufn9dAUtV7DFWjZ96hX96jZ96jZ96hX9VrdAHXk9GjR+uNN97Q5s2b6xxwHQ5T2dm+u/yU1WqRzRap7OwC2e2OSuujYyJUUFBc7TZMU5XGFNlPfFxYUOxxjFNIofvYUrPqT3fF7VTajzWk2n1VV3NtxlgshsLDQ1VUVCKHw5RpShkZeVVu44pzTtGrn2zUhu3patMsUpHhnl9bTdtpzGp6j6EyeuYd+uU9euY9euadptwvmy2y1keugyLg+kppqe/fKHa7w+N2TdOUw2F6eIa7imPKf+h8XNV2HA73xzXtr/z6ivtxrqtLzd6McTjM4wHXrPbzMbB7ay1ft0+/7cnUz9vSNaBbKxlG5akKNW0nGFT1HkPV6Jl36Jf36Jn36Jl36Ff1gmICx+LFi2W1WtWjRw9/l4IGYhiGJl/cW4YhHTyWr/1Hg/MoLQAA8F6jO4J7ww03aNCgQUpJSZEkLVu2TP/85z91zTXXqFWrVn6uDg2pYxubkpPitSUtU7/sOKaWcZEKD7P6uywAAOBnjS7gdu7cWR9++KEOHjwoh8OhTp066f7779fEiRP9XRr84NSkOB1Iz1N2fol+2ZGu/t3qNgcbAAAEj0YXcB944AF/l4AAYrEYSj21pf738wHtT8/X3iO5SmoV4++yAACAHwXFHFw0bfEx4Tq1fZwk6edt6cotKPFzRQAAwJ8IuAgKye3j1cIWLrvD1NotR2SvxZUcAABAcCLgIihYDEP9klspLMSirLxibdp1zN8lAQAAP2l0c3DRNBiGIVtc9XdpqXjd28jwEPU9taVWbT6snQdyFB8TXp8lAgCAAEXARcBa8OnGatdfe0GvSssSmkfp1KQ4bd2bpZ+3HdVvezLUJi6ivkoEAAABiCkKCDrdOsSrTfNIOUzpr2+t1bHsQn+XBAAAGhABF0HHMAz1O7WVYqNClZlbpJf+tV4FRaX+LgsAADQQAi6CUkiIRYO6t5YtOkx7Dudq1ofrVVJq93dZAACgARBwEbSiIkL1wHUDFRFm1a97MjXn3xtldzj8XRYAAKhnBFwEtS6Jcbrzsj4KsVq0bttRvbFoMyEXAIAgR8BF0Evp0Ey3XNRTFsPQyo2HNO8/m1RqJ+QCABCsCLhoEvqe2kq3XNRLVouh1ZsPa86/N6iklJALAEAwIuCiyTg9pZWmXNJbIVaLftp6VC988LPyC0v8XRYAAPAxAi6alNNOaak7L++j8FCrNu/O0BNv/6ijWQX+LgsAAPgQARdNTs9OzTXtD/0UHxOm/Ufz9NiCtdq2L6va58TERsgWF1ntfzGx3DENAIBAwK160SR1bBOrB67prxc+WK+9R3L19D9+1IRzT9WIfokyDKPSeIvFqPHWwdeM61lf5QIAAC9wBBdNVnNbhKZf3U/9u7WW3WHqH1/8prn/2cRdzwAAaOQIuGjSIsNDdMv4nppw7qmyWgyt2nRID72xWr+lZfq7NAAAUEcEXDR5hmFo1ID2uu+qfmoZF6GjWYV6+h8/6oPl21Rcwu19AQBobAi4wHGnJMVp5vUDNax3W5mSPlu1Rw++vlqbdh3zd2kAAMALnGQGlBMZHqLrx3ZX31Nb6u0vftPhzAI98946Ddt8WBGhFkWF8yUDAECg46c14EHf5Fbq1rGZPlqxQ1/+uFff/LxfFkPq0i5OpybFKTSEP34AABCo+CkNVCEyPER/GJWsGX/sr55dmsthStv2ZWnZ2r3aeSBbDofp7xIBAIAHBFygBp3a2PTwjYM1sHtrxUSGqrjUoV92HNPyn/Zp39E8mSZBFwCAQMIUBTR5MbERslgq39yhPMMw1KZ5lFo3i9Segzn6NS1TeYWlWrvliLZEhio5KU52u8Mn+3I4TOXmFHr1GgAAwAkEXDR5tblL2bUX9Cobaxjq1NamxFYx2rE/Wzv2Zyu3oEQ/bj2qu57/WmMGd9CgHgkKsXr+4wh3RAMAoP4xRQGog9AQi1I6xGtk/yR17xivsBCLDqTn6fVFm3X/3O+1bO1eFRVzDV0AAPyBI7jASQgNsejUpHh1bmtTi2ZR+njFdh3NKtQ/vvhN//7fDp3dN1Hnnp6k+Jhwf5cKAECTQcAFfCDEatH44V11Ro8EfffLAX2+Jk2HMwq0aOVufb56jwb3bKPzB7SXLS7S36UCABD0CLiAD4WHWnVOvySdlZqon7Ye1eer92jbvix9s/6Avll/QH2TWyki1KKWcREyjOpPNgMAAHVDwAXqgcVi6PSUVjo9pZW27cvS56v36MctR/TTb0ckSbaoUHVqa1NSq+gqT0gDAAB1Q8AF6tkpiXE65eLeOpSRrxU/H9AXq/coO79E67ena9OuY2rfOkad29gUExXq71IBAAgKBFyggSQ0i9KN43tJpkNph3K162CO8gpLtfNAjnYeyFHLuAh1SIhRUQlXXwAA4GQQcIEGFhZiVdfEOHVpZ9ORzELtPJCtQxkFOppVqKNZhbrp8aXq362VzujVVqcmxTFXFwAALxFwAT8xDEOtm0WqdbNI5ReWaM+hXKUdyVV+Uam+/vmAvv75gFrFR2hwjzZKPbWlOraJlYWwCwBAjQi4CGqGYdR4aa5AOEIaFRGqbh2bKaVDvAb0aqfla9O08pcDOpJZqP98t0v/+W6XmsWG6/RurdUvpbU6J8QoJOTkTk6rzW2DZRiSaVY7pDHeWjgyKlw1ftob4WvnVtAAfKkxf08h4CLo1fY2vIHAMAz17NJCP2w8oBH9EnUwPV8HjuXrcEaBMnKKtHRNmpauSVNoiEXJ7eN1WnJrdWgVpaSWMYqK8O7Luba3KJ4fhLcWtlgMzf/PhmrHNMbXzq2gAfhSY/6eQsAFAlSI1aKk1jFKah0ju8NUelahDmXkK7egVEcyC7Rx5zFt3HnMNb6FLVyJrWLUvnWMEltFK7FljFrYwhUZHhIQR6kBAGgoBFygEbBaTszXnTi2h37dflRb92Vp18FcbdyRrvTsQqVnFyk9u0jrt6e7PTc8zKrmseFqbotQ89hwxceEyxYdpoRWMTqaVajwUIvCQ60KDbEQhAEAQaFRBtzt27frscce008//aTo6GiNHz9ed911l8LCwvxdGlDvDMNQYqsYdWxrU7Nm0crIyFN2bpH2HslT2uFc7TtSdrLawfR85RWWqqjYrgPp+TqQnl/Ddsuu8BAeZnWFXi3apK17s9yWhYdaFRZqlbWm+btBwDw+B5fgDwCNS6MLuFlZWbr22mvVqVMnzZo1S4cOHdJTTz2lwsJCPfjgg/4uD/CLqIhQJbePV3L7eLflRcV2Hcsp1LGcIh3LLlRGdpGy8oqVnV+svKJSpR3MUXGJQyV2h0xTKiqxu12Hd++RHVXuM8RqKDzUqu0HsmWLDFVzW4SaxYareWyEmtvC1Sw2XDGRoX4Jhw6HqdyCkrLXevy/rLxi5RSUqLDErqzcYu06kKVSu0OlpWbZv3aHHOXOKfvk212ux1aLceI/q0VWi6EQq6EDGQUKsxiKjAhRdESoosJDFBURcuLfcssiwqwEZQBoII0u4L733nvKy8vT7NmzFR8fL0my2+2aOXOmJk+erISEBP8WCASQ8DCr2raIVtsW0ZXW2eIiXScP2B2mio+H27L/HCoqtuvUDs3046+HXMucY0xTKrWbKrWXauOOY5W27RQaYjkeesPVLDZC8TFhiokMVXRkqKIjQhUTGaLoyFCFhVgUcjw4OgOkxWKo1O5QSalDxaVl/5aWOlRQVKrcghLlFpQop6BEeQUlyskvUXZ+uSCbX1zTBRC8YneYsrvS74lfANI3Har1NgxD5QJw6PEAfCIMh4VYXa/bajVkNY4/Pt4Tw5Asx5e5HhuGDMOQxVL2cXRMuA5nFJSttxgKKddPq9WQ1WJxHZUGAG+YpimHWfZv+ccOR2B+T2l0Affrr7/WkCFDXOFWkkaPHq2HHnpI3377rS655BL/FQc0UlaLocjwEEWGu39LuHZsD8nhcFtmmqZKSh2u0DugZxvtO5SjjOwi19HijOxCZeeXqKTUocMZBTqcUdCQL8clJjJUcTFhskWFKS46TPGx4WrTMkaRESFas+GAQqwWhViN4/9aZDEkGZJkaML53fT+f3+VTMnucMjuMFVqLwu6drtDpXZTp/dI0LHMAuUXliq/sET5RaVlj4tKlVdYqoLCEuUVlsruMGWaUl5h2XLJf5fU+ez73Qo7PtUkIjxEUeFWRYSVBe2IcGvZ+yCs7L0QHRmqVi2i5SgtVViIVZFhVtf7JDzMynWZgUbANE0VFttVcPz7ktv3quPfr/ILS1VQXKrCYrsKnf8W2VVcaldmTlGlv3CVt+dInu6d0LdhX1QtNLqAu2PHDl166aVuy2w2m1q1aqUdO6r+cyoA3zAMQ2HH5+HGSjozNVHZWZUDbEmpQxm5ZWHXOUUiJ7/EdfQ1r7BEuQWlyisoUYnd4QqNlfYnKTTUorCQshPhwkOtiokKVezxI8GxkaGKiQxVbFSYK8zaosMUGxWqEKv7tYJDQixq1ixaxSV27TuYXe3rjIsJL5uHLEmyehwzalBHj6+9POcvBHnHf5AUFJYqv6hE+cfDbtkPlxKVlpquIO1wmLKbpuz2448dphzHj5Q4j5y4PT5+RMUwDB3NKpB5fH1ZIHe4ArYkOUwd/yFmV1ZecbW1V8eQFFFNOI6s8HFEmLXsKL3VcB1dLjtCfeKIffmpIM7pHOUzdPkpHoZx/HeR4x8Y5QozqhjvrLs2vDkmVf6geEiIRSHhxcotKFFpqaPqJ1W7vdrt3avjZrUcXOtt+rDGEKtFptVaFqTq2DOP+66Hv1bUdpOmFw13mM5fnE3XX4vsDkfZ17Cj/PcBx/HvlaYsoVZlZhWqsKhURSV2FZeW/dWtuMRe9j3l+PeavMISFRTZ5ajHv9y0sFV/rXl/McxG9veqnj176s4779SkSZPclo8bN059+/bVo48+Wqft+vowe9mfCC1yOBwevyAsFkM5+dX/cImNCqs0xpSp9OL9kqQWYe1kiwqvcjuGaSr2cNnYnNbtZFZztKXivirux5DhsZ7a1FybMYYM13X1TZn1uq/6HFPTe6iun3dP+6npPVYTX9RSvh5fMo//z9cHCJ09M00zYF/7yajxc2pKUZGhrnBsuv7c6AzJZV9/5T+WeSJAO/8kCaBxKpvWVPbLn+X4v+6P3f+1WgwVFJa6fjM0XP87oSG/D1rK/fJbk0Z3BLe+GEbZHDVfs1iqvtuULTq8xud7GhMX3aX224kpGxtb454qb6fifmrcF2Nq9R7yxb7K76e691hD1FKxnsbAMIygfe21qbmKA9IAUElYaM3fMALt+6Akndy9Pv3AZrMpJyen0vKsrCzFxcX5oSIAAAAEkkYXcLt06VJprm1OTo6OHDmiLl0qH3EEAABA09LoAu7w4cP13XffKTv7xAkiS5YskcVi0dChQ/1YGQAAAAJBozvJLCsrS2PHjlXnzp01efJk140eLrjgAm70AAAAgMYXcKWyW/U++uijbrfqnTp1KrfqBQAAQOMMuAAAAEBVGt0cXAAAAKA6BFwAAAAEFQIuAAAAggoBFwAAAEGFgAsAAICgQsAFAABAUCHg+tj27dt13XXXKTU1VUOHDtVf//pXFRcX+7usgPDZZ5/plltu0fDhw5Wamqrx48frX//6lypeqe6DDz7Q+eefr969e+vCCy/U8uXL/VRxYMnLy9Pw4cOVkpKiX375xW0dPXO3cOFCXXTRRerdu7cGDRqkG2+8UYWFha71X375pS688EL17t1b559/vj788EM/Vut/y5Yt0+WXX66+fftq2LBhuvPOO5WWllZpXFN8n+3evVsPPvigxo8frx49emjcuHEex9WmNzk5Obr//vs1cOBA9e3bV3fccYcOHz5c3y+hwdXUs9zcXM2aNUuXXXaZ+vfvrzPOOEM333yztmzZUmlb9MyzpUuXKiUlxeO4ptKzmhBwfSgrK0vXXnutSkpKNGvWLE2dOlX//Oc/9dRTT/m7tIDw97//XZGRkZo2bZrmzJmj4cOHa8aMGXr55ZddYxYtWqQZM2Zo9OjRmjdvnlJTUzVlyhStW7fOf4UHiFdeeUV2u73Scnrmbs6cOXr00Uc1ZswYvf7663rkkUeUlJTk6t0PP/ygKVOmKDU1VfPmzdPo0aP1l7/8RUuWLPFz5f6xatUqTZkyRaeccopefvll3X///fr11191/fXXu/1S0FTfZ1u3btWKFSvUsWNHde3a1eOY2vbmrrvu0rfffquHH35YzzzzjHbu3KmbbrpJpaWlDfBKGk5NPdu/f7/ef/99DR06VC+88IIeffRR5eTk6Morr9T27dvdxtKzygoLC/XEE0+oZcuWHtc3lZ7VyITP/O1vfzNTU1PNjIwM17L33nvP7N69u3nw4EH/FRYg0tPTKy174IEHzH79+pl2u900TdMcNWqUeffdd7uNufLKK80bb7yxQWoMVNu2bTNTU1PNd99910xOTjbXr1/vWkfPTti+fbvZo0cP86uvvqpyzPXXX29eeeWVbsvuvvtuc/To0fVdXkCaMWOGOWLECNPhcLiWrVy50kxOTjbXrFnjWtZU32fO702maZr33XefOXbs2EpjatObH3/80UxOTjb/97//uZZt377dTElJMRctWlQPlftPTT3Ly8sz8/Pz3Zbl5uaaAwcONB955BHXMnrm2QsvvGD+4Q9/8DiuKfWsJhzB9aGvv/5aQ4YMUXx8vGvZ6NGj5XA49O233/qvsADRvHnzSsu6d++u3Nxc5efnKy0tTbt27dLo0aPdxowZM0YrV65s0lM9HnvsMU2YMEGdO3d2W07P3H300UdKSkrSWWed5XF9cXGxVq1apd/97nduy8eMGaPt27dr7969DVFmQCktLVV0dLQMw3Ati42NlSTX9KGm/D6zWKr/MVnb3nz99dey2WwaOnSoa0yXLl3UvXt3ff31174v3I9q6llUVJQiIyPdlkVHR6tDhw5uf0qnZ5Xt2bNHb775ph544AGP65tSz2pCwPWhHTt2qEuXLm7LbDabWrVqpR07dvipqsC2du1aJSQkKCYmxtWjiiGua9euKikp8TgnsClYsmSJfvvtN912222V1tEzdz///LOSk5P1yiuvaMiQIerVq5cmTJign3/+WVLZD4eSkpJKX6fOPwk2xa/TSy65RNu3b9c//vEP5eTkKC0tTc8995x69Oihfv36SeJ9Vp3a9mbHjh3q3Lmz2y8SUln4aIrvu4qys7O1detWt69NelbZ448/rvHjx6tbt24e19OzEwi4PpSdnS2bzVZpeVxcnLKysvxQUWD74YcftHjxYl1//fWS5OpRxR46P26KPSwoKNBTTz2lqVOnKiYmptJ6eubuyJEj+uabb/Txxx/roYce0ssvvyzDMHT99dcrPT2dfnnQv39/zZ49W88++6z69++vkSNHKj09XfPmzZPVapXE+6w6te1Ndna268h4efx8KPN///d/MgxDv//9713L6Jm7L7/8Uj/99JPuvPPOKsfQsxMIuPCLgwcPaurUqRo0aJCuueYaf5cTsObMmaMWLVro0ksv9XcpjYJpmsrPz9eLL76o3/3udzrrrLM0Z84cmaapt99+29/lBaQff/xR9957r6644grNnz9fL774ohwOhyZNmuR2khlQXz788EP985//1IMPPqg2bdr4u5yAVFRUpCeeeEK33367x+l+qIyA60M2m005OTmVlmdlZSkuLs4PFQWm7Oxs3XTTTYqPj9esWbNcc4+cParYw+zsbLf1TcW+ffv0xhtv6I477lBOTo6ys7OVn58vScrPz1deXh49q8Bmsyk+Pt7tz3fx8fHq0aOHtm3bRr88eOyxxzR48GBNmzZNgwcP1u9+9zvNnTtXmzZt0scffyyJr83q1LY3NptNubm5lZ7f1H8+rFixQg8++KBuvfVWXXzxxW7r6NkJ8+fPl8Vi0dixY5Wdna3s7GyVlJTI4XAoOzvbNdebnp1AwPUhT3NccnJydOTIkUpz/pqqwsJCTZ48WTk5OXrttdfc/pTi7FHFHu7YsUOhoaFq3759g9bqb3v37lVJSYkmTZqkAQMGaMCAAbr55pslSddcc42uu+46elbBKaecUuW6oqIidejQQaGhoR77JalJfp1u37690ny+Nm3aqFmzZtqzZ48kvjarU9vedOnSRTt37qx03e+dO3c2yfedJK1bt0533nmnLrroIo9/dqdnJ+zYsUO7d+/WkCFDXD8PPv30U23fvl0DBgxwXcubnp1AwPWh4cOH67vvvnP95i6VnSBksVjczmhsqkpLS3XXXXdpx44deu2115SQkOC2vn379urUqVOl65EuXrxYQ4YMUVhYWEOW63fdu3fXggUL3P6bPn26JGnmzJl66KGH6FkF55xzjjIzM7V582bXsoyMDG3cuFE9e/ZUWFiYBg0apM8//9zteYsXL1bXrl2VlJTU0CX7Xbt27bRp0ya3Zfv27VNGRoYSExMl8bVZndr2Zvjw4crKytLKlStdY3bu3KlNmzZp+PDhDVpzINi2bZsmT56swYMHa+bMmR7H0LMTbrrppko/D4YNG6bExEQtWLBAI0aMkETPygvxdwHBZMKECXrrrbd02223afLkyTp06JD++te/asKECZXCXFM0c+ZMLV++XNOmTVNubq7bRdB79OihsLAw3X777frTn/6kDh06aNCgQVq8eLHWr1/fJOdP2mw2DRo0yOO6nj17qmfPnpJEz8oZOXKkevfurTvuuENTp05VeHi45s6dq7CwMF111VWSpFtuuUXXXHONHn74YY0ePVqrVq3Sp59+queff97P1fvHhAkT9MQTT+ixxx7TiBEjlJmZ6Zr7Xf7SV031fVZQUKAVK1ZIKgv+ubm5rjA7cOBANW/evFa9cd4l7v7779d9992n8PBwPf/880pJSdGoUaP88trqS009M01TN9xwg8LDw3Xttddqw4YNrufGxMS4/hJDz070rGvXrpVuALFw4UIdOnTI7edEU+pZTQyz4nFsnJTt27fr0Ucf1U8//aTo6GiNHz9eU6dObdJHOJxGjBihffv2eVy3bNky19GzDz74QPPmzdP+/fvVuXNn3X333TrnnHMastSAtWrVKl1zzTX617/+pd69e7uW07MTjh07pieffFLLly9XSUmJ+vfvr+nTp7tNX1i2bJleeOEF7dy5U+3atdOkSZN02WWX+bFq/zFNU++9957effddpaWlKTo6WqmpqZo6dWqlH6hN8X22d+9enXvuuR7XLViwwBUuatObnJwcPfnkk/riiy9UWlqqYcOG6YEHHgi6AyA19UxSlScXDxw4UG+99ZbrY3rm/j4rb9q0adqwYYM+/fRTt+VNpWc1IeACAAAgqDAHFwAAAEGFgAsAAICgQsAFAABAUCHgAgAAIKgQcAEAABBUCLgAAAAIKgRcAAAABBUCLgAAAIIKARcAAsC0adNc95N3SklJ0axZs/xUUc1mzZqllJQUf5cBAJUQcAEAVSooKNCsWbO0atUqf5cCALVGwAWAALV+/Xrdcsstfq2hoKBAs2fP1urVqyutu+WWW7R+/Xo/VAUA1SPgAkAV8vPz/br/8PBwhYSE+LWG6oSEhCg8PNzfZQBAJQRcANCJ+aTbtm3TPffcowEDBuiqq66SJH388ce65JJL1KdPHw0cOFBTp07VgQMH3J7/ww8/6I477tDZZ5+tXr166ayzztITTzyhwsLCSvtaunSpxo0bp969e2vcuHH64osvPNZUcQ6us8bdu3dr2rRp6t+/v04//XRNnz5dBQUFbs8tLCzUY489pkGDBqlv3766+eabdejQIa/m9e7du1dDhgyRJM2ePVspKSluz/c0BzclJUWPPPKIPvvsM40ZM0Z9+vTRlVdeqS1btkiS3nvvPZ133nnq3bu3Jk6cqL1791ba788//6wbbrhBp59+uk477TRdffXVWrt2ba1qBgBJCtxDAwDgB3feeac6duyoqVOnyjRNzZkzRy+++KJGjx6tyy67TMeOHdPbb7+tP/zhD/r3v/8tm80mSVqyZIkKCwv1+9//XvHx8Vq/fr3efvttHTx4UC+99JJr+998841uv/12nXLKKbrnnnuUkZGh6dOnq02bNrWu8a677lJSUpLuvvtubdq0SR988IGaN2+uP//5z64x06ZN02effabx48frtNNO05o1azRp0iSvetG8eXM9/PDDevjhh3XeeefpvPPOk6QaTyz74Ycf9OWXX7p+QZg7d65uvvlm3XjjjXrnnXd01VVXKSsrS6+99pruv/9+LViwwPXclStX6qabblKvXr00ZcoUGYahjz76SNdee63eeecd9enTx6vXAKCJMgEA5ksvvWQmJyebd999t2vZ3r17ze7du5tz5sxxG7tlyxazR48ebssLCgoqbfPVV181U1JSzH379rmWjR8/3hw6dKiZnZ3tWvbNN9+YycnJ5jnnnOP2/OTkZPOll16qVOP06dPdxt12223mwIEDXR9v2LDBTE5ONh9//HG3cdOmTau0zZqkp6dX+RxnPRVr7tWrl5mWluZa9t5775nJycnm0KFDzZycHNfyZ5991kxOTnaNdTgc5qhRo8zrr7/edDgcrnEFBQXmiBEjzOuuu67WdQNo2piiAADlTJgwwfX4iy++kMPh0OjRo3Xs2DHXfy1btlTHjh3driwQERHhepyfn69jx46pb9++Mk1TmzZtkiQdPnxYmzdv1sUXX6zY2FjX+KFDh+qUU06pU42S1L9/f2VmZio3N1eS9L///U+SXEdQna6++upa7+NkDBkyRElJSa6PTzvtNEnSqFGjFBMT41ruPBqblpYmSdq8ebN27dqlCy64QBkZGa5+5+fna8iQIVqzZo0cDkeDvAYAjRtTFACgnPLBbNeuXTJNU6NGjfI4tvwJYPv379dLL72kL7/8UllZWW7jnMFz//79kqSOHTtW2lbnzp1dQbgm7dq1c/vYOU0iKytLMTEx2r9/vywWi9trqWq/9aFt27ZuHztDbcVpGM6Qn52dLams35J03333VbntnJwcxcXF+apUAEGKgAsA5ZS/KoDD4ZBhGJo3b56sVmulsVFRUZIku92u6667TllZWbrxxhvVpUsXRUVF6dChQ5o2bZrPjzpaLJ7/+Gaapk/3U1eeelXdcmfdzn/vvfdede/e3eNYZ88BoDoEXACoQocOHWSappKSktS5c+cqx/3222/atWuXnn76aV100UWu5d9++63bOOeR1927d1faxs6dO31T9PH9OBwO7d27V506dXIt97TfmhiG4bO6atK+fXtJZUd8zzjjjAbbL4DgwxxcAKjCqFGjZLVaNXv27EpHR03TVEZGhqQTR1TLjzFN0+3qAJLUunVrde/eXQsXLlROTo5r+bfffqtt27b5rO5hw4ZJkt555x235W+//bbX24qMjJR0YhpBferVq5c6dOigN954Q3l5eZXWHzt2rN5rABAcOIILAFXo0KGD7rrrLj377LPat2+fRo4cqejoaO3du1dLly7VFVdcoRtuuEFdunRRhw4d9PTTT+vQoUOKiYnR559/7jEU3n333Zo8ebKuuuoqXXrppcrMzNTbb7+tU0891Wc3lujVq5fOP/98zZ8/X5mZma7LhDnnuHpzVDYiIkKnnHKKPvvsM3Xq1Enx8fE69dRTlZyc7JNay7NYLHrsscd00003ady4cbrkkkuUkJCgQ4cOadWqVYqJidHf/vY3n+8XQPDhCC4AVGPSpEmaNWuWLBaLXn75Zf31r3/Vl19+qaFDh2rEiBGSpNDQUP3tb39T9+7d9eqrr2r27Nnq1KmTnn766UrbGz58uF588UXZ7XY9++yz+uKLL/Tkk0+qV69ePq376aef1h/+8AetWLFCzzzzjEpKSvT8889LksLCwrza1mOPPabWrVvrySef1N13363PP//cp7WWN2jQIL3//vvq1auX3n77bT366KNauHChWrZsqWuvvbbe9gsguBhmoJyVAACoV5s3b9ZFF12k//u//9OFF17o73IAoN5wBBcAgpCnWwTPnz9fFotFAwYM8ENFANBwmIMLAEHotdde04YNGzR48GBZrVZ9/fXX+vrrr3XllVeqbdu2stvtNZ60FRUVpejo6AaqGAB8hykKABCEvv32W82ePVvbt29Xfn6+2rZtq/Hjx+vmm29WSEiI9u7dq3PPPbfabUyZMkW33357A1UMAL5DwAWAJqioqEhr166tdkz79u1d16YFgMaEgAsAAICgwklmAAAACCoEXAAAAAQVAi4AAACCCgEXAAAAQYWACwAAgKBCwAUAAEBQIeACAAAgqBBwAQAAEFT+H04cNsjgEW2NAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   We can see the graph is right skewed.\n",
        "*   Most of the articles in our corpus have a less reading time, with few articles having reading time in hours.\n",
        "*   The median reading time is 9minutes.\n"
      ],
      "metadata": {
        "id": "P9R3nfZ7pmqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading time Vs Article length**"
      ],
      "metadata": {
        "id": "4c-vjOOwqUIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "df['article_len'] = df['text'].apply(lambda x : len(x))\n",
        "#creating scatterplot\n",
        "fig, axes = plt.subplots(figsize = (8, 6))\n",
        "sns.scatterplot(x = df['reading_time'], y=df['article_len'])\n",
        "#Pearson correlation coefficient measures the linear relationship between two set of values\n",
        "corr_coeff, _ = pearsonr(df['reading_time'], df['article_len'])\n",
        "#plot title\n",
        "plt.suptitle(\"Reading Time Vs. Article Length | Corr. Coeff : {}\".format(round(corr_coeff, 2)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "mkNBL3dul9Yi",
        "outputId": "51d09211-7193-40a2-b685-d6b631d01504"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   As we can observe from the above scatter plot, the reading time and article length are correlated.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I8ji39c-t1NO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the data** - by taking a look at the articles written by each author. Are these articles written by the same author similar or on the same topic."
      ],
      "metadata": {
        "id": "L5dffASBumBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for author, count in dict(df['author'].value_counts()).items():\n",
        "  if(count < 2):\n",
        "    continue\n",
        "  print(\"Articles by {}\".format(author))\n",
        "  for title in df[df['author'] == author]['title'].values:\n",
        "    print(title)\n",
        "  print(\"-\"*120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbFs0N1Pt0HY",
        "outputId": "c3f5fffc-7843-45b2-a79f-551e49511110"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Articles by Adam Geitgey\n",
            "Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences\n",
            "Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning\n",
            "Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks\n",
            "Machine Learning is Fun! Part 2\n",
            "Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Joseph Rocca\n",
            "Ensemble methods: bagging, boosting and stacking\n",
            "Understanding Variational Autoencoders (VAEs)\n",
            "Understanding Generative Adversarial Networks (GANs)\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Natassha Selvaraj\n",
            "I tripled my income with data science. Here's how.\n",
            "How to Land a Data Analytics Job in 6 Months\n",
            "Top 10 Data Science Projects for Beginners\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Chris Zaire\n",
            "5 Online Courses I Took as a Self-Taught Data Scientist\n",
            "Is Data Science Still a Rising Career in 2021\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Dario Radecic\n",
            "Are The New M1 Macbooks Any Good for Data Science? Let's Find Out\n",
            "Top 3 Reasons Why I Sold My M1 Macbook Pro as a Data Scientist\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Adi Bronshtein\n",
            "Simple and Multiple Linear Regression in Python\n",
            "Train/Test Split and Cross Validation in Python\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Serge Faguet\n",
            "How to biohack your intelligence  with everything from sex to modafinil to MDMA\n",
            "I'm 32 and spent $200k on biohacking. Became calmer, thinner, extroverted, healthier & happier.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Will Koehrsen\n",
            "Hyperparameter Tuning the Random Forest in Python\n",
            "Random Forest in Python\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Madison Hunter\n",
            "15 Habits I Learned from Highly Effective Data Scientists\n",
            "How to Study for the Google Data Analytics Professional Certificate\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Andrei Tapalaga \n",
            "Chernobyl's Blown Up Reactor 4 Just Woke Up\n",
            "Eben Byers: The Man Who Drank Radioactive Water Until His Jaw Fell Off\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Susan Li\n",
            "Building A Logistic Regression in Python, Step by Step\n",
            "An End-to-End Project on Time Series Analysis and Forecasting with Python\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Yueh\n",
            "Richart + @GoGo \n",
            "2018  & : KOKO COMBO icash \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Daniel Jeffries\n",
            "How to Crush the Crypto Market, Quit Your Job, Move to Paradise and Do Whatever You Want the Rest of Your Life\n",
            "Why People Still Don't Get Cryptocurrency\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by allen farrington\n",
            "Bitcoin Is Venice\n",
            "Gauge Theory Does Not Fix This\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Alexandr Nellson\n",
            "How to invest in Bitcoin properly. Blockchain and other cryptocurrencies\n",
            "How to store Bitcoins and other cryptocurrencies properly.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Mercatus Center\n",
            "Nassim Nicholas Taleb on Self-Education and Doing the Math (Ep. 41  Live at Mercatus)\n",
            "Cliff Asness on Marvel vs. DC and Why Never to Share a Gym with Cirque du Soleil (Ep. 5  Live at Mason)\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Blake Ross\n",
            "Wealthfront:Silicon Valley Tech at Wall Street Prices\n",
            "Heroes Give, Superheroes Borrow\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Tomas Pueyo\n",
            "Coronavirus: Why You Must Act Now\n",
            "Coronavirus: The Hammer and the Dance\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Terence Shin\n",
            "OVER 100 Data Scientist Interview Questions and Answers!\n",
            "50+ Statistics Interview Questions and Answers for Data Scientists for 2022\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Rukshan Pramoditha\n",
            "11 Dimensionality reduction techniques you should know in 2021\n",
            "20 Necessary Requirements of a Perfect Laptop for Data Science and Machine Learning Tasks\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Ketan Doshi\n",
            "Transformers Explained Visually (Part 2): How it works, step-by-step\n",
            "Transformers Explained Visually (Part 3): Multi-head Attention, deep dive\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Aman Kharwal\n",
            "60 Python Projects with Source Code\n",
            "180 Data Science and Machine Learning Projects with Python\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Mahmoud Harmouch\n",
            "17 Clustering Algorithms Used In Data Science and Mining\n",
            "17 types of similarity and dissimilarity measures used in data science.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Articles by Sara A. Metwalli\n",
            "6 Data Science Certificates To Level Up Your Career\n",
            "6 Machine Learning Certificates to Pursue in 2021\n",
            "------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   From above we can see that the authors tend to write multiple articles on the same topic.\n",
        "*   But alos, there are multiple authors writing on the same topic."
      ],
      "metadata": {
        "id": "sWvmXbfqzYSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing"
      ],
      "metadata": {
        "id": "VfaIaaa5r2J2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using contractions library to remove the contractions and expand them.\n",
        "It is not feasible to do them manually using a dictionary as there are many contractions."
      ],
      "metadata": {
        "id": "BNCKU1PZr-jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nvr9GYvx5Cb",
        "outputId": "2eed53e7-1bbe-420e-d037-a1ce2abc085b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "\n",
        "# sample data\n",
        "sample_text = \"\"\"\n",
        "I've decided to go to the party after all. I'll reach by 05:00 PM.\n",
        "He's not coming with us.\n",
        "It's his birthday and he has other plans.\n",
        "They've thought about going to the movies.\n",
        "I won't be going to movies.\n",
        "\"\"\"\n",
        "#checking with a sample text\n",
        "expanded_text = contractions.fix(sample_text)\n",
        "print(expanded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASqX0d3ouIwB",
        "outputId": "93948692-1d8b-461f-ef69-e08c4e039281"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I have decided to go to the party after all. I will reach by 05:00 PM.\n",
            "He is not coming with us.\n",
            "It is his birthday and he has other plans.\n",
            "They have thought about going to the movies.\n",
            "I will not be going to movies.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps for preprocessing the text data we have:\n",
        "\n",
        "\n",
        "\n",
        "1.   Split the article into sentences.\n",
        "2.   For each sentence in the corpus -\n",
        "      1.   Convert the sentence to lowercase\n",
        "      2.   Expand contractions\n",
        "      1.   Lemmatization\n",
        "      2.   Remove stopwords\n",
        "      1.   Remove punctuations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9WoWKImYiO_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for processing the sentences\n",
        "import re\n",
        "\n",
        "def process_sentence(sentence, nlp_object):\n",
        "  #convert to lowercase\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  #expanding contractions\n",
        "  sentence = contractions.fix(sentence)\n",
        "\n",
        "  #lemmatization and removing stopwords\n",
        "  doc = nlp_object(sentence)\n",
        "  sentence = \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
        "\n",
        "  #remove punctuation\n",
        "  for p in string.punctuation:\n",
        "    sentence = sentence.replace(p, \" \")\n",
        "\n",
        "  sentence  = re.sub(r\"\\s+\", \" \", sentence) # replace multiple whitespaces with a singe space\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "G38RfPsjt0KQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "#tqdm to see real time progress\n",
        "tqdm.pandas()\n",
        "\n",
        "#Loading English language pipeline from spaCy: nlp = spacy.load('en_core_web_sm')\n",
        "#It loads the English language processing pipeline from spaCy.\n",
        "#This pipeline includes various components such as tokenization, part-of-speech tagging,\n",
        "#named entity recognition, and dependency parsing, which can be applied to text data.\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')  # English pipeline optimized for CPU\n",
        "\n",
        "def process_article(article_text, nlp_object):\n",
        "  processed_article_sentences = []\n",
        "  #using nltk sentence tokenizer\n",
        "  for sentence in sent_tokenize(article_text):\n",
        "    #preprocessing each sentence using our process_sentence function\n",
        "    processed_article_sentences.append(process_sentence(sentence, nlp_object))\n",
        "\n",
        "  #joining preprocessed sentences as complete pragraph of the article\n",
        "  return \" \".join(processed_article_sentences)\n",
        "\n",
        "df['processed_text'] = df['text'].progress_apply(lambda x : process_article(x, nlp))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2e73205db7d1490d8a890a92e6fee68c",
            "624ccb8e07f844adbf662104666ec228",
            "80479d9bc5594ff1838e020f7f94a598",
            "8348cc697c5947f5af0e4c1cdc98bd6c",
            "6e7f69632a744179aa419601d06b4278",
            "7dd91eadf0da4d148f7048167b7b16e8",
            "ca479a7ebbfb4e79b8fe77e741d462df",
            "952e050b2e2c41d7a25647fd2ed18b2c",
            "5021b77fe45445e1b1e873ca17714687",
            "03886693f3194001afb4cd6d037e71be",
            "ae93d10750f945cf94e95c9319c7ddc4"
          ]
        },
        "id": "OGYulmnqkoya",
        "outputId": "e9ff8f18-5290-48ac-96b4-fb73ad385ff3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/208 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e73205db7d1490d8a890a92e6fee68c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The article text is processed and tokenized. Now we need to find similarity between articles using this processed text."
      ],
      "metadata": {
        "id": "DvVcqWdXukZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Document Similarity**\n",
        "\n",
        "We first need to make a vector representation of the documents. We have already seens two ways of doing it so far\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "  1.  BOW\n",
        "  2.  TF-IDF\n",
        "\n",
        "After the vector representation, we can use the cosine similarity as the similarity metric\n"
      ],
      "metadata": {
        "id": "RsUtXO1QuP5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Similarity using BOW"
      ],
      "metadata": {
        "id": "SVe-W8G2xWZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using CountVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#BOW representation of the dataset using CountVectorizer from scikit-learn\n",
        "count_vectorizer = CountVectorizer(min_df=5)\n",
        "#min_df: ignore terms that have a document frequency strictly lower than the given threshold\n",
        "\n",
        "#learn the vocabulary dictionary and return document-term matrix\n",
        "bow_rep = count_vectorizer.fit_transform(df['processed_text']).todense()\n",
        "#create dataframe\n",
        "bow_features_df = pd.DataFrame(bow_rep)\n",
        "bow_features_df.columns = count_vectorizer.get_feature_names_out()\n",
        "bow_features_df['TITLE'] = df['title']\n",
        "bow_features_df['ID'] = df['id']\n",
        "display(bow_features_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "peEBfo2ct5zH",
        "outputId": "cc2cc7f3-c150-4b65-e71c-7584439d388f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     00  000  01  05  06  07  10  100  1000  101  10k  10x  11  12  120  125  \\\n",
              "0     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
              "1     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
              "2     0    0   0   0   1   0   1    0     0    0    0    0   0   0    0    0   \n",
              "3     0    0   0   0   0   0   0    0     0    0    0    0   1   0    0    0   \n",
              "4     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
              "..   ..  ...  ..  ..  ..  ..  ..  ...   ...  ...  ...  ...  ..  ..  ...  ...   \n",
              "203   1    0   0   0   0   0   1    0     0    0    0    0   0   1    0    0   \n",
              "204   0    0   0   0   0   0   0    0     0    0    0    0   0   1    0    0   \n",
              "205   0    0   0   0   0   0   1    0     0    0    0    0   1   1    0    0   \n",
              "206   0    0   0   0   0   0   5    0     0    0    0    0   0   0    0    0   \n",
              "207   0    0   0   0   0   0   1    0     0    0    0    0   0   0    0    0   \n",
              "\n",
              "     128  13  14  15  150  16  17  18  19  1980  1989  1990  1k  1st  20  200  \\\n",
              "0      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "1      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "2      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "3      0   0   1   1    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "4      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "..   ...  ..  ..  ..  ...  ..  ..  ..  ..   ...   ...   ...  ..  ...  ..  ...   \n",
              "203    0   0   0   0    0   0   0   0   0     0     0     0   0    0   1    0   \n",
              "204    0   0   1   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "205    0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
              "206    0   0   0   3    0   0   0   2   0     0     0     0   0    0   0    0   \n",
              "207    0   0   0   0    0   0   0   0   0     0     0     0   0    0   1    0   \n",
              "\n",
              "     2000  2001  2005  2008  2009  2010  2011  2012  2013  2014  2015  2016  \\\n",
              "0       0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "1       0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "2       0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "3       0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "4       0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "203     1     0     0     1     0     0     0     0     0     0     0     0   \n",
              "204     0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "205     0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "206     0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "207     0     0     0     0     0     0     0     0     0     0     0     0   \n",
              "\n",
              "     2017  2018  2019  2020  2021  21  ...  wise  wish  withdraw  woman  \\\n",
              "0       0     0     0     0     0   0  ...     0     0         0      0   \n",
              "1       0     0     0     0     0   0  ...     0     0         0      0   \n",
              "2       0     0     0     0     1   0  ...     0     0         0      0   \n",
              "3       0     0     0     0     0   0  ...     0     0         0      0   \n",
              "4       1     0     1     0     0   0  ...     0     1         0      0   \n",
              "..    ...   ...   ...   ...   ...  ..  ...   ...   ...       ...    ...   \n",
              "203     0     1     0     0     0   0  ...     0     0         0      0   \n",
              "204     0     0     0     0     0   0  ...     0     0         0      0   \n",
              "205     0     0     0     0     0   0  ...     0     0         0      0   \n",
              "206     1     0     0     0     0   0  ...     0     0         0      0   \n",
              "207     0     0     0     0     0   0  ...     0     0         0      5   \n",
              "\n",
              "     wonder  wonderful  wood  word  work  worker  workflow  working  workout  \\\n",
              "0         0          0     0     2     2       0         0        0        0   \n",
              "1         0          0     0     0     0       0         0        0        0   \n",
              "2         0          0     0     0     4       0         0        0        0   \n",
              "3         0          0     0     0     4       0         0        0        0   \n",
              "4         0          0     0     1     2       0         0        0        0   \n",
              "..      ...        ...   ...   ...   ...     ...       ...      ...      ...   \n",
              "203       1          0     0     0     4       0         0        0        0   \n",
              "204       1          0     0     0     4       0         0        0        0   \n",
              "205       0          0     0     0     0       0         0        0        0   \n",
              "206       0          0     0     0    10       0         0        0        0   \n",
              "207       0          0     0     3     2       0         0        0        0   \n",
              "\n",
              "     world  worried  worry  worse  worsen  worth  wow  wrap  write  writer  \\\n",
              "0        0        0      0      0       0      0    0     0      4       0   \n",
              "1        0        0      0      0       0      0    0     0      1       0   \n",
              "2        0        0      0      0       0      0    0     0      2       0   \n",
              "3        3        0      1      0       0      0    0     0      4       0   \n",
              "4        0        0      0      0       0      0    0     0      0       0   \n",
              "..     ...      ...    ...    ...     ...    ...  ...   ...    ...     ...   \n",
              "203      0        0      0      0       1      0    0     0      1       0   \n",
              "204      0        0      0      0       0      0    0     0      0       0   \n",
              "205      0        0      0      0       0      0    0     0      0       0   \n",
              "206      1        0      0      0       0      0    0     0      3       0   \n",
              "207      0        0      1      0       0      0    0     0      2       0   \n",
              "\n",
              "     writing  wrong  www  xgboost  xi  yeah  year  yearly  yell  yellow  yes  \\\n",
              "0          0      0    0        1   0     0     0       0     0       0    0   \n",
              "1          0      0    1        0   0     0     0       0     0       0    0   \n",
              "2          0      1    1        0   0     0     1       0     0       0    0   \n",
              "3          0      0    0        0   0     0     0       0     0       0    1   \n",
              "4          0      0    0        0   0     0     0       0     0       0    0   \n",
              "..       ...    ...  ...      ...  ..   ...   ...     ...   ...     ...  ...   \n",
              "203        0      3    0        0   0     0     4       0     0       0    0   \n",
              "204        0      2    3        0   0     0     1       0     0       0    1   \n",
              "205        0      0    0        0   0     0     0       0     0       0    0   \n",
              "206        0      0    1        0   0     0     2       0     0       0    0   \n",
              "207        0      1    0        0   0     0     1       0     0       0    2   \n",
              "\n",
              "     yesterday  yield  yo  york  you  young  youtube  zero  zhou  zip  zombie  \\\n",
              "0            0      0   0     0    0      0        0     0     0    0       0   \n",
              "1            0      0   0     0    0      0        0     0     0    0       0   \n",
              "2            0      0   0     0    0      0        0     0     0    0       0   \n",
              "3            0      0   0     0    0      0        0     1     0    0       0   \n",
              "4            0      0   0     0    0      0        0     0     0    0       0   \n",
              "..         ...    ...  ..   ...  ...    ...      ...   ...   ...  ...     ...   \n",
              "203          0      0   0     0    0      1        0     0     0    0       0   \n",
              "204          0      0   0     0    1      0        0     0     0    0       0   \n",
              "205          0      0   0     0    0      0        0     1     0    0       0   \n",
              "206          0      0   0     0    0      0        0     0     0    0       1   \n",
              "207          0      0   2     0    0      0        0     0     0    0       0   \n",
              "\n",
              "     zone  zoom  zuckerberg  \\\n",
              "0       0     0           0   \n",
              "1       0     0           0   \n",
              "2       0     0           0   \n",
              "3       0     0           0   \n",
              "4       0     0           0   \n",
              "..    ...   ...         ...   \n",
              "203     0     0           0   \n",
              "204     2     0           0   \n",
              "205     0     0           0   \n",
              "206     1     0           0   \n",
              "207     0     0           0   \n",
              "\n",
              "                                                 TITLE   ID  \n",
              "0     Ensemble methods: bagging, boosting and stacking    1  \n",
              "1                        Understanding AUC - ROC Curve    2  \n",
              "2    How to work with object detection datasets in ...    3  \n",
              "3    11 Dimensionality reduction techniques you sho...    4  \n",
              "4                          The Time Series Transformer    5  \n",
              "..                                                 ...  ...  \n",
              "203    Type 2 Diabetes Reversal  The Quick Start Guide  210  \n",
              "204            How a 22 Day Water Fast Changed My Life  211  \n",
              "205                                 Breaking Your Fast  212  \n",
              "206           11 Unusual Tips for How to Wake Up Early  213  \n",
              "207  The 3 Biggest Mistakes Women Make On The Ketog...  214  \n",
              "\n",
              "[208 rows x 3714 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-999d839a-3f4e-4ab6-b73e-fdcf57cf9214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>10k</th>\n",
              "      <th>10x</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>125</th>\n",
              "      <th>128</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>1980</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1k</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>200</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2005</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>21</th>\n",
              "      <th>...</th>\n",
              "      <th>wise</th>\n",
              "      <th>wish</th>\n",
              "      <th>withdraw</th>\n",
              "      <th>woman</th>\n",
              "      <th>wonder</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>wood</th>\n",
              "      <th>word</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>workflow</th>\n",
              "      <th>working</th>\n",
              "      <th>workout</th>\n",
              "      <th>world</th>\n",
              "      <th>worried</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worsen</th>\n",
              "      <th>worth</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>www</th>\n",
              "      <th>xgboost</th>\n",
              "      <th>xi</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yearly</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yield</th>\n",
              "      <th>yo</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhou</th>\n",
              "      <th>zip</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Understanding AUC - ROC Curve</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>How to work with object detection datasets in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The Time Series Transformer</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Type 2 Diabetes Reversal  The Quick Start Guide</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>How a 22 Day Water Fast Changed My Life</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Breaking Your Fast</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11 Unusual Tips for How to Wake Up Early</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The 3 Biggest Mistakes Women Make On The Ketog...</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 3714 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-999d839a-3f4e-4ab6-b73e-fdcf57cf9214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-999d839a-3f4e-4ab6-b73e-fdcf57cf9214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-999d839a-3f4e-4ab6-b73e-fdcf57cf9214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b915648-460f-44ff-b3ab-63cf2460f6d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b915648-460f-44ff-b3ab-63cf2460f6d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b915648-460f-44ff-b3ab-63cf2460f6d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_96d82a69-0f14-4fd5-8089-4631ae16e86c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bow_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_96d82a69-0f14-4fd5-8089-4631ae16e86c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bow_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bow_features_df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualise the text vector using T-SNE**"
      ],
      "metadata": {
        "id": "7zsaiGkHPW8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "#using t-sne to observe any trends, and clusters.\n",
        "tsne = TSNE(n_components=2) #n_components: estimated number of components\n",
        "tsne_bow_features = tsne.fit_transform(bow_features_df[count_vectorizer.get_feature_names_out()].values)\n",
        "tsne_bow_features_df = pd.DataFrame(tsne_bow_features)\n",
        "tsne_bow_features_df.columns = [\"C1\", \"C2\"]\n",
        "tsne_bow_features_df[\"TITLE\"] = bow_features_df[\"TITLE\"]\n",
        "tsne_bow_features_df[\"ID\"] = bow_features_df[\"ID\"]\n",
        "\n",
        "display(tsne_bow_features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "smXDsZf9t52V",
        "outputId": "95ee7c5f-b069-4c42-8e03-101c80109c10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           C1        C2                                              TITLE  \\\n",
              "0    4.263233  1.649894   Ensemble methods: bagging, boosting and stacking   \n",
              "1    0.509500 -1.138046                      Understanding AUC - ROC Curve   \n",
              "2    3.320558  0.437742  How to work with object detection datasets in ...   \n",
              "3    4.495707 -0.295115  11 Dimensionality reduction techniques you sho...   \n",
              "4    1.745166  0.694401                        The Time Series Transformer   \n",
              "..        ...       ...                                                ...   \n",
              "203 -4.660771 -0.762061    Type 2 Diabetes Reversal  The Quick Start Guide   \n",
              "204 -5.588498 -2.407030            How a 22 Day Water Fast Changed My Life   \n",
              "205 -5.606082 -2.263056                                 Breaking Your Fast   \n",
              "206 -3.630148 -3.033635           11 Unusual Tips for How to Wake Up Early   \n",
              "207 -5.436822 -1.042816  The 3 Biggest Mistakes Women Make On The Ketog...   \n",
              "\n",
              "      ID  \n",
              "0      1  \n",
              "1      2  \n",
              "2      3  \n",
              "3      4  \n",
              "4      5  \n",
              "..   ...  \n",
              "203  210  \n",
              "204  211  \n",
              "205  212  \n",
              "206  213  \n",
              "207  214  \n",
              "\n",
              "[208 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c539122-e79c-4abd-b84e-3bf90a2737ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.263233</td>\n",
              "      <td>1.649894</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.509500</td>\n",
              "      <td>-1.138046</td>\n",
              "      <td>Understanding AUC - ROC Curve</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.320558</td>\n",
              "      <td>0.437742</td>\n",
              "      <td>How to work with object detection datasets in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.495707</td>\n",
              "      <td>-0.295115</td>\n",
              "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.745166</td>\n",
              "      <td>0.694401</td>\n",
              "      <td>The Time Series Transformer</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>-4.660771</td>\n",
              "      <td>-0.762061</td>\n",
              "      <td>Type 2 Diabetes Reversal  The Quick Start Guide</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-5.588498</td>\n",
              "      <td>-2.407030</td>\n",
              "      <td>How a 22 Day Water Fast Changed My Life</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>-5.606082</td>\n",
              "      <td>-2.263056</td>\n",
              "      <td>Breaking Your Fast</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>-3.630148</td>\n",
              "      <td>-3.033635</td>\n",
              "      <td>11 Unusual Tips for How to Wake Up Early</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>-5.436822</td>\n",
              "      <td>-1.042816</td>\n",
              "      <td>The 3 Biggest Mistakes Women Make On The Ketog...</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c539122-e79c-4abd-b84e-3bf90a2737ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c539122-e79c-4abd-b84e-3bf90a2737ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c539122-e79c-4abd-b84e-3bf90a2737ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08935666-9ee1-4f5f-bf61-69bcff48d603\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08935666-9ee1-4f5f-bf61-69bcff48d603')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08935666-9ee1-4f5f-bf61-69bcff48d603 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c167daa1-6caa-459c-8785-705f923f493f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tsne_bow_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c167daa1-6caa-459c-8785-705f923f493f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tsne_bow_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tsne_bow_features_df",
              "summary": "{\n  \"name\": \"tsne_bow_features_df\",\n  \"rows\": 208,\n  \"fields\": [\n    {\n      \"column\": \"C1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          -3.6442360877990723,\n          2.579415798187256,\n          4.172553539276123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          0.49529120326042175,\n          2.7417216300964355,\n          0.8876516222953796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TITLE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          \"How I transformed $6,000 to $3,000,000\",\n          \"Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences\",\n          \"Train/Test Split and Cross Validation in Python\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62,\n        \"min\": 1,\n        \"max\": 214,\n        \"num_unique_values\": 208,\n        \"samples\": [\n          168,\n          16,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "#scatter plot of t-sne for the BOW representation\n",
        "\n",
        "title = \"T-distributed Stochastic Neighbour Embedding for BOW document representation\"\n",
        "\n",
        "fig = px.scatter(tsne_bow_features_df, x=\"C1\", y=\"C2\", hover_data=['TITLE'], title=title)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bs8kC53royXF",
        "outputId": "92b69b34-3567-4547-803d-967c6930fe6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"6040994d-130e-4c67-b5f5-59d64d64a7dd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6040994d-130e-4c67-b5f5-59d64d64a7dd\")) {                    Plotly.newPlot(                        \"6040994d-130e-4c67-b5f5-59d64d64a7dd\",                        [{\"customdata\":[[\"Ensemble methods: bagging, boosting and stacking\"],[\"Understanding AUC - ROC Curve\"],[\"How to work with object detection datasets in COCO format\"],[\"11 Dimensionality reduction techniques you should know in 2021\"],[\"The Time Series Transformer\"],[\"Learning a Personalized Homepage\"],[\"6 Data Science Certificates To Level Up Your Career\"],[\"Transformers Explained Visually (Part 2): How it works, step-by-step\"],[\"60 Python Projects with Source Code\"],[\"Geometric foundations of Deep Learning\"],[\"Machine Learning Basics with the K-Nearest Neighbors Algorithm\"],[\"Building RNN, LSTM, and GRU for time series using PyTorch\"],[\"Algorithms of the Mind\"],[\"4 Reasons Why Economists Make Great Data Scientists (And Why No One Tells Them)\"],[\"How To Create A Chatbot with Python & Deep Learning In Less Than An Hour\"],[\"Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences\"],[\"Illustrated Guide to LSTM's and GRU's: A step by step explanation\"],[\"How to go from a Python newbie to a Google Certified TensorFlow Developer under two months\"],[\"17 Clustering Algorithms Used In Data Science and Mining\"],[\"Introduction to Genetic Algorithms  Including Example Code\"],[\"Photoreal Roman Emperor Project\"],[\"Fundamental Techniques of Feature Engineering for Machine Learning\"],[\"How I Got a Job at DeepMind as a Research Engineer (without a Machine Learning Degree!)\"],[\"Towards the end of deep learning and the beginning of AGI\"],[\"Tutorial: Document Classification using WEKA\"],[\"Understanding Random Forest\"],[\"Probability concepts explained: Maximum likelihood estimation\"],[\"Transformers Explained Visually (Part 3): Multi-head Attention, deep dive\"],[\"180 Data Science and Machine Learning Projects with Python\"],[\"5 Online Courses I Took as a Self-Taught Data Scientist\"],[\"Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning\"],[\"9 Distance Measures in Data Science\"],[\"The Sexiest Job of the 21st Century Isn't \\\"Sexy\\\" Anymore\"],[\"Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks\"],[\"A Comprehensive Guide to Convolutional Neural Networks  the ELI5 way\"],[\"20 Necessary Requirements of a Perfect Laptop for Data Science and Machine Learning Tasks\"],[\"3 Beginner Mistakes I've Made in My Data Science Career\"],[\"Understanding Variational Autoencoders (VAEs)\"],[\"Setting Up a New M1 MacBook for Data Science\"],[\"Are The New M1 Macbooks Any Good for Data Science? Let's Find Out\"],[\"Simple and Multiple Linear Regression in Python\"],[\"I tripled my income with data science. Here's how.\"],[\"Keyword Extraction process in Python with Natural Language Processing(NLP)\"],[\"Machine learning models for 100% better returns in Algo-trading\"],[\"How to Install Ubuntu Desktop With a Graphical User Interface in WSL2\"],[\"Understanding Contrastive Learning\"],[\"Understanding Semantic Segmentation with UNET\"],[\"How Transformers Work\"],[\"Yes you should understand backprop\"],[\"PCA using Python (scikit-learn)\"],[\"Hyperparameter Tuning the Random Forest in Python\"],[\"Top 3 Reasons Why I Sold My M1 Macbook Pro as a Data Scientist\"],[\"TRAIN A CUSTOM YOLOv4 OBJECT DETECTOR (Using Google Colab)\"],[\"6 Machine Learning Certificates to Pursue in 2021\"],[\"What to do with \\\"small\\\" data?\"],[\"Time Series Forecasting with PyCaret Regression Module\"],[\"15 Habits I Learned from Highly Effective Data Scientists\"],[\"OVER 100 Data Scientist Interview Questions and Answers!\"],[\"Activation Functions in Neural Networks\"],[\"A One-Stop Shop for Principal Component Analysis\"],[\"5 Things You Should Know About Covariance\"],[\"How to build your own Neural Network from scratch in Python\"],[\"The best explanation of Convolutional Neural Networks on the Internet!\"],[\"Lambda Functions with Practical Examples in Python\"],[\"The Complete Guide to Time Series Analysis and Forecasting\"],[\"8 Ways to Filter Pandas Dataframes\"],[\"Standing with Dr. Timnit Gebru  #ISupportTimnit #BelieveBlackWomen\"],[\"Visualising high-dimensional datasets using PCA and t-SNE in Python\"],[\"How to Study for the Google Data Analytics Professional Certificate\"],[\"Is Data Science Still a Rising Career in 2021\"],[\"Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks\"],[\"How To Grow From Non-Coder to Data Scientist in 6 Months\"],[\"Apple's New M1 Chip is a Machine Learning Beast\"],[\"Train\\u002fTest Split and Cross Validation in Python\"],[\"Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT\"],[\"The 5 Clustering Algorithms Data Scientists Need to Know\"],[\"Building A Logistic Regression in Python, Step by Step\"],[\"Springer has released 65 Machine Learning and Data books for free\"],[\"Every single Machine Learning course on the internet, ranked by your reviews\"],[\"TensorFlow Tutorial Part 1\"],[\"The 7 Best Data Science and Machine Learning Podcasts\"],[\"Random Forest in Python\"],[\"How to Land a Data Analytics Job in 6 Months\"],[\"What is a Transformer?\"],[\"Fundamentals Of Statistics For Data Scientists and Analysts\"],[\"Is Google's AI research about to implode?\"],[\"Machine Learning is Fun! Part 2\"],[\"Understanding Generative Adversarial Networks (GANs)\"],[\"17 types of similarity and dissimilarity measures used in data science.\"],[\"Deep Learning Is Going to Teach Us All the Lesson of Our Lives: Jobs Are for Machines\"],[\"I interviewed at five top companies in Silicon Valley in five days, and luckily got five job offers\"],[\"Advantages and Disadvantages of Artificial Intelligence\"],[\"Could Nim Replace Python?\"],[\"An End-to-End Project on Time Series Analysis and Forecasting with Python\"],[\"Data Scientists Will be Extinct in 10 Years\"],[\"Import all Python libraries in one line of code\"],[\"Enchanted Random Forest\"],[\"Machine Learning in a Week\"],[\"50+ Statistics Interview Questions and Answers for Data Scientists for 2022\"],[\"Top 10 Data Science Projects for Beginners\"],[\"Check For a Substring in a Pandas DataFrame Column\"],[\"Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning\"],[\"Everything You Need to Know About Artificial Neural Networks\"],[\"Ways to Detect and Remove the Outliers\"],[\"How to Crush the Crypto Market, Quit Your Job, Move to Paradise and Do Whatever You Want the Rest of Your Life\"],[\"Bitcoin Is Venice\"],[\"How I Built a Net Worth of $500,000 Before Age 30\"],[\"Nassim Nicholas Taleb on Self-Education and Doing the Math (Ep. 41  Live at Mercatus)\"],[\"Public Mint Polkastarter IDO: Launching 23rd of February, Whitelist Now Open!\"],[\"This is How I Made $40k In Passive Income By Age 26\"],[\"Introducing The Iron Bank\"],[\"I used Acorns, Robinhood, and Stash for 2 years. This is what I learned and earned.\"],[\"Explaining blockchain  how proof of work enables trustless consensus\"],[\"Wealthfront:Silicon Valley Tech at Wall Street Prices\"],[\"Crypto Trading Bots  A helpful guide for beginners [2020]\"],[\"Why People Still Don't Get Cryptocurrency\"],[\"Australia's Economy is a House of Cards\"],[\"My First Two Months Trading Stocks with Robinhood\"],[\"What It Takes to Go from $0 to $1 Million in Less Than One Year\"],[\"Tesla Is Dead (And Elon Musk Knows It)\"],[\"Uber's Credit Card Is Bankrupting Restaurants... and It's All Your Fault\"],[\"A Quick Starter Guide to Leveraged Trading at BitMEX\"],[\"I Made $3 Million in Crypto. These are the 26 Rules I Learned.\"],[\"The Black-Scholes formula, explained\"],[\"You Will Never Be Rich If You Keep Doing These 10 things\"],[\"Heroes Give, Superheroes Borrow\"],[\"Could Bitcoin's Bull Market End Next Month?\"],[\"The Exact Steps I Followed to Make $1,500+ of Passive Income Every Month\"],[\"You May Have A Poor Person's Mindset And Not Know It\"],[\"A Definitive Guide to Why Life Is So Terrible for Most Millennials\"],[\"The Berkshire Hathaway of The Internet\"],[\"How to invest in Bitcoin properly. Blockchain and other cryptocurrencies\"],[\"Machine learning in finance: Why, what & how\"],[\"Minimum Wage Artists\"],[\"Richart + @GoGo \"],[\"How to store Bitcoins and other cryptocurrencies properly.\"],[\"I was wrong about Ethereum\"],[\"Deep Learning the Stock Market\"],[\"Financial Fridays: It's Financial Suicide To Own A House\"],[\"Gauge Theory Does Not Fix This\"],[\"High Frequency Trading on the Coinbase Exchange\"],[\"A $1000 Bitcoin Investment Won't Make You Rich\"],[\"How To Legally Own Another Person\"],[\"5 Things NOT to Do in the Robinhood App for Stock Trading\"],[\"The One Word That Explains Why Economics Professors Are Not Billionaires\"],[\"Building your credit history\"],[\"I Retired at 35  Here Are 5 Lessons from My First 6 Months of Freedom\"],[\"Why you should never use Upwork, ever.\"],[\"Facebook Can't Be Fixed.\"],[\"A comprehensive guide to downloading stock prices in Python\"],[\"Detecting Credit Card Fraud Using Machine Learning\"],[\"2018  & : KOKO COMBO icash \"],[\"Is Wealthfront Worth it?\"],[\"How I Slowly Became A \\\"Middle-Class\\\" Millionaire\"],[\"SPY vs. QQQ: Investing in Different Indexes\"],[\"I Won $104 Million for Blowing the Whistle on My CompanyBut Somehow I Was the Only One Who Went to Jail\"],[\"Robinhood Lends \\\"Your\\\" Shares to Short Sellers (and Keeps All the Proceeds)\"],[\"The Secret to Making 2000% in Stocks Overnight, the Anavex story.\"],[\"4 Unusual Side Hustles I Do to Earn an Extra $1,500 a Month\"],[\"Meet 'Spoofy'. How a Single entity dominates the price of Bitcoin.\"],[\"How I Started Saving a TON of Money.\"],[\"How I transformed $6,000 to $3,000,000\"],[\"Cliff Asness on Marvel vs. DC and Why Never to Share a Gym with Cirque du Soleil (Ep. 5  Live at Mason)\"],[\"Paypal froze our funds, then offered us a business loan\"],[\"A Visual Explanation of Algorithmic Stablecoins\"],[\"Algorithmic Trading Bot: Python\"],[\"Chernobyl's Blown Up Reactor 4 Just Woke Up\"],[\"The Unexpected Case of the Disappearing Flu\"],[\"The Diet & Workout Plan of a Full-Time Traveling Family  HIS\"],[\"The Cult of Work You Never Meant to Join\"],[\"5 Things to do in the First 24 Hours of a Cold or Flu\"],[\"The Sweet Spot for Intermittent Fasting\"],[\"The 6 Types of ICU Nurse\"],[\"How to biohack your intelligence  with everything from sex to modafinil to MDMA\"],[\"8 Common Arguments Against Vaccines\"],[\"A Reasonably Detailed Guide to Optimizing Your iPhone for Productivity, Focus and Your Own Health\"],[\"The cure for type 2 diabetes is known, but few are aware\"],[\"Face mapping: how to deal with acne like a true detective\"],[\"I'm 32 and spent $200k on biohacking. Became calmer, thinner, extroverted, healthier & happier.\"],[\"I need more iron\"],[\"What I Learned From Quitting Coffee After 15 Years Of Daily Consumption\"],[\"The forgotten art of untucking the tail\"],[\"Hip Replacement Isn't What It Used To Be 12 Weeks Ago\"],[\"Coronavirus: Why You Must Act Now\"],[\"Manufacturers have been using nanotechnology-derived graphene in face masks  now there are safety concerns\"],[\"Eben Byers: The Man Who Drank Radioactive Water Until His Jaw Fell Off\"],[\"My Intermittent Fasting Lifestyle: How I Dropped 50 Pounds\"],[\"I Stopped Drinking for 30 Days. Here's What Happened.\"],[\"How to lose 10+ pounds of fat a month- even if you have a slow metabolism\"],[\"If You're Buying Your Weed Solely Based on the THC Level, You're Doing it Wrong.\"],[\"2016 Is Not Killing People\"],[\"How I Learned to Sleep Only Three Hours Per Night (and Why You Should Too)\"],[\"I fasted for 11 days, here is what happened.\"],[\"Coronavirus: The Hammer and the Dance\"],[\"What Happens in Your Body When You Quit Drinking\"],[\"The Science Behind Fat Metabolism\"],[\"The Easiest Way to Lose 125 Pounds Is to Gain 175 Pounds\"],[\"7 things I did to reboot my life.\"],[\"How I lost 10kg in 60 days: My 7-step weight loss plan\"],[\"The Foo Fighters' AIDS denialism should be on the record\"],[\"The Uncut History of Male Circumcision\"],[\"10 Things You Can Do This Morning To Heal Your Anxiety\"],[\"I just lost 100 pounds. Here's whyalmost nobody else will!\"],[\"Type 2 Diabetes Reversal  The Quick Start Guide\"],[\"How a 22 Day Water Fast Changed My Life\"],[\"Breaking Your Fast\"],[\"11 Unusual Tips for How to Wake Up Early\"],[\"The 3 Biggest Mistakes Women Make On The Ketogenic Diet (And How To Fix Them)\"]],\"hovertemplate\":\"C1=%{x}\\u003cbr\\u003eC2=%{y}\\u003cbr\\u003eTITLE=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[4.263232707977295,0.5095002055168152,3.3205578327178955,4.495707035064697,1.7451664209365845,1.0182868242263794,4.4797043800354,0.9242973327636719,0.1198682188987732,-0.7677714228630066,4.377514362335205,3.871175765991211,0.291708767414093,3.3884847164154053,1.6961208581924438,2.579415798187256,-1.6700915098190308,2.1095974445343018,6.290342807769775,-0.0203972440212965,-0.04038648307323456,2.6966159343719482,1.6877392530441284,0.6870772242546082,1.7119638919830322,3.9818801879882812,5.936087131500244,0.9161611199378967,0.07774556428194046,3.6809041500091553,0.2545483112335205,6.978564262390137,4.091104030609131,-1.0535365343093872,-0.5166085362434387,1.1777195930480957,3.3860950469970703,5.917224407196045,0.4722540080547333,1.123897671699524,3.0175960063934326,2.5541040897369385,0.14072395861148834,-2.1394453048706055,1.5115629434585571,0.7888941168785095,-0.48623180389404297,0.9281858801841736,-0.19377680122852325,4.352220058441162,4.373189449310303,0.3031046986579895,1.19861900806427,4.827081203460693,4.037537097930908,3.381023645401001,4.4118804931640625,6.524606704711914,-0.30713680386543274,2.576388120651245,1.3992737531661987,-1.0952249765396118,-0.9201173186302185,-0.29812178015708923,4.314693450927734,0.9402410387992859,5.739119529724121,4.351150035858154,3.7050325870513916,4.055196285247803,-1.2599663734436035,4.13539457321167,1.3652154207229614,4.172553539276123,2.0827202796936035,6.021377086639404,2.58327317237854,1.3628147840499878,5.519354343414307,0.8554367423057556,1.9946422576904297,4.766713619232178,3.413585662841797,0.9546951055526733,6.58999490737915,2.957496166229248,3.1781415939331055,6.149357795715332,7.020613193511963,-3.0438950061798096,1.6778088808059692,0.7847851514816284,2.0162808895111084,4.254243850708008,3.621218681335449,-0.48116305470466614,3.981912612915039,2.307206153869629,6.439314842224121,3.470703363418579,1.0636149644851685,1.9530647993087769,-1.3066946268081665,3.6826486587524414,-4.038499355316162,-1.776308536529541,-2.096644639968872,-4.641490459442139,-0.08607576787471771,-1.636061191558838,1.657267689704895,-3.501337766647339,-1.6202423572540283,-1.4691944122314453,0.08105059713125229,-3.2124183177948,-3.625154495239258,-3.284198045730591,-0.5153416395187378,-1.8626749515533447,1.854667067527771,-0.6177409291267395,-1.008816123008728,-2.1355810165405273,-3.175123691558838,-0.4075809419155121,-1.2187978029251099,-3.7576355934143066,-2.907731533050537,-2.6091678142547607,-1.5620315074920654,-1.7548969984054565,5.418508052825928,-0.8788643479347229,-0.09550272673368454,-0.6459760069847107,-0.34644803404808044,1.6174545288085938,-2.2628626823425293,-1.8746906518936157,0.11371459811925888,-1.2770286798477173,-2.5450069904327393,-3.3600237369537354,-2.6859254837036133,-0.10942681133747101,-3.003690242767334,-0.5364845395088196,-0.851519763469696,-1.157051920890808,3.5314812660217285,-0.11007753014564514,-1.4550634622573853,-1.4882701635360718,-1.3197506666183472,-0.7348707914352417,0.6855189204216003,-3.3713977336883545,0.015949634835124016,-0.28879043459892273,-1.0244468450546265,-3.6442360877990723,-4.6217041015625,-0.37794622778892517,1.3244333267211914,-1.6304142475128174,0.057619739323854446,0.7162705063819885,-3.9249675273895264,-3.788888692855835,-0.1478186994791031,0.5266884565353394,-1.5207765102386475,-6.002920150756836,0.07005022466182709,-6.135438442230225,-4.944154262542725,-0.3972388505935669,-5.945891857147217,1.8278648853302002,-2.222801685333252,-1.1847472190856934,-3.331677198410034,-6.2889580726623535,1.2259161472320557,-0.4999135732650757,-5.66697359085083,-2.834005355834961,-4.977075576782227,-1.4032232761383057,-0.4513731300830841,-2.8719236850738525,-5.996212005615234,-6.248978137969971,-2.2507078647613525,-5.612716197967529,-5.023534297943115,-4.858959197998047,-4.57119083404541,-0.1433592289686203,0.06584002077579498,-4.063277721405029,-5.239461898803711,-4.660770893096924,-5.588498115539551,-5.606081962585449,-3.630147933959961,-5.436821937561035],\"xaxis\":\"x\",\"y\":[1.6498944759368896,-1.1380460262298584,0.4377416968345642,-0.29511475563049316,0.6944008469581604,-0.046176038682460785,-3.8596205711364746,5.10964298248291,-1.891711950302124,2.2469165325164795,-1.395779013633728,1.5036695003509521,1.652921199798584,-2.1596481800079346,2.0352847576141357,2.7417216300964355,1.8212491273880005,-2.4806699752807617,-1.492471694946289,-1.0436300039291382,-1.9689090251922607,0.5306185483932495,-7.240968704223633,0.3270922005176544,-0.22124676406383514,-6.146029472351074,-0.03356330841779709,5.123129367828369,-1.9442570209503174,-3.5278258323669434,1.9526115655899048,-2.392827272415161,-2.4694674015045166,2.9472784996032715,3.004253625869751,-2.344517946243286,-2.251019239425659,-0.0740068182349205,-1.9492419958114624,-1.7865099906921387,0.0026959655806422234,-2.6896491050720215,-0.8642576932907104,0.41975465416908264,2.422243356704712,1.2110446691513062,3.3020925521850586,5.013509273529053,-0.3312009572982788,-0.40579405426979065,1.1614896059036255,-1.9297757148742676,2.5967252254486084,-4.095983028411865,0.931509256362915,0.3652592599391937,-2.503706455230713,1.2951043844223022,0.3565417230129242,-0.460861474275589,-0.9989577531814575,2.2171196937561035,2.255906105041504,0.47665244340896606,3.213757038116455,-0.46678823232650757,-4.337434768676758,-0.5604612827301025,-3.8642866611480713,-2.440570831298828,1.0169861316680908,-2.968837261199951,-1.9155619144439697,0.8876516222953796,1.9354153871536255,-1.5794756412506104,-0.4335830807685852,-3.890320301055908,-4.174591541290283,-1.439703345298767,-1.766560435295105,1.0695605278015137,-3.1216611862182617,5.150369644165039,1.3422224521636963,2.158592462539673,2.1120738983154297,0.04440650716423988,-2.319275140762329,-1.1938836574554443,-7.07647180557251,-2.7573165893554688,-4.092502117156982,3.103078603744507,-1.9072887897491455,-0.688675045967102,-6.1164350509643555,-1.752368450164795,1.1679091453552246,-3.1399805545806885,-0.6026378273963928,-1.340611219406128,2.3455896377563477,-1.5173022747039795,-6.425145149230957,-7.289148330688477,-3.752656936645508,-5.177978038787842,-2.0499627590179443,-4.42991304397583,-5.289925575256348,-0.03675692528486252,-2.8774397373199463,-4.707552433013916,-5.4472527503967285,-6.154270172119141,-6.763699054718018,0.253418505191803,-3.199958324432373,-1.0095304250717163,-3.333118200302124,-7.1780595779418945,-6.831596851348877,-0.4295174777507782,-5.5705461502075195,-2.428276538848877,-6.400245666503906,-5.050699234008789,-5.576948642730713,-4.716659069061279,-3.3954696655273438,-7.105356216430664,-3.453587055206299,-2.73559832572937,-2.027707576751709,-1.3961100578308105,-4.622641086578369,1.425181269645691,-4.2433319091796875,-6.062836647033691,-5.685253620147705,-6.385079383850098,-4.52712345123291,0.35045647621154785,-5.83476448059082,-2.2339367866516113,-4.337643146514893,-3.9754531383514404,-1.7669650316238403,-0.47182631492614746,-0.5970381498336792,-2.0555481910705566,-4.707488536834717,-3.758451223373413,-1.3222991228103638,-3.443819761276245,-4.2369794845581055,0.7606107592582703,-3.9873013496398926,-6.240663528442383,-2.9984772205352783,0.49529120326042175,-6.000515460968018,-2.533451795578003,-5.103076934814453,0.07730690389871597,-2.0438928604125977,-3.0345516204833984,-2.377594470977783,-3.541053295135498,-2.1071927547454834,-3.581988573074341,-2.4608113765716553,-4.02417516708374,-3.412673234939575,-4.298035621643066,-1.1537251472473145,-1.8292609453201294,-3.3015589714050293,-5.594540596008301,-1.858697772026062,-1.5366004705429077,-2.962780237197876,-6.297954082489014,-3.0797319412231445,-2.277982234954834,-2.30387282371521,-2.389744758605957,-1.8242526054382324,-2.282883405685425,-2.300248146057129,-2.910085439682007,-2.341848373413086,-6.27559757232666,-2.019196033477783,-0.9100145697593689,-3.9633007049560547,-4.166628837585449,-1.8985391855239868,-2.721292495727539,-2.3810770511627197,-2.6206116676330566,-3.6417598724365234,-0.7620609998703003,-2.4070301055908203,-2.2630555629730225,-3.033635139465332,-1.042816162109375],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"C1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"C2\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"T-distributed Stochastic Neighbour Embedding for BOW document representation\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6040994d-130e-4c67-b5f5-59d64d64a7dd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting similar documents**"
      ],
      "metadata": {
        "id": "F7Q8f8H7sOld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_similar_documents(all_article_rep_df, article_id, features):\n",
        "  #extracting features of a article\n",
        "  this_article_rep = all_article_rep_df[all_article_rep_df[\"ID\"] == article_id][features]\n",
        "  other_article_rep = all_article_rep_df[all_article_rep_df[\"ID\"] != article_id][features]\n",
        "  #calculating cosine similarity\n",
        "  similarity_matrix = cosine_similarity(this_article_rep, other_article_rep)\n",
        "  similar_articles = list(zip(similarity_matrix[0].tolist(), all_article_rep_df[\"TITLE\"].tolist()))\n",
        "  #sorting\n",
        "  similar_articles = sorted(similar_articles, key = lambda x : x[0], reverse = True)\n",
        "  print(\"Reference Article : {}\".format(all_article_rep_df[all_article_rep_df[\"ID\"] == article_id][\"TITLE\"].values[0]))\n",
        "\n",
        "  print(\"**** Similar Articles ****\")\n",
        "  #top 5 similar articles\n",
        "  for score, title in similar_articles[:5]:\n",
        "    print(title)\n",
        "  print()\n",
        "\n",
        "# Let us check top 5 similar articles for some of the articles in our corpus\n",
        "get_similar_documents(bow_features_df, 90, count_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(bow_features_df, 80, count_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(bow_features_df, 150, count_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(bow_features_df, 205, count_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUVkVIzJoy8y",
        "outputId": "5b32a3a5-d9e4-4248-a088-29cd101ef8a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference Article : 17 types of similarity and dissimilarity measures used in data science.\n",
            "**** Similar Articles ****\n",
            "9 Distance Measures in Data Science\n",
            "17 Clustering Algorithms Used In Data Science and Mining\n",
            "Machine Learning Basics with the K-Nearest Neighbors Algorithm\n",
            "OVER 100 Data Scientist Interview Questions and Answers!\n",
            "Fundamental Techniques of Feature Engineering for Machine Learning\n",
            "\n",
            "Reference Article : TensorFlow Tutorial Part 1\n",
            "**** Similar Articles ****\n",
            "How to go from a Python newbie to a Google Certified TensorFlow Developer under two months\n",
            "Enchanted Random Forest\n",
            "The 7 Best Data Science and Machine Learning Podcasts\n",
            "Time Series Forecasting with PyCaret Regression Module\n",
            "PCA using Python (scikit-learn)\n",
            "\n",
            "Reference Article : The One Word That Explains Why Economics Professors Are Not Billionaires\n",
            "**** Similar Articles ****\n",
            "Why People Still Don't Get Cryptocurrency\n",
            "You May Have A Poor Person's Mindset And Not Know It\n",
            "You Will Never Be Rich If You Keep Doing These 10 things\n",
            "How I transformed $6,000 to $3,000,000\n",
            "The Exact Steps I Followed to Make $1,500+ of Passive Income Every Month\n",
            "\n",
            "Reference Article : How I lost 10kg in 60 days: My 7-step weight loss plan\n",
            "**** Similar Articles ****\n",
            "10 Things You Can Do This Morning To Heal Your Anxiety\n",
            "How to lose 10+ pounds of fat a month- even if you have a slow metabolism\n",
            "The Diet & Workout Plan of a Full-Time Traveling Family  HIS\n",
            "The cure for type 2 diabetes is known, but few are aware\n",
            "The Easiest Way to Lose 125 Pounds Is to Gain 175 Pounds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Similarity using TF-IDF**"
      ],
      "metadata": {
        "id": "bAlO71trxxIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#TF-IDF representation of the dataset using TfidfVectorizer from scikit learn\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=5)\n",
        "#min_df - ignores the terms that have a document frequency less than the given threshold\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(df['processed_text']).todense()\n",
        "tfidf_features_df = pd.DataFrame(tfidf_features)\n",
        "tfidf_features_df.columns = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_features_df['TITLE'] = df['title']\n",
        "tfidf_features_df['ID'] = df['id']\n",
        "display(tfidf_features_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "GtFo1qTQxeXF",
        "outputId": "67f55514-318d-486a-9962-b70830f7daca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           00  000   01   05        06   07        10  100  1000  101  10k  \\\n",
              "0    0.000000  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.0   \n",
              "1    0.000000  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.0   \n",
              "2    0.000000  0.0  0.0  0.0  0.019325  0.0  0.008338  0.0   0.0  0.0  0.0   \n",
              "3    0.000000  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.0   \n",
              "4    0.000000  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.0   \n",
              "..        ...  ...  ...  ...       ...  ...       ...  ...   ...  ...  ...   \n",
              "203  0.014645  0.0  0.0  0.0  0.000000  0.0  0.006144  0.0   0.0  0.0  0.0   \n",
              "204  0.000000  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.0   \n",
              "205  0.000000  0.0  0.0  0.0  0.000000  0.0  0.016124  0.0   0.0  0.0  0.0   \n",
              "206  0.000000  0.0  0.0  0.0  0.000000  0.0  0.043812  0.0   0.0  0.0  0.0   \n",
              "207  0.000000  0.0  0.0  0.0  0.000000  0.0  0.007926  0.0   0.0  0.0  0.0   \n",
              "\n",
              "     10x        11        12  120  125  128   13        14        15  150  \\\n",
              "0    0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "1    0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "2    0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "3    0.0  0.006739  0.000000  0.0  0.0  0.0  0.0  0.008671  0.006797  0.0   \n",
              "4    0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "..   ...       ...       ...  ...  ...  ...  ...       ...       ...  ...   \n",
              "203  0.0  0.000000  0.007839  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "204  0.0  0.000000  0.019870  0.0  0.0  0.0  0.0  0.027925  0.000000  0.0   \n",
              "205  0.0  0.022469  0.020573  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "206  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.036947  0.0   \n",
              "207  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
              "\n",
              "      16   17        18   19  1980  1989  1990   1k  1st        20  200  \\\n",
              "0    0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "1    0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "2    0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "3    0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "4    0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "..   ...  ...       ...  ...   ...   ...   ...  ...  ...       ...  ...   \n",
              "203  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.007293  0.0   \n",
              "204  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "205  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "206  0.0  0.0  0.031423  0.0   0.0   0.0   0.0  0.0  0.0  0.000000  0.0   \n",
              "207  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  0.009408  0.0   \n",
              "\n",
              "         2000  2001  2005      2008  2009  2010  2011  2012  2013  2014  2015  \\\n",
              "0    0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "1    0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "2    0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "3    0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "4    0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "..        ...   ...   ...       ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "203  0.012485   0.0   0.0  0.013551   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "204  0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "205  0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "206  0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "207  0.000000   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "     2016      2017     2018     2019  2020      2021   21  ...  wise  \\\n",
              "0     0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "1     0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "2     0.0  0.000000  0.00000  0.00000   0.0  0.014752  0.0  ...   0.0   \n",
              "3     0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "4     0.0  0.034345  0.00000  0.03956   0.0  0.000000  0.0  ...   0.0   \n",
              "..    ...       ...      ...      ...   ...       ...  ...  ...   ...   \n",
              "203   0.0  0.000000  0.01073  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "204   0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "205   0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "206   0.0  0.014926  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "207   0.0  0.000000  0.00000  0.00000   0.0  0.000000  0.0  ...   0.0   \n",
              "\n",
              "         wish  withdraw     woman    wonder  wonderful  wood      word  \\\n",
              "0    0.000000       0.0  0.000000  0.000000        0.0   0.0  0.007983   \n",
              "1    0.000000       0.0  0.000000  0.000000        0.0   0.0  0.000000   \n",
              "2    0.000000       0.0  0.000000  0.000000        0.0   0.0  0.000000   \n",
              "3    0.000000       0.0  0.000000  0.000000        0.0   0.0  0.000000   \n",
              "4    0.034345       0.0  0.000000  0.000000        0.0   0.0  0.021550   \n",
              "..        ...       ...       ...       ...        ...   ...       ...   \n",
              "203  0.000000       0.0  0.000000  0.009991        0.0   0.0  0.000000   \n",
              "204  0.000000       0.0  0.000000  0.025325        0.0   0.0  0.000000   \n",
              "205  0.000000       0.0  0.000000  0.000000        0.0   0.0  0.000000   \n",
              "206  0.000000       0.0  0.000000  0.000000        0.0   0.0  0.000000   \n",
              "207  0.000000       0.0  0.073074  0.000000        0.0   0.0  0.025414   \n",
              "\n",
              "         work  worker  workflow  working  workout     world  worried  \\\n",
              "0    0.005163     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "1    0.000000     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "2    0.023056     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "3    0.013373     0.0       0.0      0.0      0.0  0.013774      0.0   \n",
              "4    0.027877     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "..        ...     ...       ...      ...      ...       ...      ...   \n",
              "203  0.016990     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "204  0.043065     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "205  0.000000     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "206  0.060575     0.0       0.0      0.0      0.0  0.008319      0.0   \n",
              "207  0.010959     0.0       0.0      0.0      0.0  0.000000      0.0   \n",
              "\n",
              "        worry  worse    worsen  worth  wow  wrap     write  writer  writing  \\\n",
              "0    0.000000    0.0  0.000000    0.0  0.0   0.0  0.013415     0.0      0.0   \n",
              "1    0.000000    0.0  0.000000    0.0  0.0   0.0  0.014015     0.0      0.0   \n",
              "2    0.000000    0.0  0.000000    0.0  0.0   0.0  0.014976     0.0      0.0   \n",
              "3    0.008340    0.0  0.000000    0.0  0.0   0.0  0.017372     0.0      0.0   \n",
              "4    0.000000    0.0  0.000000    0.0  0.0   0.0  0.000000     0.0      0.0   \n",
              "..        ...    ...       ...    ...  ...   ...       ...     ...      ...   \n",
              "203  0.000000    0.0  0.015103    0.0  0.0   0.0  0.005518     0.0      0.0   \n",
              "204  0.000000    0.0  0.000000    0.0  0.0   0.0  0.000000     0.0      0.0   \n",
              "205  0.000000    0.0  0.000000    0.0  0.0   0.0  0.000000     0.0      0.0   \n",
              "206  0.000000    0.0  0.000000    0.0  0.0   0.0  0.023607     0.0      0.0   \n",
              "207  0.013668    0.0  0.000000    0.0  0.0   0.0  0.014236     0.0      0.0   \n",
              "\n",
              "        wrong       www  xgboost   xi  yeah      year  yearly  yell  yellow  \\\n",
              "0    0.000000  0.000000  0.00918  0.0   0.0  0.000000     0.0   0.0     0.0   \n",
              "1    0.000000  0.025665  0.00000  0.0   0.0  0.000000     0.0   0.0     0.0   \n",
              "2    0.010886  0.013712  0.00000  0.0   0.0  0.006700     0.0   0.0     0.0   \n",
              "3    0.000000  0.000000  0.00000  0.0   0.0  0.000000     0.0   0.0     0.0   \n",
              "4    0.000000  0.000000  0.00000  0.0   0.0  0.000000     0.0   0.0     0.0   \n",
              "..        ...       ...      ...  ...   ...       ...     ...   ...     ...   \n",
              "203  0.024065  0.000000  0.00000  0.0   0.0  0.019747     0.0   0.0     0.0   \n",
              "204  0.040666  0.076833  0.00000  0.0   0.0  0.012514     0.0   0.0     0.0   \n",
              "205  0.000000  0.000000  0.00000  0.0   0.0  0.000000     0.0   0.0     0.0   \n",
              "206  0.000000  0.014410  0.00000  0.0   0.0  0.014081     0.0   0.0     0.0   \n",
              "207  0.010348  0.000000  0.00000  0.0   0.0  0.006369     0.0   0.0     0.0   \n",
              "\n",
              "          yes  yesterday  yield        yo  york       you     young  youtube  \\\n",
              "0    0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "1    0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "2    0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "3    0.006572        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "4    0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "..        ...        ...    ...       ...   ...       ...       ...      ...   \n",
              "203  0.000000        0.0    0.0  0.000000   0.0  0.000000  0.009776      0.0   \n",
              "204  0.021163        0.0    0.0  0.000000   0.0  0.034348  0.000000      0.0   \n",
              "205  0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "206  0.000000        0.0    0.0  0.000000   0.0  0.000000  0.000000      0.0   \n",
              "207  0.021541        0.0    0.0  0.040333   0.0  0.000000  0.000000      0.0   \n",
              "\n",
              "         zero  zhou  zip   zombie      zone  zoom  zuckerberg  \\\n",
              "0    0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "1    0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "2    0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "3    0.006364   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "4    0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "..        ...   ...  ...      ...       ...   ...         ...   \n",
              "203  0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "204  0.000000   0.0  0.0  0.00000  0.068695   0.0         0.0   \n",
              "205  0.021217   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "206  0.000000   0.0  0.0  0.02154  0.019325   0.0         0.0   \n",
              "207  0.000000   0.0  0.0  0.00000  0.000000   0.0         0.0   \n",
              "\n",
              "                                                 TITLE   ID  \n",
              "0     Ensemble methods: bagging, boosting and stacking    1  \n",
              "1                        Understanding AUC - ROC Curve    2  \n",
              "2    How to work with object detection datasets in ...    3  \n",
              "3    11 Dimensionality reduction techniques you sho...    4  \n",
              "4                          The Time Series Transformer    5  \n",
              "..                                                 ...  ...  \n",
              "203    Type 2 Diabetes Reversal  The Quick Start Guide  210  \n",
              "204            How a 22 Day Water Fast Changed My Life  211  \n",
              "205                                 Breaking Your Fast  212  \n",
              "206           11 Unusual Tips for How to Wake Up Early  213  \n",
              "207  The 3 Biggest Mistakes Women Make On The Ketog...  214  \n",
              "\n",
              "[208 rows x 3714 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3789f92e-b7c9-4bb6-a21b-aff052b51800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>10k</th>\n",
              "      <th>10x</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>125</th>\n",
              "      <th>128</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>1980</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1k</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>200</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2005</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>21</th>\n",
              "      <th>...</th>\n",
              "      <th>wise</th>\n",
              "      <th>wish</th>\n",
              "      <th>withdraw</th>\n",
              "      <th>woman</th>\n",
              "      <th>wonder</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>wood</th>\n",
              "      <th>word</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>workflow</th>\n",
              "      <th>working</th>\n",
              "      <th>workout</th>\n",
              "      <th>world</th>\n",
              "      <th>worried</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worsen</th>\n",
              "      <th>worth</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>www</th>\n",
              "      <th>xgboost</th>\n",
              "      <th>xi</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yearly</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yield</th>\n",
              "      <th>yo</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhou</th>\n",
              "      <th>zip</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007983</td>\n",
              "      <td>0.005163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00918</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025665</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Understanding AUC - ROC Curve</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010886</td>\n",
              "      <td>0.013712</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>How to work with object detection datasets in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008671</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013373</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034345</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.03956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021550</td>\n",
              "      <td>0.027877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The Time Series Transformer</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.014645</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012485</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.01073</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009991</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Type 2 Diabetes Reversal  The Quick Start Guide</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027925</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040666</td>\n",
              "      <td>0.076833</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034348</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>How a 22 Day Water Fast Changed My Life</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022469</td>\n",
              "      <td>0.020573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Breaking Your Fast</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036947</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014926</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014081</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02154</td>\n",
              "      <td>0.019325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11 Unusual Tips for How to Wake Up Early</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.073074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025414</td>\n",
              "      <td>0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014236</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010348</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The 3 Biggest Mistakes Women Make On The Ketog...</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 3714 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3789f92e-b7c9-4bb6-a21b-aff052b51800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3789f92e-b7c9-4bb6-a21b-aff052b51800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3789f92e-b7c9-4bb6-a21b-aff052b51800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43755e88-6d75-40ab-b62d-67978673267a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43755e88-6d75-40ab-b62d-67978673267a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43755e88-6d75-40ab-b62d-67978673267a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_697c1ca6-035a-4a6d-b11b-a9685c7afae5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tfidf_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_697c1ca6-035a-4a6d-b11b-a9685c7afae5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tfidf_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tfidf_features_df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2)\n",
        "tsne_tfidf_features = tsne.fit_transform(tfidf_features_df[tfidf_vectorizer.get_feature_names_out()].values)\n",
        "tsne_tfidf_features_df = pd.DataFrame(tsne_tfidf_features)\n",
        "tsne_tfidf_features_df.columns = ['C1', 'C2']\n",
        "tsne_tfidf_features_df['TITLE'] = tfidf_features_df['TITLE']\n",
        "display(tsne_tfidf_features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p0RQKfyXxehw",
        "outputId": "12ebdccd-91f2-4510-cebb-9f5c76a34fe3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           C1         C2                                              TITLE\n",
              "0    0.369850  15.963756   Ensemble methods: bagging, boosting and stacking\n",
              "1    4.710252  17.383831                      Understanding AUC - ROC Curve\n",
              "2   -2.583960  13.446282  How to work with object detection datasets in ...\n",
              "3   -2.480263  16.863926  11 Dimensionality reduction techniques you sho...\n",
              "4   -6.881161  16.156950                        The Time Series Transformer\n",
              "..        ...        ...                                                ...\n",
              "203 -6.844769 -22.623976    Type 2 Diabetes Reversal  The Quick Start Guide\n",
              "204 -6.120381 -17.950832            How a 22 Day Water Fast Changed My Life\n",
              "205 -7.058402 -18.350189                                 Breaking Your Fast\n",
              "206  0.051298 -18.754917           11 Unusual Tips for How to Wake Up Early\n",
              "207 -8.436134 -19.942486  The 3 Biggest Mistakes Women Make On The Ketog...\n",
              "\n",
              "[208 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bcd7c62-84b4-4aaa-b751-952f501a7664\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>TITLE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.369850</td>\n",
              "      <td>15.963756</td>\n",
              "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.710252</td>\n",
              "      <td>17.383831</td>\n",
              "      <td>Understanding AUC - ROC Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.583960</td>\n",
              "      <td>13.446282</td>\n",
              "      <td>How to work with object detection datasets in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.480263</td>\n",
              "      <td>16.863926</td>\n",
              "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.881161</td>\n",
              "      <td>16.156950</td>\n",
              "      <td>The Time Series Transformer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>-6.844769</td>\n",
              "      <td>-22.623976</td>\n",
              "      <td>Type 2 Diabetes Reversal  The Quick Start Guide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-6.120381</td>\n",
              "      <td>-17.950832</td>\n",
              "      <td>How a 22 Day Water Fast Changed My Life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>-7.058402</td>\n",
              "      <td>-18.350189</td>\n",
              "      <td>Breaking Your Fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.051298</td>\n",
              "      <td>-18.754917</td>\n",
              "      <td>11 Unusual Tips for How to Wake Up Early</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>-8.436134</td>\n",
              "      <td>-19.942486</td>\n",
              "      <td>The 3 Biggest Mistakes Women Make On The Ketog...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bcd7c62-84b4-4aaa-b751-952f501a7664')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6bcd7c62-84b4-4aaa-b751-952f501a7664 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6bcd7c62-84b4-4aaa-b751-952f501a7664');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc8d00c5-9980-45a4-846b-58e1181d29f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc8d00c5-9980-45a4-846b-58e1181d29f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc8d00c5-9980-45a4-846b-58e1181d29f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f59bcad8-69c2-451d-ac2a-88a088fa9d7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tsne_tfidf_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f59bcad8-69c2-451d-ac2a-88a088fa9d7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tsne_tfidf_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tsne_tfidf_features_df",
              "summary": "{\n  \"name\": \"tsne_tfidf_features_df\",\n  \"rows\": 208,\n  \"fields\": [\n    {\n      \"column\": \"C1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          1.9939985275268555,\n          -8.06248664855957,\n          0.8784953355789185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          -2.75359845161438,\n          12.664704322814941,\n          13.82808780670166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TITLE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 208,\n        \"samples\": [\n          \"How I transformed $6,000 to $3,000,000\",\n          \"Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences\",\n          \"Train/Test Split and Cross Validation in Python\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"T-distributed Stochastic Neighbor Embedding for TFIDF document representation\"\n",
        "fig = px.scatter(tsne_tfidf_features_df, x=\"C1\", y=\"C2\", hover_data=['TITLE'], title=title)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2cHtMwwgnXwv",
        "outputId": "c100fe71-9595-4d75-85e6-a59bbea60697"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"d9ff25c0-2b9f-4ed8-a6cf-3a874454dff3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d9ff25c0-2b9f-4ed8-a6cf-3a874454dff3\")) {                    Plotly.newPlot(                        \"d9ff25c0-2b9f-4ed8-a6cf-3a874454dff3\",                        [{\"customdata\":[[\"Ensemble methods: bagging, boosting and stacking\"],[\"Understanding AUC - ROC Curve\"],[\"How to work with object detection datasets in COCO format\"],[\"11 Dimensionality reduction techniques you should know in 2021\"],[\"The Time Series Transformer\"],[\"Learning a Personalized Homepage\"],[\"6 Data Science Certificates To Level Up Your Career\"],[\"Transformers Explained Visually (Part 2): How it works, step-by-step\"],[\"60 Python Projects with Source Code\"],[\"Geometric foundations of Deep Learning\"],[\"Machine Learning Basics with the K-Nearest Neighbors Algorithm\"],[\"Building RNN, LSTM, and GRU for time series using PyTorch\"],[\"Algorithms of the Mind\"],[\"4 Reasons Why Economists Make Great Data Scientists (And Why No One Tells Them)\"],[\"How To Create A Chatbot with Python & Deep Learning In Less Than An Hour\"],[\"Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences\"],[\"Illustrated Guide to LSTM's and GRU's: A step by step explanation\"],[\"How to go from a Python newbie to a Google Certified TensorFlow Developer under two months\"],[\"17 Clustering Algorithms Used In Data Science and Mining\"],[\"Introduction to Genetic Algorithms  Including Example Code\"],[\"Photoreal Roman Emperor Project\"],[\"Fundamental Techniques of Feature Engineering for Machine Learning\"],[\"How I Got a Job at DeepMind as a Research Engineer (without a Machine Learning Degree!)\"],[\"Towards the end of deep learning and the beginning of AGI\"],[\"Tutorial: Document Classification using WEKA\"],[\"Understanding Random Forest\"],[\"Probability concepts explained: Maximum likelihood estimation\"],[\"Transformers Explained Visually (Part 3): Multi-head Attention, deep dive\"],[\"180 Data Science and Machine Learning Projects with Python\"],[\"5 Online Courses I Took as a Self-Taught Data Scientist\"],[\"Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning\"],[\"9 Distance Measures in Data Science\"],[\"The Sexiest Job of the 21st Century Isn't \\\"Sexy\\\" Anymore\"],[\"Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks\"],[\"A Comprehensive Guide to Convolutional Neural Networks  the ELI5 way\"],[\"20 Necessary Requirements of a Perfect Laptop for Data Science and Machine Learning Tasks\"],[\"3 Beginner Mistakes I've Made in My Data Science Career\"],[\"Understanding Variational Autoencoders (VAEs)\"],[\"Setting Up a New M1 MacBook for Data Science\"],[\"Are The New M1 Macbooks Any Good for Data Science? Let's Find Out\"],[\"Simple and Multiple Linear Regression in Python\"],[\"I tripled my income with data science. Here's how.\"],[\"Keyword Extraction process in Python with Natural Language Processing(NLP)\"],[\"Machine learning models for 100% better returns in Algo-trading\"],[\"How to Install Ubuntu Desktop With a Graphical User Interface in WSL2\"],[\"Understanding Contrastive Learning\"],[\"Understanding Semantic Segmentation with UNET\"],[\"How Transformers Work\"],[\"Yes you should understand backprop\"],[\"PCA using Python (scikit-learn)\"],[\"Hyperparameter Tuning the Random Forest in Python\"],[\"Top 3 Reasons Why I Sold My M1 Macbook Pro as a Data Scientist\"],[\"TRAIN A CUSTOM YOLOv4 OBJECT DETECTOR (Using Google Colab)\"],[\"6 Machine Learning Certificates to Pursue in 2021\"],[\"What to do with \\\"small\\\" data?\"],[\"Time Series Forecasting with PyCaret Regression Module\"],[\"15 Habits I Learned from Highly Effective Data Scientists\"],[\"OVER 100 Data Scientist Interview Questions and Answers!\"],[\"Activation Functions in Neural Networks\"],[\"A One-Stop Shop for Principal Component Analysis\"],[\"5 Things You Should Know About Covariance\"],[\"How to build your own Neural Network from scratch in Python\"],[\"The best explanation of Convolutional Neural Networks on the Internet!\"],[\"Lambda Functions with Practical Examples in Python\"],[\"The Complete Guide to Time Series Analysis and Forecasting\"],[\"8 Ways to Filter Pandas Dataframes\"],[\"Standing with Dr. Timnit Gebru  #ISupportTimnit #BelieveBlackWomen\"],[\"Visualising high-dimensional datasets using PCA and t-SNE in Python\"],[\"How to Study for the Google Data Analytics Professional Certificate\"],[\"Is Data Science Still a Rising Career in 2021\"],[\"Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks\"],[\"How To Grow From Non-Coder to Data Scientist in 6 Months\"],[\"Apple's New M1 Chip is a Machine Learning Beast\"],[\"Train\\u002fTest Split and Cross Validation in Python\"],[\"Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT\"],[\"The 5 Clustering Algorithms Data Scientists Need to Know\"],[\"Building A Logistic Regression in Python, Step by Step\"],[\"Springer has released 65 Machine Learning and Data books for free\"],[\"Every single Machine Learning course on the internet, ranked by your reviews\"],[\"TensorFlow Tutorial Part 1\"],[\"The 7 Best Data Science and Machine Learning Podcasts\"],[\"Random Forest in Python\"],[\"How to Land a Data Analytics Job in 6 Months\"],[\"What is a Transformer?\"],[\"Fundamentals Of Statistics For Data Scientists and Analysts\"],[\"Is Google's AI research about to implode?\"],[\"Machine Learning is Fun! Part 2\"],[\"Understanding Generative Adversarial Networks (GANs)\"],[\"17 types of similarity and dissimilarity measures used in data science.\"],[\"Deep Learning Is Going to Teach Us All the Lesson of Our Lives: Jobs Are for Machines\"],[\"I interviewed at five top companies in Silicon Valley in five days, and luckily got five job offers\"],[\"Advantages and Disadvantages of Artificial Intelligence\"],[\"Could Nim Replace Python?\"],[\"An End-to-End Project on Time Series Analysis and Forecasting with Python\"],[\"Data Scientists Will be Extinct in 10 Years\"],[\"Import all Python libraries in one line of code\"],[\"Enchanted Random Forest\"],[\"Machine Learning in a Week\"],[\"50+ Statistics Interview Questions and Answers for Data Scientists for 2022\"],[\"Top 10 Data Science Projects for Beginners\"],[\"Check For a Substring in a Pandas DataFrame Column\"],[\"Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning\"],[\"Everything You Need to Know About Artificial Neural Networks\"],[\"Ways to Detect and Remove the Outliers\"],[\"How to Crush the Crypto Market, Quit Your Job, Move to Paradise and Do Whatever You Want the Rest of Your Life\"],[\"Bitcoin Is Venice\"],[\"How I Built a Net Worth of $500,000 Before Age 30\"],[\"Nassim Nicholas Taleb on Self-Education and Doing the Math (Ep. 41  Live at Mercatus)\"],[\"Public Mint Polkastarter IDO: Launching 23rd of February, Whitelist Now Open!\"],[\"This is How I Made $40k In Passive Income By Age 26\"],[\"Introducing The Iron Bank\"],[\"I used Acorns, Robinhood, and Stash for 2 years. This is what I learned and earned.\"],[\"Explaining blockchain  how proof of work enables trustless consensus\"],[\"Wealthfront:Silicon Valley Tech at Wall Street Prices\"],[\"Crypto Trading Bots  A helpful guide for beginners [2020]\"],[\"Why People Still Don't Get Cryptocurrency\"],[\"Australia's Economy is a House of Cards\"],[\"My First Two Months Trading Stocks with Robinhood\"],[\"What It Takes to Go from $0 to $1 Million in Less Than One Year\"],[\"Tesla Is Dead (And Elon Musk Knows It)\"],[\"Uber's Credit Card Is Bankrupting Restaurants... and It's All Your Fault\"],[\"A Quick Starter Guide to Leveraged Trading at BitMEX\"],[\"I Made $3 Million in Crypto. These are the 26 Rules I Learned.\"],[\"The Black-Scholes formula, explained\"],[\"You Will Never Be Rich If You Keep Doing These 10 things\"],[\"Heroes Give, Superheroes Borrow\"],[\"Could Bitcoin's Bull Market End Next Month?\"],[\"The Exact Steps I Followed to Make $1,500+ of Passive Income Every Month\"],[\"You May Have A Poor Person's Mindset And Not Know It\"],[\"A Definitive Guide to Why Life Is So Terrible for Most Millennials\"],[\"The Berkshire Hathaway of The Internet\"],[\"How to invest in Bitcoin properly. Blockchain and other cryptocurrencies\"],[\"Machine learning in finance: Why, what & how\"],[\"Minimum Wage Artists\"],[\"Richart + @GoGo \"],[\"How to store Bitcoins and other cryptocurrencies properly.\"],[\"I was wrong about Ethereum\"],[\"Deep Learning the Stock Market\"],[\"Financial Fridays: It's Financial Suicide To Own A House\"],[\"Gauge Theory Does Not Fix This\"],[\"High Frequency Trading on the Coinbase Exchange\"],[\"A $1000 Bitcoin Investment Won't Make You Rich\"],[\"How To Legally Own Another Person\"],[\"5 Things NOT to Do in the Robinhood App for Stock Trading\"],[\"The One Word That Explains Why Economics Professors Are Not Billionaires\"],[\"Building your credit history\"],[\"I Retired at 35  Here Are 5 Lessons from My First 6 Months of Freedom\"],[\"Why you should never use Upwork, ever.\"],[\"Facebook Can't Be Fixed.\"],[\"A comprehensive guide to downloading stock prices in Python\"],[\"Detecting Credit Card Fraud Using Machine Learning\"],[\"2018  & : KOKO COMBO icash \"],[\"Is Wealthfront Worth it?\"],[\"How I Slowly Became A \\\"Middle-Class\\\" Millionaire\"],[\"SPY vs. QQQ: Investing in Different Indexes\"],[\"I Won $104 Million for Blowing the Whistle on My CompanyBut Somehow I Was the Only One Who Went to Jail\"],[\"Robinhood Lends \\\"Your\\\" Shares to Short Sellers (and Keeps All the Proceeds)\"],[\"The Secret to Making 2000% in Stocks Overnight, the Anavex story.\"],[\"4 Unusual Side Hustles I Do to Earn an Extra $1,500 a Month\"],[\"Meet 'Spoofy'. How a Single entity dominates the price of Bitcoin.\"],[\"How I Started Saving a TON of Money.\"],[\"How I transformed $6,000 to $3,000,000\"],[\"Cliff Asness on Marvel vs. DC and Why Never to Share a Gym with Cirque du Soleil (Ep. 5  Live at Mason)\"],[\"Paypal froze our funds, then offered us a business loan\"],[\"A Visual Explanation of Algorithmic Stablecoins\"],[\"Algorithmic Trading Bot: Python\"],[\"Chernobyl's Blown Up Reactor 4 Just Woke Up\"],[\"The Unexpected Case of the Disappearing Flu\"],[\"The Diet & Workout Plan of a Full-Time Traveling Family  HIS\"],[\"The Cult of Work You Never Meant to Join\"],[\"5 Things to do in the First 24 Hours of a Cold or Flu\"],[\"The Sweet Spot for Intermittent Fasting\"],[\"The 6 Types of ICU Nurse\"],[\"How to biohack your intelligence  with everything from sex to modafinil to MDMA\"],[\"8 Common Arguments Against Vaccines\"],[\"A Reasonably Detailed Guide to Optimizing Your iPhone for Productivity, Focus and Your Own Health\"],[\"The cure for type 2 diabetes is known, but few are aware\"],[\"Face mapping: how to deal with acne like a true detective\"],[\"I'm 32 and spent $200k on biohacking. Became calmer, thinner, extroverted, healthier & happier.\"],[\"I need more iron\"],[\"What I Learned From Quitting Coffee After 15 Years Of Daily Consumption\"],[\"The forgotten art of untucking the tail\"],[\"Hip Replacement Isn't What It Used To Be 12 Weeks Ago\"],[\"Coronavirus: Why You Must Act Now\"],[\"Manufacturers have been using nanotechnology-derived graphene in face masks  now there are safety concerns\"],[\"Eben Byers: The Man Who Drank Radioactive Water Until His Jaw Fell Off\"],[\"My Intermittent Fasting Lifestyle: How I Dropped 50 Pounds\"],[\"I Stopped Drinking for 30 Days. Here's What Happened.\"],[\"How to lose 10+ pounds of fat a month- even if you have a slow metabolism\"],[\"If You're Buying Your Weed Solely Based on the THC Level, You're Doing it Wrong.\"],[\"2016 Is Not Killing People\"],[\"How I Learned to Sleep Only Three Hours Per Night (and Why You Should Too)\"],[\"I fasted for 11 days, here is what happened.\"],[\"Coronavirus: The Hammer and the Dance\"],[\"What Happens in Your Body When You Quit Drinking\"],[\"The Science Behind Fat Metabolism\"],[\"The Easiest Way to Lose 125 Pounds Is to Gain 175 Pounds\"],[\"7 things I did to reboot my life.\"],[\"How I lost 10kg in 60 days: My 7-step weight loss plan\"],[\"The Foo Fighters' AIDS denialism should be on the record\"],[\"The Uncut History of Male Circumcision\"],[\"10 Things You Can Do This Morning To Heal Your Anxiety\"],[\"I just lost 100 pounds. Here's whyalmost nobody else will!\"],[\"Type 2 Diabetes Reversal  The Quick Start Guide\"],[\"How a 22 Day Water Fast Changed My Life\"],[\"Breaking Your Fast\"],[\"11 Unusual Tips for How to Wake Up Early\"],[\"The 3 Biggest Mistakes Women Make On The Ketogenic Diet (And How To Fix Them)\"]],\"hovertemplate\":\"C1=%{x}\\u003cbr\\u003eC2=%{y}\\u003cbr\\u003eTITLE=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.3698495924472809,4.710251808166504,-2.5839600563049316,-2.4802634716033936,-6.881160736083984,9.254891395568848,9.984884262084961,-8.347959518432617,2.6307427883148193,-8.939273834228516,4.630731582641602,-0.48931625485420227,-6.657022953033447,6.4036545753479,-4.734533309936523,-8.06248664855957,-9.987181663513184,7.96846866607666,0.43434280157089233,2.068070650100708,-13.754218101501465,2.275561571121216,-2.265996217727661,-4.65922737121582,-1.6671662330627441,3.419558525085449,-0.5924493074417114,-8.04504108428955,3.512416362762451,7.818859577178955,-8.457472801208496,5.151799201965332,8.470473289489746,-8.824342727661133,-7.8870930671691895,16.990018844604492,6.839699745178223,-6.010370254516602,15.06990909576416,15.174500465393066,-0.9844914078712463,6.382137298583984,1.1467560529708862,2.167872190475464,-3.6145377159118652,-6.243645191192627,-7.65748405456543,-8.09715461730957,-10.975190162658691,-2.903618812561035,2.0220019817352295,15.79482650756836,-2.9768900871276855,9.878636360168457,1.5397156476974487,0.3331317901611328,7.801077365875244,1.0074057579040527,-0.5533507466316223,-2.481327533721924,-2.7623581886291504,-10.233409881591797,-9.283365249633789,-0.2576533555984497,6.05397891998291,8.2723970413208,9.778008460998535,-3.5576393604278564,8.569096565246582,8.72513484954834,-10.936466217041016,7.7960076332092285,15.349825859069824,0.8784953355789185,-5.772176265716553,0.47223377227783203,-0.3010542690753937,3.625450849533081,6.9445037841796875,7.612610340118408,10.696113586425781,2.576131820678711,9.156033515930176,-8.772347450256348,-0.5821382403373718,-3.867737054824829,-3.9230360984802246,-5.515653133392334,5.047478675842285,-2.4818341732025146,-2.3102874755859375,-2.931997537612915,2.3245837688446045,6.409654140472412,9.189313888549805,2.5732295513153076,3.478205680847168,5.8144145011901855,1.1137182712554932,9.845111846923828,7.8214898109436035,-12.25774097442627,-10.193050384521484,2.640993118286133,-2.6117005348205566,-4.773698806762695,2.510162591934204,-2.4159886837005615,-9.402944564819336,3.246778726577759,-11.254767417907715,4.090721607208252,-5.664015769958496,4.746773719787598,-7.171992778778076,-0.7086902260780334,4.544706344604492,4.0893235206604,7.4734721183776855,0.5451012253761292,8.965384483337402,-4.604353427886963,-4.376319885253906,0.8525128960609436,1.4538055658340454,-0.7496923804283142,-5.494729042053223,1.8644218444824219,0.09264939278364182,4.001782417297363,1.5715522766113281,-5.854447841644287,5.438532829284668,4.251568794250488,-3.3558120727539062,-6.879366874694824,-7.444691181182861,-6.923333644866943,4.081230163574219,-3.4725828170776367,-7.114003658294678,-5.071885108947754,-1.0022677183151245,3.668649673461914,0.5814421772956848,11.010091781616211,1.249650239944458,7.738263130187988,-0.1948271244764328,2.2068819999694824,3.6688032150268555,-3.749840259552002,3.6775882244110107,2.9049713611602783,4.806051254272461,6.028401851654053,5.202785968780518,1.8171038627624512,6.175262451171875,-5.959650993347168,0.34346967935562134,1.9939985275268555,-1.729068636894226,10.737771034240723,-10.643881797790527,2.812823534011841,9.773894309997559,6.163680553436279,-3.7531251907348633,-0.7552146911621094,5.125931262969971,-8.585582733154297,-2.973106622695923,-0.749964714050293,7.410970687866211,-2.4787580966949463,-7.102255344390869,-9.57430362701416,-1.2001981735229492,-11.659486770629883,0.28528454899787903,-3.914564847946167,-3.5915446281433105,5.765474796295166,-7.418191432952881,-6.166660785675049,-6.125675678253174,-0.5827571153640747,-5.561610698699951,-6.109764575958252,3.2146456241607666,0.11953273415565491,-5.573837757110596,5.9481096267700195,-1.2684024572372437,-8.02837085723877,-3.0629782676696777,-2.0407145023345947,-4.7402238845825195,2.9245495796203613,1.0031920671463013,0.5213676691055298,-4.0779266357421875,-6.844769477844238,-6.1203813552856445,-7.058401584625244,0.05129817873239517,-8.436134338378906],\"xaxis\":\"x\",\"y\":[15.96375560760498,17.383831024169922,13.446282386779785,16.86392593383789,16.156949996948242,18.614025115966797,9.841243743896484,15.75248908996582,5.618884086608887,7.340427398681641,20.56783676147461,14.553479194641113,7.678956985473633,5.954975605010986,11.943580627441406,12.664704322814941,13.143594741821289,10.640311241149902,23.391151428222656,20.917522430419922,12.462944984436035,16.999032974243164,0.5909277200698853,6.61149263381958,12.047941207885742,12.361682891845703,21.405719757080078,16.22008514404297,5.849302768707275,6.892645359039307,4.65568733215332,22.338289260864258,4.229076862335205,8.391704559326172,9.66380786895752,3.3114800453186035,4.689510822296143,19.217424392700195,2.5987651348114014,4.2881951332092285,18.540468215942383,3.3940396308898926,5.330734729766846,-0.7227249145507812,11.878254890441895,8.163252830505371,9.399959564208984,14.022757530212402,11.128252983093262,16.745485305786133,13.644400596618652,3.933972120285034,12.715255737304688,9.66929817199707,15.342148780822754,13.431806564331055,3.201017379760742,19.09885597229004,9.083452224731445,18.668380737304688,20.078725814819336,8.449226379394531,9.752026557922363,9.11314582824707,14.602097511291504,18.16181755065918,1.3912962675094604,16.77819061279297,7.8858232498168945,4.5888671875,7.364228248596191,5.58245325088501,2.6155941486358643,13.82808780670166,13.45898151397705,23.623714447021484,17.741619110107422,10.350998878479004,8.13247299194336,11.236541748046875,4.976635456085205,14.128401756286621,6.911686897277832,15.337149620056152,19.71213722229004,8.813419342041016,9.487241744995117,19.60759162902832,22.097444534301758,4.102973461151123,0.5690385699272156,4.214962959289551,6.036764621734619,14.586050033569336,3.5033504962921143,3.219336748123169,11.996671676635742,8.802596092224121,19.514358520507812,6.742311477661133,17.953413009643555,8.645827293395996,9.926946640014648,18.211654663085938,-7.556210041046143,-4.25969934463501,-11.35851001739502,-9.689228057861328,-6.103960037231445,-7.124703884124756,-8.921137809753418,-3.814866304397583,-1.1007940769195557,-6.876418590545654,-8.983197212219238,-7.408138751983643,-8.758648872375488,-2.800126314163208,-6.000797748565674,-2.3534886837005615,-11.17384147644043,-7.434359073638916,-6.539834022521973,-0.6104950308799744,-9.460018157958984,-5.4981560707092285,-5.172223091125488,-8.578044891357422,-8.39638614654541,-10.691178321838379,-5.665664196014404,-3.587055206298828,7.7202677726745605,-12.207121849060059,-12.609341621398926,-3.026183605194092,-5.526151657104492,13.723814964294434,-9.237151145935059,-3.5086159706115723,-8.885910987854004,-4.9288482666015625,-9.869853973388672,-2.6857519149780273,-7.485967636108398,-7.13649320602417,-10.274758338928223,-8.488972663879395,-4.153840065002441,1.1401773691177368,15.944720268249512,-12.262290000915527,-6.176048755645752,-9.867860794067383,-5.468398094177246,-8.538196563720703,-2.316779851913452,-3.572585105895996,-10.892936706542969,-6.856893062591553,-11.389761924743652,-2.75359845161438,-8.40112018585205,-6.95187520980835,-8.088343620300293,-0.2870384156703949,-2.435347318649292,-17.834766387939453,-20.964521408081055,-17.630067825317383,-18.608747482299805,-21.833765029907227,-16.25301170349121,-15.754530906677246,-15.360116958618164,-13.350626945495605,-21.34981346130371,3.006234645843506,-15.393148422241211,-9.62411880493164,-22.40764617919922,-22.58266258239746,-16.983104705810547,-16.248844146728516,3.0215277671813965,-15.86549186706543,-18.739320755004883,-21.917987823486328,-20.398029327392578,-13.334405899047852,-15.381126403808594,-17.476470947265625,-17.161935806274414,-16.448944091796875,-21.990169525146484,-20.46014976501465,-18.70182228088379,-18.261280059814453,-20.69622039794922,-15.70205307006836,-15.154836654663086,-19.426515579223633,-19.632144927978516,-22.62397575378418,-17.95083236694336,-18.350189208984375,-18.75491714477539,-19.942485809326172],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"C1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"C2\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"T-distributed Stochastic Neighbor Embedding for TFIDF document representation\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d9ff25c0-2b9f-4ed8-a6cf-3a874454dff3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check top 5 similar articles for some of the articles in our corpus\n",
        "get_similar_documents(tfidf_features_df, 90, tfidf_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(tfidf_features_df, 80, tfidf_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(tfidf_features_df, 150, tfidf_vectorizer.get_feature_names_out())\n",
        "get_similar_documents(tfidf_features_df, 205, tfidf_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwBnpBJvqxNc",
        "outputId": "b9c09fde-35fa-4232-ca94-aa939c11fc89"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference Article : 17 types of similarity and dissimilarity measures used in data science.\n",
            "**** Similar Articles ****\n",
            "9 Distance Measures in Data Science\n",
            "Machine Learning Basics with the K-Nearest Neighbors Algorithm\n",
            "17 Clustering Algorithms Used In Data Science and Mining\n",
            "OVER 100 Data Scientist Interview Questions and Answers!\n",
            "Fundamental Techniques of Feature Engineering for Machine Learning\n",
            "\n",
            "Reference Article : TensorFlow Tutorial Part 1\n",
            "**** Similar Articles ****\n",
            "How to go from a Python newbie to a Google Certified TensorFlow Developer under two months\n",
            "Enchanted Random Forest\n",
            "Building RNN, LSTM, and GRU for time series using PyTorch\n",
            "The 7 Best Data Science and Machine Learning Podcasts\n",
            "PCA using Python (scikit-learn)\n",
            "\n",
            "Reference Article : The One Word That Explains Why Economics Professors Are Not Billionaires\n",
            "**** Similar Articles ****\n",
            "You Will Never Be Rich If You Keep Doing These 10 things\n",
            "Why People Still Don't Get Cryptocurrency\n",
            "You May Have A Poor Person's Mindset And Not Know It\n",
            "How I transformed $6,000 to $3,000,000\n",
            "4 Reasons Why Economists Make Great Data Scientists (And Why No One Tells Them)\n",
            "\n",
            "Reference Article : How I lost 10kg in 60 days: My 7-step weight loss plan\n",
            "**** Similar Articles ****\n",
            "How to lose 10+ pounds of fat a month- even if you have a slow metabolism\n",
            "10 Things You Can Do This Morning To Heal Your Anxiety\n",
            "The Diet & Workout Plan of a Full-Time Traveling Family  HIS\n",
            "The Science Behind Fat Metabolism\n",
            "The cure for type 2 diabetes is known, but few are aware\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compare the similarities we got from BOW and TF-IDF. We can see there is a little improvement in suggestions using TF-IDF"
      ],
      "metadata": {
        "id": "2ACv13pCroRp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6LGQXz-qxQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "\n",
        "*   Two techniques were used to vectorize the text: BOW and TF-IDF\n",
        "*   BOW used CountVectorizer and TF-IDF uses TfidfVectorizer that is built on top of CountVectorizer.\n",
        "*   These are the basic building blocks of NLP.\n",
        "*   There are more advanced vectorization techniques which use language model and deep learning models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "41zwLMW3smRx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcYzAvflqxTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}